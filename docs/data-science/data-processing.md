# Data processing

[Ibis](https://github.com/ibis-project/ibis) & [Orchest](https://github.com/orchest/orchest) are nice.

## Notes

- [A simple use of array of JSON to store tabular data seems nice. [{row1}, {row2}, {row3}].](https://news.ycombinator.com/item?id=31220841)

## Links

- [Bigslice](https://bigslice.io/) - System for fast, large-scale, serverless data processing using Go.
- [Reflow](https://github.com/grailbio/reflow) - Language and runtime for distributed, incremental data processing in the cloud.
- [Self-managing serverless computing with Bigmachine (2019)](https://medium.com/grail-eng/self-managing-serverless-computing-with-bigmachine-e75bd412ef5a)
- [Bigslice: a cluster computing system for Go (2019)](https://medium.com/grail-eng/bigslice-a-cluster-computing-system-for-go-7e03acd2419b)
- [When your data doesn’t fit in memory: the basic techniques (2019)](https://pythonspeed.com/articles/data-doesnt-fit-in-memory/) ([HN](https://news.ycombinator.com/item?id=21508542))
- [Differential Dataflow](https://github.com/TimelyDataflow/differential-dataflow) - Implementation of differential dataflow using timely dataflow on Rust. ([Book](https://timelydataflow.github.io/differential-dataflow/introduction.html)) ([HN](https://news.ycombinator.com/item?id=24837031))
- [The Log: What every software engineer should know about real-time data's unifying abstraction (2013)](https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying)
- [Luna](https://luna-lang.org/index.html#Overview) - Data processing and visualization environment built on a principle that people need an immediate connection to what they are building.
- [Guide To The Data Lake — Modern Batch Data Warehousing (2020)](https://towardsdatascience.com/a-guide-to-modern-batch-data-warehousing-extraction-f63bfa6ef878)
- [Plumbing At Scale (2020)](https://engineering.grab.com/plumbing-at-scale) - Event Sourcing and Stream Processing Pipelines at Grab.
- [Differential Dataflow! But at what COST? (2017)](https://github.com/frankmcsherry/blog/blob/master/posts/2017-10-23.md) ([HN](https://news.ycombinator.com/item?id=22094512))
- [Timely Dataflow and Total Order (2020)](http://justinjaffray.com/timely-dataflow-and-total-order/)
- [Nuclio](https://github.com/nuclio/nuclio) - High-Performance Serverless event and data processing platform.
- [Apache Spark](https://github.com/apache/spark) - Unified analytics engine for large-scale data processing. ([PySpark](https://github.com/apache/spark/tree/master/python/pyspark)) ([PySpark Style Guide](https://github.com/palantir/pyspark-style-guide)) ([Article](https://medium.com/palantir/a-pyspark-style-guide-for-real-world-data-scientists-1727fda397e9)) ([Web](https://spark.apache.org/)) ([Spark Learning Guide](https://github.com/ankurchavda/SparkLearning))
- [Spark: The Definitive Guide Book (2018)](https://www.oreilly.com/library/view/spark-the-definitive/9781491912201/) ([Code](https://github.com/databricks/Spark-The-Definitive-Guide))
- [Batch](https://batch.sh/) - Event replay platform. Version control for data passing through your messaging systems. ([HN](https://news.ycombinator.com/item?id=24188214))
- [A log/event processing pipeline you can't have (2019)](https://apenwarr.ca/log/20190216) ([HN](https://news.ycombinator.com/item?id=24275683))
- [mm-ADT](http://www.mm-adt.org/) - Multi-Model Abstract Data Type. Distributed virtual machine capable of integrating a diverse collection of data processing technologies. ([Code](https://github.com/mm-adt/vm))
- [Data Preprocessing in Machine Learning (2020)](https://serokell.io/blog/data-preprocessing)
- [lakeFS](https://github.com/treeverse/lakeFS) - Open source layer that delivers resilience and manageability to object-storage based data lakes. ([Web](https://lakefs.io/))
- [Baker](https://github.com/AdRoll/baker) - High performance, composable and extendable data-processing pipeline for the big data era.
- [Cylon](https://github.com/cylondata/cylon) - Fast, scalable distributed memory data parallel library for processing structured data. ([Web](https://cylondata.org/))
- [cuGraph](https://github.com/rapidsai/cugraph) - GPU Graph Analytics.
- [Opaque](https://github.com/mc2-project/opaque) - Secure Apache Spark SQL.
- [Apache Beam](https://github.com/apache/beam) - Unified programming model for Batch and Streaming. ([Web](https://beam.apache.org/))
- [Stitch](https://www.stitchdata.com/) - Simple, extensible ETL built for data teams.
- [Databricks](https://databricks.com/) - Unified Data Analytics. ([GitHub](https://github.com/databricks)) ([CLI](https://github.com/databricks/databricks-cli)) ([Reflecting on Four Years at Databricks (2021)](https://www.lihaoyi.com/post/ReflectingonFourYearsatDatabricks.html))
- [AugMix](https://github.com/google-research/augmix) - Simple Data Processing Method to Improve Robustness and Uncertainty.
- [Snapflow](https://github.com/kvh/snapflow) - Framework for building end-to-end functional data pipelines from modular components.
- [Workflow Description Language (WDL)](https://github.com/openwdl/wdl) - Way to specify data processing workflows with a human-readable and writeable syntax.
- [Cloudfuse](https://www.cloudfuse.io/) - Open source serverless data solutions. Future of data pipelines. ([GitHub](https://github.com/cloudfuse-io))
- [Create your own data stream for Kafka with Python and Faker (2021)](https://aiven.io/blog/create-your-own-data-stream-for-kafka-with-python-and-faker)
- [Hindsight](https://github.com/mozilla-services/hindsight) - C based data processing infrastructure based on the lua sandbox project.
- [Reverse ETL — A Primer (2021)](https://medium.com/memory-leak/reverse-etl-a-primer-4e6694dcc7fb)
- [I wrote one of the fastest DataFrame libraries (2021)](https://www.ritchievink.com/blog/2021/02/28/i-wrote-one-of-the-fastest-dataframe-libraries/)
- [Build your own “data lake” for reporting purposes in a multi-services environment (2021)](https://tech.fretlink.com/build-your-own-data-lake-for-reporting-purposes/)
- [Feature Stores: The Data Side of ML Pipelines (2021)](https://medium.com/riselab/feature-stores-the-data-side-of-ml-pipelines-7083d69bff1c)
- [Flowgger](https://github.com/awslabs/flowgger) - Fast, simple and lightweight data collector written in Rust.
- [Popsink](https://app.popsink.dev/) - Real-time data platform you don't have to build.
- [Flyte](https://github.com/flyteorg/flyte) - Structured programming and distributed processing platform that enables highly concurrent, scalable and maintainable workflows for Machine Learning and Data Processing. ([Web](https://flyte.org/)) ([GitHub](https://github.com/flyteorg)) ([Python SDK](https://github.com/flyteorg/flytekit)) ([CLI](https://github.com/flyteorg/flytectl))
- [Winterfell](https://github.com/novifinancial/winterfell) - Distributed STARK prover.
- [Python to Distributed Python to Airflow task in ~5 lines of code](https://www.astronomer.io/blog/airflow-ray-data-science-story)
- [DataFusion](https://github.com/apache/arrow-datafusion) - Extensible query execution framework, written in Rust, that uses Apache Arrow as its in-memory format.
- [Delta Lake](https://delta.io/) - Reliable Data Lakes at Scale. ([GitHub](https://github.com/delta-io))
- [Delta Sharing](https://delta.io/sharing/) - Open Protocol for Secure Data Sharing. ([Article](https://databricks.com/blog/2021/05/26/introducing-delta-sharing-an-open-protocol-for-secure-data-sharing.html)) ([Tweet](https://twitter.com/matei_zaharia/status/1397585545849540612))
- [Dataform](https://dataform.co/) - Manage data pipelines in BigQuery.
- [Legate Pandas](https://github.com/nv-legate/legate.pandas) - Aspiring Drop-In Replacement for Pandas at Scale.
- [datablocks](https://datablocks.pro/) - Flow based data processing editor. ([HN](https://news.ycombinator.com/item?id=27459664))
- [Reproducible data processing pipelines (2021)](https://guix.gnu.org/blog/2021/reproducible-data-processing-pipelines/)
- [datasketch](https://github.com/ekzhu/datasketch) - Probabilistic data structures that can process and search very large amount of data super fast, with little loss of accuracy.
- [Tuplex](https://github.com/tuplex/tuplex) - Parallel big data processing framework that runs data science pipelines written in Python at the speed of compiled code. ([Web](https://tuplex.cs.brown.edu/))
- [file.d](https://github.com/ozonru/file.d) - Blazing fast tool for building data pipelines: read, process and output events.
- [Datafuse](https://datafuse.rs/) - Modern Real-Time Data Processing in Rust. ([Code](https://github.com/datafuselabs/datafuse/)) ([HN](https://news.ycombinator.com/item?id=28069895))
- [MapReduce is making a comeback (2021)](https://www.estuary.dev/blog/why-mapreduce-is-making-a-comeback) ([HN](https://news.ycombinator.com/item?id=28128360))
- [SciPipe](https://github.com/scipipe/scipipe) - Robust, flexible and resource-efficient pipelines using Go and the command line. ([Docs](https://scipipe.org/))
- [The Future Is Big Graphs: A Community View on Graph Processing Systems (2021)](https://cacm.acm.org/magazines/2021/9/255040-the-future-is-big-graphs/fulltext) ([HN](https://news.ycombinator.com/item?id=28499999))
- [What Is the Data Lakehouse Pattern?](https://timeflow.systems/what-is-the-data-lakehouse-pattern/) ([HN](https://news.ycombinator.com/item?id=28531009))
- [Apache Hadoop](https://hadoop.apache.org/) - Open-source software for reliable, scalable, distributed computing. ([Is Hadoop Dead?](https://tech.marksblogg.com/is-hadoop-dead.html)) ([Code](https://github.com/apache/hadoop))
- [go-stash](https://github.com/tal-tech/go-stash) - High performance, free and open source server-side data processing pipeline that ingests data from Kafka, processes it, and then sends it to ElasticSearch.
- [pypely](https://github.com/stoney95/pypely) - Make your data processing easy - build pipelines in a functional manner.
- [An opinionated map of incremental and streaming systems (2021)](https://scattered-thoughts.net/writing/an-opinionated-map-of-incremental-and-streaming-systems/)
- [Crossjoin](https://github.com/crossjoin-io/crossjoin) - Joins together your data from anywhere.
- [Ceramic Network](https://ceramic.network/) - Decentralized, open source platform for creating, hosting, and sharing streams of data. ([TS Code](https://github.com/ceramicnetwork/js-ceramic)) ([GitHub](https://github.com/ceramicnetwork)) ([Doc](https://github.com/ceramicnetwork/ceramic))
- [Graphite-Web](https://github.com/graphite-project/graphite-web) - Highly scalable real-time graphing system. ([Docs](https://graphite.readthedocs.io/en/stable/))
- [vega](https://github.com/rajasekarv/vega) - Faster implementation of Apache Spark from scratch in Rust.
- [Memgraph](https://github.com/memgraph/memgraph) - Build modern, graph-based applications on top of your streaming data in minutes. ([Web](https://memgraph.com/))
- [Apache Parquetv](https://parquet.apache.org/) - Columnar storage format that supports nested data. ([Code](https://github.com/apache/parquet-format))
- [Data Pipelines Pocket Reference Book (2021)](https://www.oreilly.com/library/view/data-pipelines-pocket/9781492087823/) ([Code](https://github.com/jamesdensmore/datapipelinesbook))
- [miniwdl](https://github.com/chanzuckerberg/miniwdl) - Workflow Description Language developer tools & local runner.
- [Rain](https://github.com/substantic/rain) - Framework for large distributed pipelines.
- [Apache SeaTunnel](https://seatunnel.apache.org/) - Distributed, high-performance data integration platform for the synchronization and transformation of massive data (offline & real-time). ([Code](https://github.com/apache/incubator-seatunnel))
- [Databend](https://github.com/datafuselabs/databend) - Open Source Serverless Data Warehouse for Everyone. ([Web](https://databend.rs/))
- [Pydra](https://github.com/nipype/pydra) - Simple dataflow engine with scalable semantics.
- [Bytewax](https://github.com/bytewax/bytewax) - Open source Python framework for building highly scalable dataflows.
- [Atomic Data](https://docs.atomicdata.dev/) - Modular specification for sharing, modifying and modeling graph data. ([Code](https://github.com/ontola/atomic-data-docs)) ([Rust Code](https://github.com/joepio/atomic-data-rust))
- [Apache Arrow Flight SQL: Accelerating Database Access (2022)](https://arrow.apache.org/blog/2022/02/16/introducing-arrow-flight-sql/) ([HN](https://news.ycombinator.com/item?id=30360726))
- [Grist](https://github.com/gristlabs/grist-core) - Modern relational spreadsheet. Open core alternative to Airtable and Google Sheets. ([HN](https://news.ycombinator.com/item?id=30392227))
- [Data Engineering Practice Problems](https://github.com/danielbeach/data-engineering-practice)
- [Dagster: Rebundling the Data Platform (2022)](https://dagster.io/blog/rebundling-the-data-platform)
- [cq](https://github.com/markus-wa/cq) - Clojure Command-line Data Processor for JSON, YAML, EDN, XML and more.
- [utt](https://github.com/queer/utt) - Universal text transformer.
- [Loggie](https://github.com/loggie-io/loggie) - Lightweight, high-performance, cloud-native agent and aggregator based on Go.
- [ter](https://github.com/schulke-214/ter) - CLI to run text expressions and perform basic text operations such as filtering, ignoring and replacing on the command line.
- [csv-diff](https://github.com/simonw/csv-diff) - Python CLI tool and library for diffing CSV and JSON files.
- [pqrs](https://github.com/manojkarthick/pqrs) - Command line tool for inspecting Parquet files.
- [Kestra](https://kestra.io/) - Infinitely scalable open source orchestration & scheduling platform. ([Code](https://github.com/kestra-io/kestra)) ([HN](https://news.ycombinator.com/item?id=30790047))
- [TiFlash](https://github.com/pingcap/tiflash) - Analytical engine for TiDB.
- [Streamify](https://github.com/ankurchavda/streamify) - Data pipeline with Kafka, Spark Streaming, dbt, Docker, Airflow, Terraform, GCP and much more.
- [DTL](https://getdtl.org/) - Language and JavaScript lib to transform and manipulate data. ([HN](https://news.ycombinator.com/item?id=31098205))
- [Hawk](https://github.com/gelisam/hawk) - Haskell text processor for the command-line.
- [Alternatives to pandas library](https://twitter.com/lalleal/status/1511400363622121482)
- [Zed](https://github.com/brimdata/zed) - Tooling for super-structured data: a new and easier way to manipulate data. ([Web](https://zed.brimdata.io/))
- [Fast Analysis with DuckDB + PyArrow (2022)](https://tech.gerardbentley.com/python/data/intermediate/2022/04/26/holy-duck.html) - Trying out some new speedy tools for data analysis.
- [Why isn’t there a decent file format for tabular data? (2022)](https://successfulsoftware.net/2022/04/30/why-isnt-there-a-decent-file-format-for-tabular-data/) ([HN](https://news.ycombinator.com/item?id=31220841))
- [Data Engineering Wiki](https://dataengineering.wiki/Index) ([Code](https://github.com/JPHaus/data-engineering-wiki))
- [csv-clean](https://github.com/TimothyJones/csv-clean) - Command line tool to clean up malformed CSV files.
- [rq](https://github.com/dflemstr/rq) - Tool for doing record analysis and transformation.
- [Data Integration Guide: Techniques, Technologies, and Tools (2022)](https://airbyte.com/blog/data-integration)
- [Mito](https://www.trymito.io/) - Mito – Excel-like interface for Pandas dataframes in Jupyter notebook. ([HN](https://news.ycombinator.com/item?id=31446236))
- [Tornado](https://github.com/WuerthPhoenix/tornado) - Complex Event Processor that receives reports of events from data sources such as monitoring, email, and telegram, matches them against pre-configured rules.
- [Meet Dash-AB — The Statistics Engine of Experimentation at DoorDash (2022)](https://doordash.engineering/2022/05/24/meet-dash-ab-the-statistics-engine-of-experimentation-at-doordash/)
- [dataPipe](https://github.com/FalconSoft/dataPipe) - Data processing and data analytics library for JavaScript.
- [gosquito](https://github.com/livelace/gosquito) - Pluggable tool for data gathering, data processing and data transmitting to various destinations.
- [DLT](https://github.com/scale-vector/dlt) - Enables simple python-native data pipelining for data professionals.
- [PipeRider](https://github.com/InfuseAI/piperider) - Toolkit for detecting data issues across pipelines that works with CI systems for continuous data quality assessment.
