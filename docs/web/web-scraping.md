# Web scraping

[Scraping Fish](https://scrapingfish.com/), [shot-scraper](https://simonwillison.net/2022/Mar/14/scraping-web-pages-shot-scraper/) ([example](https://til.simonwillison.net/shot-scraper/readability)), [Colly](https://github.com/gocolly/colly) are neat.

Currently exploring [Playwright](https://playwright.dev/) together with [AutoScraper](https://github.com/alirezamika/autoscraper) for my scraping needs.

## Links

- [Scrapy](https://github.com/scrapy/scrapy) - Fast high-level web crawling & scraping framework for Python. ([Web](https://scrapy.org/)) ([Docs](https://docs.scrapy.org/en/latest/)) ([Awesome Scrapy](https://github.com/AccordBox/awesome-scrapy)) ([Random proxy middleware](https://github.com/aivarsk/scrapy-proxies))
- [Scrapyd](https://github.com/scrapy/scrapyd) - Service for running Scrapy spiders. ([Docs](https://scrapyd.readthedocs.io/en/stable/))
- [ScrapydWeb](https://github.com/my8100/scrapydweb) - Web app for Scrapyd cluster management, Scrapy log analysis & visualization, Auto packaging, Timer tasks, Monitor & Alert, and Mobile UI.
- [Simple Scraper](https://simplescraper.io/) - Extract data from any website in seconds.
- [ScrapingBee](https://www.scrapingbee.com/) - Web Scraping API.
- [Easy web scraping with Scrapy (2019)](https://www.scrapingbee.com/blog/web-scraping-with-scrapy/)
- [A guide to Web Scraping without getting blocked in 2020](https://www.scrapingbee.com/blog/web-scraping-without-getting-blocked/)
- [Crawlab](https://github.com/crawlab-team/crawlab) - Distributed web crawler admin platform for spiders management regardless of languages and frameworks.
- [hakrawler](https://github.com/hakluke/hakrawler) - Simple, fast web crawler designed for easy, quick discovery of endpoints and assets within a web application.
- [JobFunnel](https://github.com/PaulMcInnis/JobFunnel) - Tool for scraping job websites, and filtering and reviewing the job listings.
- [You-Get](https://github.com/soimort/you-get) - Tiny command-line utility to download media contents (videos, audios, images) from the Web.
- [Universal Reddit Scraper](https://github.com/JosephLai241/Universal-Reddit-Scraper) - Scrape Subreddits, Redditors, and comments on posts. A command-line tool written in Python.
- [Gerapy](https://github.com/Gerapy/Gerapy) - Distributed Crawler Management Framework Based on Scrapy, Scrapyd, Django and Vue.js.
- [Ask HN: Best practices for ethical web scraping? (2020)](https://news.ycombinator.com/item?id=22778089)
- [Newscatcher](https://newscatcherapi.com/) - Programmatically collect normalized news from (almost) any website. ([Code](https://github.com/kotartemiy/newscatcher))
- [scrapio](https://github.com/Koshqua/scrapio) - Simple and easy-to-use scraper and crawler in Go.
- [Colly](https://github.com/gocolly/colly) - Elegant Scraper and Crawler Framework for Go. ([Tutorial](https://www.youtube.com/watch?v=sU_BwzOxl54))
- [Python Web Scraping with Virtual Private Networks (2020)](https://tech.marksblogg.com/python-scraper-wireguard-vpn-ssh-proxy.html)
- [extract-news-api](https://github.com/kotartemiy/extract-news-api) - Flask code to deploy an API that pulls structured data from online news articles.
- [Web Scraper](https://web.scraper.workers.dev/) - Scrape websites for text by CSS selector.
- [List all the broken links on your website](https://gist.github.com/mdamien/7b71ef06f49de1189fb75f8fed91ae82)
- [Creating a Robust, Reusable Link-Checker (2020)](http://adventures.michaelfbryan.com/posts/linkchecker/)
- [micawber](https://github.com/coleifer/micawber) - Small library for extracting rich content from urls.
- [Spider Pro](https://tryspider.com/) - Easy and cheap way to scrape the internet. ([HN](https://news.ycombinator.com/item?id=21215484))
- [Website Sitemap Parser](https://github.com/berkmancenter/mediacloud-ultimate-sitemap-parser)
- [rget](https://github.com/merklecounty/rget) - Download URLs and verify the contents against a publicly recorded cryptographic log.
- [yarl](https://github.com/aio-libs/yarl) - Yet another URL library.
- [Apify](https://apify.com/) - Web Scraping, Data Extraction and Automation.
- [Gumbo](https://github.com/google/gumbo-parser) - Pure-C HTML5 parser.
- [What is a present-day web scraping in 2020?](https://dataflowkit.com/blog/what-is-a-present-day-web-scraper/)
- [Dataflow Kit](https://dataflowkit.com/) - Web scraping. Data extraction tools
- [Awesome Web Scraping](https://github.com/lorien/awesome-web-scraping)
- [Common Crawl](https://commoncrawl.org/) - Open repository of web crawl data that can be accessed and analyzed by anyone. ([HN](https://news.ycombinator.com/item?id=26594172)) ([Lobsters](https://lobste.rs/s/yotfuq/common_crawl))
- [Analysing Petabytes of Websites using Common Crawl (2017)](https://tech.marksblogg.com/petabytes-of-website-data-spark-emr.html)
- [Cognito Common Crawl](https://github.com/andresriancho/cc-lambda) - Search the common crawl using lambda functions.
- [Awesome Open Source Javascript Projects for Web Scraping (2020)](https://scrapingant.com/awesome-open-source-javascript-projects-for-web-scraping/)
- [ScrapingAnt](https://scrapingant.com/) - All in One Scraping API. Rotating Proxies. Headless Chrome.
- [Django Dynamic Scraper](https://github.com/holgerd77/django-dynamic-scraper) - Creating Scrapy scrapers via the Django admin interface.
- [AutoScraper](https://github.com/alirezamika/autoscraper) - Smart, Automatic, Fast and Lightweight Web Scraper for Python.
- [Spidey](https://github.com/Manzanit0/spidey) - Dead-simple crawler which focuses on ease of use and speed. Return a list of all URls of a web page.
- [Scraping News and Articles From Public APIs with Python (2020)](https://martinheinz.dev/blog/31)
- [LinkedIn Scraper](https://github.com/linkedtales/scrapedin)
- [ScrapeOwl](https://scrapeowl.com/) - Simple and affordable web scraping API.
- [Pholcidae](https://github.com/bbrodriges/pholcidae) - Tiny python web crawler.
- [Booking site web scraper](https://github.com/ZoranPandovski/BookingScraper) - Downloads all of the accommodations for the chosen country and saves them in a file.
- [Reddit Media Downloader](https://github.com/shadowmoose/RedditDownloader) - Scrapes Reddit to download media of your choice.
- [Web scraping with JS (2020)](https://qoob.cc/web-scraping/) ([HN](https://news.ycombinator.com/item?id=24898016))
- [Web scraping that just works with OpenFaaS with Puppeteer (2020)](https://www.openfaas.com/blog/puppeteer-scraping/)
- [What Happened to XPath? (2020)](https://webreflection.medium.com/what-happened-to-xpath-1409aa3dbd57) ([HN](https://news.ycombinator.com/item?id=24940676))
- [ScrapingHub](https://www.scrapinghub.com/) - Turn web content into useful data. ([GitHub](https://github.com/scrapinghub))
- [extruct](https://github.com/scrapinghub/extruct) - Library for extracting embedded metadata from HTML markup.
- [Introduction to Scraping in Python (2020)](https://itnext.io/introduction-to-scraping-in-python-with-beautifulsoup-and-requests-ab7b1c9bc113)
- [Test driving a HackerNews scraper with Node.js (2020)](https://cri.dev/posts/2020-11-06-Test-driving-a-HackerNews-scraper-with-Nodejs/)
- [SecretAgent](https://github.com/ulixee/secret-agent) - Web browser that's built for scraping. ([Web](https://secretagent.dev/))
- [Ulixee](https://ulixee.org/) - Turns every website into an open API. Access any dataset on the world wide web. ([GitHub](https://github.com/ulixee))
- [Floki](https://github.com/philss/floki) - Simple HTML parser that enables search for nodes using CSS selectors.
- [NYT Vote Scraper](https://github.com/alex/nyt-2020-election-scraper) - Scrapes the NYT Votes Remaining Page JSON and commits it back to this repo. Nice use of GitHub actions for git scraping.
- [Instagram Scraper](https://github.com/arc298/instagram-scraper) - Scrapes an instagram user's photos and videos.
- [Inventory Hunter](https://github.com/EricJMarti/inventory-hunter) - Get notified as soon as your next CPU, GPU, or game console is in stock.
- [Guide on preventing Website Scraping](https://github.com/JonasCz/How-To-Prevent-Scraping)
- [Bibliographies of the Bibliometric-enhanced Information Retrieval workshops and related other workshops](https://github.com/PhilippMayr/Bibliometric-enhanced-IR_Bibliography)
- [news-please](https://github.com/fhamborg/news-please) - Open source, easy-to-use news crawler that extracts structured information from almost any news website.
- [Web crawling with Python (2020)](https://www.scrapingbee.com/blog/crawling-python/)
- [Metascraper](https://github.com/microlinkhq/metascraper) - Scrape data from websites using Open Graph, HTML metadata & fallbacks. ([Docs](https://metascraper.js.org/#/))
- [Instaloader](https://github.com/instaloader/instaloader) - Download pictures (or videos) along with their captions and other metadata from Instagram. ([Docs](https://instaloader.github.io/))
- [trafilatura](https://github.com/adbar/trafilatura) - Manage URLs and scrape main text and metadata.
- [Go-Trafilatura](https://github.com/markusmobius/go-trafilatura) - Go package and command-line tool which seamlessly downloads, parses, and scrapes web page data.
- [htmldate](https://github.com/adbar/htmldate) - Find the publication date of web pages.
- [Filtering links to gather texts on the web (2020)](http://adrien.barbaresi.eu/blog/link-filtering-courlan-python.html)
- [Evaluating scraping and text extraction tools for Python (2020)](http://adrien.barbaresi.eu/blog/evaluating-text-extraction-python.html)
- [Using sitemaps to crawl websites (2019)](http://adrien.barbaresi.eu/blog/using-sitemaps-crawl-websites.html)
- [Evaluation of date extraction tools for Python (2020)](http://adrien.barbaresi.eu/blog/evaluation-date-extraction-python.html)
- [jusText](https://github.com/miso-belica/jusText) - Tool for removing boilerplate content, such as navigation links, headers, and footers from HTML pages.
- [sumy](https://github.com/miso-belica/sumy) - Module for automatic summarization of text documents and HTML pages.
- [Voyager](https://github.com/mattsse/voyager) - Write your own web crawler/scraper as a state machine in rust.
- [Trandoshan](https://github.com/creekorful/trandoshan) - Fast, highly configurable, cloud native dark web crawler.
- [ralger](https://github.com/feddelegrand7/ralger) - Makes it easy to scrape a website with R.
- [Scraping HN content with declarative programming](https://pathom3.wsscode.com/docs/tutorials/hacker-news-scraper/)
- [snscrape](https://github.com/JustAnotherArchivist/snscrape) - Social networking service scraper in Python. ([Fork](https://github.com/bellingcat/snscrape))
- [qwarc](https://github.com/JustAnotherArchivist/qwarc) - Framework for rapidly archiving a large number of URLs with little overhead.
- [select.rs](https://github.com/utkarshkukreti/select.rs) - Rust library to extract useful data from HTML documents, suitable for web scraping.
- [Scrapera](https://github.com/DarshanDeshpande/Scrapera) - Provides access to a variety of scraper scripts for most commonly used machine learning and data science domains.
- [Visual scraping with Elixir and Crawly (2021)](https://oltarasenko.medium.com/visual-scraping-with-elixir-and-crawly-or-how-to-get-data-without-programming-540222750135)
- [Headless Chrome Crawler](https://github.com/yujiosaka/headless-chrome-crawler) - Distributed crawler powered by Headless Chrome.
- [Tips for reliable web automation and scraping selectors (2021)](https://medium.com/brick-by-brick/7-bite-sized-tips-for-reliable-web-automation-and-scraping-selectors-2612bc4de2a1) ([HN](https://news.ycombinator.com/item?id=25993258))
- [Web Crawler for scraping Financial data](https://github.com/Skumarr53/Stock-Fundamental-data-scraping-and-analysis) ([Article](https://medium.com/datadriveninvestor/build-a-web-crawler-that-scrapes-stock-fundamentals-in-python-e2d4af56398))
- [Web Scraping 101 with Python (2021)](https://www.scrapingbee.com/blog/web-scraping-101-with-python/) ([HN](https://news.ycombinator.com/item?id=26090243)) ([HN](https://news.ycombinator.com/item?id=31387248))
- [Automatio](https://automatio.co/) - No-code Web Automation Tool. Automation Tool to Extract Data From Any Website.
- [Scaling up a Serverless Web Crawler and Search Engine (2021)](https://aws.amazon.com/blogs/architecture/scaling-up-a-serverless-web-crawler-and-search-engine/)
- [crawler-user-agents](https://github.com/monperrus/crawler-user-agents) - List of of HTTP user-agents used by robots, crawlers, and spiders as in single JSON file.
- [ant](https://github.com/yields/ant) - Web crawler for Go.
- [SearchScraperAPI](https://github.com/EdmundMartin/SearchScraperAPI) - Implementation of an API, which allows you to scrape Google, Bing, Yandex, and Qwant.
- [Scala Scraper](https://github.com/ruippeixotog/scala-scraper) - Scala library for scraping content from HTML pages.
- [Next.js Web Scraper Playground](https://github.com/johnpolacek/nextjs-scraper-playground) - Build and test your own web scraper APIs with Next.js API Routes and cheerio. ([Web](https://nextjs-scraper-playground.vercel.app/))
- [Scrapers List](https://github.com/cassidoo/scrapers)
- [Trafilatura](https://github.com/adbar/trafilatura) - Web scraping library and command-line tool for text discovery and extraction (main content, metadata, comments).
- [Rarchy](https://rarchy.com/) - Visual Sitemaps & Website Planning Tool. ([HN](https://news.ycombinator.com/item?id=27509682))
- [CloudProxy](https://github.com/claffin/cloudproxy) - Hide your scrapers IP behind the cloud. ([HN](https://news.ycombinator.com/item?id=27640217))
- [FlareSolverr](https://github.com/FlareSolverr/FlareSolverr) - Proxy server to bypass Cloudflare protection.
- [Schema API for the Semantic Web](https://schema.api.page/) - Extract structured content from the semantic web.
- [DataHen Till](https://github.com/DataHenHQ/till) - Standalone tool that runs alongside your web scraper, and instantly makes your existing web scraper scalable, maintainable and unblockable. ([Web](https://till.datahen.com/)) ([HN](https://news.ycombinator.com/item?id=28059291))
- [Mastering Web Scraping in Python: Crawling from Scratch (2021)](https://www.zenrows.com/blog/mastering-web-scraping-in-python-crawling-from-scratch) ([HN](https://news.ycombinator.com/item?id=28142002))
- [Data-Mining Wikipedia for Fun and Profit (2021)](https://billpg.com/data-mining-wikipedia/) ([HN](https://news.ycombinator.com/item?id=28234122))
- [Wikidata or Scraping Wikipedia](http://simia.net/wiki/Wikidata_or_scraping_Wikipedia) ([HN](https://news.ycombinator.com/item?id=28277749))
- [pyspider](https://github.com/binux/pyspider) - Powerful Spider (Web Crawler) System in Python. ([Docs](http://docs.pyspider.org/en/latest/))
- [Python-Goose](https://github.com/grangier/python-goose) - HTML Content / Article Extractor, web scrapping lib in Python.
- [Dyer](https://github.com/HomelyGuy/dyer) - Designed for reliable, flexible and fast web crawling, providing some high-level, comprehensive features without compromising speed.
- [How to Crawl the Web with Scrapy (2021)](https://www.babbling.fish/scraping-for-a-job/) ([HN](https://news.ycombinator.com/item?id=28514998))
- [PageMetaScraper](https://github.com/olerichter00/page-meta-scraper) - Page metadata scraper with several fallback strategies.
- [cariddi](https://github.com/edoardottt/cariddi) - Take a list of domains, crawl URLs and scan for endpoints, secrets, API keys, file extensions, tokens and more.
- [Super-Simple Scraper](https://github.com/gotripod/ssscraper) - Crawler/scraper based on Go + colly, configurable via JSON.
- [Gospider](https://github.com/jaeles-project/gospider) - Fast web spider written in Go.
- [The State Of Web Scraping in 2021](https://mihaisplace.blog/2021/10/03/the-state-of-web-scraping-in-2021/) ([HN](https://news.ycombinator.com/item?id=28827509))
- [trafilatura](https://github.com/adbar/trafilatura) - Web scraping tool for text discovery and retrieval.
- [scrapy.js](https://github.com/sijey-praveen/scrapy.js) - Web Scraping library for JavaScript built using BeautifulSoup4.
- [PHP Goose](https://github.com/scotteh/php-goose) - Readability / HTML Content / Article Extractor & Web Scrapping library written in PHP.
- [Web scraping by watching requests (2021)](https://en.jeffprod.com/blog/2021/web-scraping-by-watching-requests/)
- [Effortless Crawling with Scrapy with one method (2021)](https://www.youtube.com/watch?v=o1g8prnkuiQ)
- [Avoiding bot detection: How to scrape the web without getting blocked?](https://github.com/niespodd/browser-fingerprinting)
- [crawley](https://github.com/s0rg/crawley) - Crawls web pages and prints any link it can find.
- [grab-site](https://github.com/ArchiveTeam/grab-site) - Archivist's web crawler: WARC output, dashboard for all crawls, dynamic ignore patterns.
- [cloudscraper](https://github.com/VeNoMouS/cloudscraper) - Python module to bypass Cloudflare's anti-bot page.
- [Papercut](https://github.com/armand1m/papercut) - Scraping/crawling library for Node.js, written in Typescript.
- [Marple](https://github.com/soxoj/marple) - Collect links to profiles by username through search engines.
- [Web Scraping with Go (2021)](https://www.scrapingbee.com/blog/web-scraping-go/) ([Reddit](https://www.reddit.com/r/golang/comments/qw0io1/web_scraping_with_go/))
- [Maigret](https://github.com/soxoj/maigret) - Collect a dossier on a person by username from thousands of sites.
- [Notes on Writing Web Scrapers (2021)](https://cushychicken.github.io/rules-for-web-scrapers/)
- [Scraping Websites With Logins (2021)](https://blog.octachart.com/scraping-websites-that-require-login-in-python) ([Reddit](https://www.reddit.com/r/Python/comments/rck8bh/scraping_websites_that_require_login_in_python/))
- [Skan.jl](https://github.com/rikhuijzer/Skan.jl) - Scan web pages for changes using Julia & GitHub Actions.
- [cloudflare-scraper](https://github.com/JimmyLaurent/cloudflare-scraper) - Package to bypass Cloudflare's protection.
- [scrapy-poet](https://github.com/scrapinghub/scrapy-poet) - Page Object pattern for Scrapy.
- [Go Download Web](https://github.com/antsanchez/go-download-web) - Download an entire website with Go.
- [linkcheck](https://github.com/filiph/linkcheck) - Fast link checker.
- [scrapli](https://github.com/carlmontanari/scrapli) - Fast, flexible, sync/async, Python 3.6+ screen scraping client specifically for network devices.
- [scrapligo](https://github.com/scrapli/scrapligo) - scrapli, but in go.
- [waybacked](https://github.com/KarimPwnz/waybacked) - Get URLs from the Wayback Machine. Able to handle large outputs.
- [changedetection.io](https://github.com/dgtlmoon/changedetection.io) - Self-Hosted, Open Source, Change Monitoring of Web Pages.
- [Jiu](https://github.com/Xetera/jiu) - Detect new images and video on social media feeds and dispatch webhooks on updates.
- [Building a scalable scraper in Rust (2021)](https://xetera.dev/building-a-scalable-scraper/)
- [Instagram Scraper](https://github.com/gippy/instagram-scraper) - Allows you to scrape posts from a user's profile page, hashtag page, or place.
- [Scraping without JavaScript using Chromium on AWS Lambda: The Novel (2022)](https://blog.carlosnunez.me/post/scraping-chromium-lambda-nodeless-zerostress/)
- [The State of Web Scraping 2022](https://scrapeops.io/blog/the-state-of-web-scraping-2022/) ([HN](https://news.ycombinator.com/item?id=29905799))
- [Chrome File Downloader](https://github.com/rusq/chromedl) - Go library for scraping or downloading files bypassing Cloudflare protection and browser checks.
- [Mechaml](https://github.com/yannham/mechaml) - OCaml functional web scraping library.
- [WikiDump Indexer and Search](https://github.com/saiakarsh193/WikiDump-Indexer-and-Search) - Wikipedia dump parser and indexer with search functionality. Made for Information Retrieval and Extraction course.
- [Xidel](https://github.com/benibela/xidel) - Command line tool to download and extract data from HTML/XML pages or JSON-APIs, using CSS, XPath 3.0, XQuery 3.0, JSONiq or pattern matching.
- [web-poet](https://github.com/scrapinghub/web-poet) - Web scraping Page Objects core library.
- [Are Product Hunt's featured products still online today? (2022)](https://www.scrapingbee.com/blog/producthunt-cemetery/) ([HN](https://news.ycombinator.com/item?id=30274450))
- [html2data](https://github.com/msoap/html2data) - Library and cli for extracting data from HTML via CSS selectors.
- [Hyperlink](https://github.com/Munter/hyperlink) - Detect invalid and inefficient links on your webpages. Works with local files or websites, on the command line and as a node library.
- [requests-ip-rotator](https://github.com/Ge0rg3/requests-ip-rotator) - Python library to utilize AWS API Gateway's large IP pool as a proxy to generate pseudo-infinite IPs for web scraping and brute forcing.
- [Pinterest Web Scraper](https://github.com/SwatiModi/pinterest-web-scraper) - Scraping Visually Similar Images from Pinterest.
- [gazpacho](https://github.com/maxhumber/gazpacho) - Simple, fast, and modern web scraping library. ([Docs](https://gazpacho.xyz/))
- [Hitomi Downloader](https://github.com/KurtBestor/Hitomi-Downloader) - Desktop utility to download images/videos/music/text from various websites, and more.
- [Pinterest Downloader](https://github.com/limkokhole/pinterest-downloader) - Download all images/videos from Pinterest user/board/section.
- [More notes on writing web scrapers (2022)](https://cushychicken.github.io/more-web-scraper-notes/) ([HN](https://news.ycombinator.com/item?id=30466687))
- [scraperlite](https://github.com/danp/scraperlite) - Scrape text and HTML based on CSS selectors and save contents to a SQLite database.
- [Browsertrix Crawler](https://github.com/webrecorder/browsertrix-crawler) - Run a high-fidelity browser-based crawler in a single Docker container.
- [pafy](https://github.com/mps-youtube/pafy) - Python library to download YouTube content and retrieve metadata.
- [So you want to Scrape like the Big Boys? (2021)](https://incolumitas.com/2021/11/03/so-you-want-to-scrape-like-the-big-boys/)
- [Dude](https://github.com/roniemartinez/dude) - Simple framework for writing a web scraper using Python decorators.
- [myfaveTT](https://chrome.google.com/webstore/detail/myfavett-download-all-you/gmajiifkcmjkehmngbopoobeplhoegad) - Download all your TikTok Likes. ([HN](https://news.ycombinator.com/item?id=30685938))
- [Scraping web pages from the command line with shot-scraper (2022)](https://simonwillison.net/2022/Mar/14/scraping-web-pages-shot-scraper/) ([HN](https://news.ycombinator.com/item?id=30667588))
- [Apify SDK](https://github.com/apify/apify-ts) - Scalable web crawling and scraping library for JavaScript.
- [Extracting web page content using Readability.js and shot-scraper (2022)](https://til.simonwillison.net/shot-scraper/readability)
- [Texting Robots: Taming robots.txt with Rust and 34 million tests (2022)](https://state.smerity.com/smerity/state/01FZ3813Q79VTTVDHWHFA2A15E) ([Reddit](https://www.reddit.com/r/rust/comments/tqkmo5/texting_robots_taming_robotstxt_with_rust_and_34/))
- [Scraping Instagram (2022)](https://scrapingfish.com/blog/scraping-instagram) ([HN](https://news.ycombinator.com/item?id=30868738))
- [Linkedin Scraper](https://github.com/joeyism/linkedin_scraper) - Scrapes Linkedin User Data.
- [Aeon](https://github.com/leinelissen/aeon) - Scan the internet for your personal information and modify or remove it.
- [article-parser](https://github.com/ndaidong/article-parser) - Extract main article, main image and meta data from URL.
- [Apify SDK](https://github.com/apify/apify-js) - Scalable web crawling and scraping library for JavaScript.
- [WebParsy](https://github.com/joseconstela/webparsy) - Node.JS library and cli for scraping websites using Puppeteer (or not) and YAML definitions.
- [Hext](https://github.com/html-extract/hext) - Domain-specific language for extracting structured data from HTML documents.
- [AutoScrape](https://github.com/brandonrobertz/autoscrape-py) - Automated, programming-free web scraper for interactive sites.
- [Portia](https://github.com/scrapinghub/portia) - Tool that allows you to visually scrape websites without any programming knowledge required.
- [Surgeon](https://github.com/gajus/surgeon) - Declarative DOM extraction expression evaluator.
- [Ayakashi](https://github.com/ayakashi-io/ayakashi) - Next generation web scraping framework.
- [CCNet: Extracting High Quality Monolingual Datasets from Web Crawl Data (2019)](https://arxiv.org/abs/1911.00359) ([Code](https://github.com/facebookresearch/cc_net))
- [How To Use HTMLRewriter for Web Scraping (2022)](https://qwtel.com/posts/software/how-to-use-htmlrewriter-for-web-scraping/)
- [Brozzler](https://github.com/internetarchive/brozzler) - Distributed browser-based web crawler.
- [oEmbed Parser](https://github.com/ndaidong/oembed-parser) - Extract oEmbed data from given webpage.
- [Proxy scraper and checker](https://github.com/iw4p/proxy-scraper) - Scrape more than 1K HTTP proxies in less than 2 seconds.
- [Toutatis](https://github.com/megadose/toutatis) - Tool that allows you to extract information from instagrams accounts such as e-mails, phone numbers and more.
- [Crawl Original Google Images & Youtube Videos](https://github.com/thaoshibe/crawl-original-google-images)
- [OnlyFans DataScraper](https://github.com/DIGITALCRIMINAL/OnlyFans) - Scrape all the media from an OnlyFans account.
- [Shot Scraper Template](https://github.com/simonw/shot-scraper-template) - Quickly create a new GitHub repository that takes automated screenshots of a web page using shot-scraper.
- [Web Scraping via JavaScript Runtime Heap Snapshots (2022)](https://www.adriancooney.ie/blog/web-scraping-via-javascript-heap-snapshots) ([HN](https://news.ycombinator.com/item?id=31205139))
- [All the Places](https://github.com/alltheplaces/alltheplaces) - Set of spiders and scrapers to extract location information from places that post their location on the internet.
- [Spider](https://github.com/madeindjs/spider) - Multithreaded Web spider crawler written in Rust.
- [Scrapism 2022 course](https://github.com/antiboredom/scrapism-spring-2022)
- [Libextract](https://github.com/datalib/libextract) - Extract data from websites using basic statistical magic.
- [TikTok Scraper & Downloader](https://github.com/drawrowfly/tiktok-scraper) - Download video posts, collect user/trend/hashtag/music feed metadata, sign URL and etc.
- [Scraping Airbnb (2022)](https://scrapingfish.com/blog/scraping-airbnb)
- [Shears](https://github.com/Pingid/shears) - Functional web scraping in TS.
- [Web scraping with Python open knowledge](https://github.com/reanalytics-databoutique/webscraping-open-project) ([HN](https://news.ycombinator.com/item?id=31531694))
- [Web scraping Proxy Library for Scrapy](https://github.com/reanalytics-databoutique/advanced-scrapy-proxies) ([HN](https://news.ycombinator.com/item?id=31561409))
- [SLRP](https://github.com/nfx/slrp) - Rotating open proxy multiplexer.
- [Node.js web scraper](https://github.com/get-set-fetch/scraper)
- [WarcDB](https://github.com/Florents-Tselai/WarcDB) - Web crawl data as SQLite databases. ([HN](https://news.ycombinator.com/item?id=31799147))
- [How to scrape Zillow with Python and Scrapy (2022)](https://www.trickster.dev/post/how-to-scrape-zillow-with-python-and-scrapy/)
- [Scraply](https://github.com/alash3al/scraply) - Simple DOM scraper to fetch information from any HTML based website.
- [coURLan](https://github.com/adbar/courlan) - Clean, filter, normalize, and sample URLs.
- [htmldate](https://github.com/adbar/htmldate) - Find the publication date of web pages.
- [Wpull](https://github.com/ArchiveTeam/wpull) - Wget-compatible web downloader and crawler.
- [City Scrapers](https://github.com/City-Bureau/city-scrapers) - Scrape, standardize and share public meetings from local government websites.
- [Lambda Soup](https://github.com/aantron/lambdasoup) - Functional HTML scraping and rewriting with CSS in OCaml.
- [linkchecker](https://github.com/Jasstkn/link-checker) - Simple CLI tool to find all broken links in your website.
- [OSINT](https://github.com/sinwindie/OSINT) - Collections of tools and methods created to aid in OSINT collection.
- [Ask HN: What are the best tools for web scraping in 2022?](https://news.ycombinator.com/item?id=32409632)
