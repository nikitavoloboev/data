# Neural networks

## Notes

- Neural Networks are great identifying patterns in data. As a classic example, if you wanted to predict housing prices, you could build a data set that maps features about houses (square feet, location, proximity to Caltrain, etc) onto their actual price, and then train a network to recognize the complex relationship between features and pricing. Training happens by feeding the network features, letting it make a guess about the price, and then correcting the guess (backpropagation).
  - Convolutional Neural Networks work similarly, but with images. Instead of giving a CNN discrete features, you'll usually just use the pixels of the image itself. Through a series of layers, the CNN is able to build features itself (traditionally things like edges, corners) and learn patterns in image data. For example, a CNN might be trained on a dataset that maps images onto labels, and learn how to label new images on its own.

## Links

- [Neural Network from Scratch (Interactive)](https://aegeorge42.github.io/) ([HN](https://news.ycombinator.com/item?id=28806701))
- [But what is a Neural Network? | Deep learning, chapter 1 (2017)](https://www.youtube.com/watch?v=aircAruvnKk)
- [A Neural Network Playground](https://playground.tensorflow.org)
- [A Beginner's Guide To Understanding Convolutional Neural Networks](https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/)
- [Capsule Networks (CapsNets) – Tutorial](https://www.youtube.com/watch?v=pPN8d0E3900)
- [Chris Olah explains neural nets](https://www.youtube.com/watch?v=vdqu6fvjc5c)
- [How I Shipped a Neural Network on iOS with CoreML, PyTorch, and React Native](https://attardi.org/pytorch-and-coreml) - Detailed and awesome article.
- [Generative Adversarial Networks (GANs) in 50 lines of code (PyTorch)](https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f)
- [Neural Networks, Types, and Functional Programming](http://colah.github.io/posts/2015-09-NN-Types-FP/)
- [Recurrent Neural Networks lecture by Yoshua Bengio](http://videolectures.net/deeplearning2016_bengio_neural_networks/)
- [Practical Advice for Building Deep Neural Networks](https://pcc.cs.byu.edu/2017/10/02/practical-advice-for-building-deep-neural-networks/)
- [Differentiable Architecture Search](https://github.com/quark0/darts) - Code for [DARTS: Differentiable Architecture Search](https://arxiv.org/abs/1806.09055) paper.
- [TensorSpace.js](https://github.com/tensorspace-team/tensorspace) - Neural network 3D visualization framework, build interactive and intuitive model in browsers, support pre-trained deep learning models from TensorFlow, Keras, TensorFlow.js
- [UIS-RNN](https://github.com/google/uis-rnn) - Library for the Unbounded Interleaved-State Recurrent Neural Network (UIS-RNN) algorithm, corresponding to the paper Fully Supervised Speaker Diarization.
- [ONNX](https://github.com/onnx/onnx) - Open Neural Network Exchange. ([Scoring ONNX ML Models with Scala](https://www.youtube.com/watch?v=HyYpMJNVoVk))
- [DyNet](https://github.com/clab/dynet) - Dynamic Neural Network Toolkit.
- [gonn](https://github.com/sausheong/gonn) - Building a simple neural network in Go.
- [Neural Ordinary Differential Equations (2018)](https://arxiv.org/abs/1806.07366) - [Video explanation](https://www.youtube.com/watch?v=AD3K8j12EIE) | [Notes](https://github.com/llSourcell/Neural_Differential_Equations/blob/master/Neural_Ordinary_Differential_Equations.ipynb)
- [Neural Network framework in 25 LOC](https://gist.github.com/macournoyer/620a8ba4a2ecd6d6feaf)
- [Learning and Processing over Networks (2019)](https://github.com/rodrigo-pena/amld2019-graph-workshop) - Workshop presented by Michaël Defferrard and Rodrigo Pena at the Applied Machine Learning Days in January 2019.
- [The Next Generation of Neural Networks by Geoffrey Hinton (2007)](https://www.youtube.com/watch?v=AyzOUbkUf3M)
- [Who Invented Backpropagation? (2014)](http://people.idsia.ch/~juergen/who-invented-backpropagation.html)
- [Deep Learning in Neural Networks: An Overview (2015)](http://people.idsia.ch/~juergen/deep-learning-overview.html)
- [Neural Networks (E01: introduction) (2018)](https://www.youtube.com/watch?v=bVQUSndDllU) - This series is intended as a light introduction to neural networks, with a focus on the task of classifying handwritten digits.
- [Machine Learning for Beginners: An Introduction to Neural Networks (2019)](https://victorzhou.com/blog/intro-to-neural-networks/)
- [A Recipe for Training Neural Networks (2019)](https://karpathy.github.io/2019/04/25/recipe/)
- [Exploring Neural Networks with Activation Atlases (2019)](https://distill.pub/2019/activation-atlas/)
- [Curated list of neural architecture search and related resources](https://github.com/D-X-Y/Awesome-NAS)
- [Weight Agnostic Neural Networks (2019)](https://weightagnostic.github.io/) ([HN](https://news.ycombinator.com/item?id=20160693))
- [Geoffrey Hinton explains the evolution of neural networks (2019)](https://www.wired.com/story/ai-pioneer-explains-evolution-neural-networks/)
- [Evolved Turing neural networks](http://compucology.net/evolved)
- [Intelligent Machinery paper by Alan Turing](https://weightagnostic.github.io/papers/turing1948.pdf)
- [SRU](https://github.com/taolei87/sru) - Training RNNs as Fast as CNNs.
- [ODIN](https://github.com/facebookresearch/odin) - Out-of-Distribution Detector for Neural Networks.
- [Ask HN: What Neural Networks/Deep Learning Books Should I Read? (2019)](https://news.ycombinator.com/item?id=20674745)
- [Python vs Rust for Neural Networks (2019)](https://ngoldbaum.github.io/posts/python-vs-rust-nn/) ([HN](https://news.ycombinator.com/item?id=20728288))
- [Exploring Weight Agnostic Neural Networks (2019)](https://ai.googleblog.com/2019/08/exploring-weight-agnostic-neural.html) ([HN](https://news.ycombinator.com/item?id=20817083))
- [Neural Networks, Types, and Functional Programming (2015)](https://colah.github.io/posts/2015-09-NN-Types-FP/)
- [Glow](https://github.com/pytorch/glow) - Compiler for Neural Network hardware accelerators.
- [Go Neural Net Sandbox](https://github.com/lightvector/GoNN) - Sandbox for personal experimentation in Go neural net training and Go AI.
- [layer](https://github.com/cloudkj/layer) - Neural network inference the Unix way.
- [XNNPACK](https://github.com/google/XNNPACK) - Highly optimized library of floating-point neural network inference operators for ARM, WebAssembly, and x86 (SSE2 level) platforms.
- [LSTM implementation explained (2015)](http://apaszke.github.io/lstm-explained.html)
- [The Neural Process Family](https://github.com/deepmind/neural-processes) - Contains notebook implementations of the following Neural Process variants: Conditional Neural Processes (CNPs), Neural Processes (NPs), Attentive Neural Processes (ANPs).
- [Notes on Neural Nets](https://wiki.kourouklides.com/wiki/Artificial_Neural_Network)
- [RNNoise](https://github.com/xiph/rnnoise) - Recurrent neural network for audio noise reduction.
- [Hacking Neural Networks](https://github.com/Kayzaks/HackingNeuralNetworks) - Short introduction on methods that use neural networks in an offensive manner.
- [Distilling knowledge from Neural Networks to build smaller and faster models (2019)](https://blog.floydhub.com/knowledge-distillation/)
- [Neural Network Processing Neural Networks: An efficient way to learn higher order functions (2019)](https://arxiv.org/abs/1911.05640)
- [Building a neural net from scratch in Go (2017)](https://datadan.io/neural-net-with-go)
- [SparseConvNet](https://github.com/btgraham/SparseConvNet) - Spatially-sparse convolutional neural network.
- [Norse](https://github.com/electronicvisions/norse) - Library to do deep learning with spiking neural networks.
- [Tensor Programs I: Wide Feedforward or Recurrent Neural Networks of Any Architecture are Gaussian Processes (2019)](https://arxiv.org/abs/1910.12478) ([Code](https://github.com/thegregyang/GP4A))
- [Single Headed Attention RNN: Stop Thinking With Your Head (2019)](https://arxiv.org/abs/1911.11423) ([HN](https://news.ycombinator.com/item?id=21647804))
- [Visualizing the Loss Landscape of Neural Nets](https://github.com/tomgoldstein/loss-landscape)
- [primitiv](https://github.com/primitiv/primitiv) - Neural Network Toolkit.
- [On the Relationship between Self-Attention and Convolutional Layers (2019)](https://openreview.net/forum?id=HJlnC1rKPB) ([Code](https://github.com/epfml/attention-cnn)) ([Reddit](https://www.reddit.com/r/MachineLearning/comments/en2ywu/r_on_the_relationship_between_selfattention_and/))
- [Implementation of a deep learning library in Futhark](https://futhark-lang.org/student-projects/duc-bsc-thesis.pdf)
- [Single Headed Attention RNN: Stop Thinking With Your Head (2019)](https://arxiv.org/abs/1911.11423)
- [Using neural networks to solve advanced mathematics equations (2020)](https://ai.facebook.com/blog/using-neural-networks-to-solve-advanced-mathematics-equations/)
- [AlphaFold](https://github.com/deepmind/deepmind-research/tree/master/alphafold_casp13) - Provides an implementation of the contact prediction network, associated model weights and CASP13 dataset as published in Nature. ([Paper](https://www.nature.com/articles/s41586-019-1923-7))
- [Go Perceptron](https://github.com/made2591/go-perceptron-go) - Single / multi layer / recurrent neural network written in Golang.
- [Temperature Scaling](https://github.com/gpleiss/temperature_scaling) - Simple way to calibrate your neural network.
- [Recurrent Geometric Networks for end-to-end differentiable learning of protein structure](https://github.com/aqlaboratory/rgn)
- [FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence (2020)](https://arxiv.org/abs/2001.07685) ([Tweet](https://twitter.com/D_Berthelot_ML/status/1219823580654948353))
- [kapre](https://github.com/keunwoochoi/kapre) - Keras Audio Preprocessors.
- [Putting An End to End-to-End: Gradient-Isolated Learning of Representations (2019)](https://arxiv.org/pdf/1905.11786.pdf)
- [Memory-Augmented Neural Networks for Machine Translation (2019)](https://arxiv.org/abs/1909.08314)
- [Have there been any important developments on content addressable memory since hopfield network? (neural networkish) (2020)](https://www.reddit.com/r/MachineLearning/comments/esrroh/d_have_there_been_any_important_developments_on/)
- [G-Bert](https://github.com/jshang123/G-Bert) - Pre-training of Graph Augmented Transformers for Medication Recommendation.
- [Two strange useless things to do with neural nets: a demonstration](https://github.com/howonlee/twostrangethings)
- [Understanding the Neural Tangent Kernel (2019)](https://rajatvd.github.io/NTK/)
- [Cutting out the Middle-Man: Training and Evaluating Energy-Based Models without Sampling](https://arxiv.org/abs/2002.05616) ([Tweet](https://twitter.com/wgrathwohl/status/1228144635010322440))
- [Haiku](https://github.com/deepmind/haiku) - JAX-based neural network library.
- [Convolution in one dimension for neural networks (2020)](https://e2eml.school/convolution_one_d.html)
- [Lucid](https://github.com/tensorflow/lucid) - Collection of infrastructure and tools for research in neural network interpretability.
- [Minkowski Engine](https://github.com/NVIDIA/MinkowskiEngine) - Auto-diff neural network library for high-dimensional sparse tensors.
- [Generating MIDI melody from lyrics using LSTM-GANs](https://github.com/yy1lab/Lyrics-Conditioned-Neural-Melody-Generation) ([HN](https://news.ycombinator.com/item?id=22524176))
- [Zoom In: An Introduction to Circuits (2020)](https://distill.pub/2020/circuits/zoom-in/)
- [Lagrangian Neural Networks (2020)](https://greydanus.github.io/2020/03/10/lagrangian-nns/) ([HN](https://news.ycombinator.com/item?id=22552790))
- [Neural Tangents](https://github.com/google/neural-tangents) - Fast and Easy Infinite Neural Networks in Python.
- [A Survey of Long-Term Context in Transformers (2020)](https://www.pragmatic.ml/a-survey-of-methods-for-incorporating-long-term-context/)
- [OpenNMT-py](https://github.com/OpenNMT/OpenNMT-py) - Open Source Neural Machine Translation in PyTorch.
- [Deep Learning for Symbolic Mathematics (2019)](https://github.com/facebookresearch/SymbolicMathematics) ([Paper](https://arxiv.org/pdf/1912.01412.pdf))
- [Google Brain AutoML](https://github.com/google/automl)
- [Physics Informed Neural Networks](https://github.com/maziarraissi/PINNs) - Data-driven Solutions and Discovery of Nonlinear Partial Differential Equations.
- [An introduction to Bayesian neural networks (2020)](https://papercup.dev/posts/bayesian-neural-nets/)
- [PyTorch Neural Turing Machine](https://github.com/loudinthecloud/pytorch-ntm)
- [PyTorch Neural Turing Machine 2](https://github.com/vlgiitr/ntm-pytorch)
- [Learning DAGs with Continuous Optimization (2020)](https://blog.ml.cmu.edu/2020/04/10/learning-dags-with-continuous-optimization/)
- [Early Vision (2020)](https://distill.pub/2020/circuits/early-vision/) - Guided tour of the first five layers of InceptionV1, taxonomized into “neuron groups.”.
- [micrograd](https://github.com/karpathy/micrograd) - Tiny autograd engine and a neural net library on top of it, potentially for educational purposes.
- [MiniGrad](https://github.com/kennysong/minigrad) - Minimal implementation of reverse-mode automatic differentiation (a.k.a. autograd / backpropagation) in pure Python.
- [Learning from Small Neural Networks (2020)](https://medium.com/make-computer-science-fun-again/learning-from-small-neural-networks-6bc5ffc2f3d3)
- [Neural Game Engine](https://github.com/Bam4d/Neural-Game-Engine) - Code to reproduce Neural Game Engine experiments and pre-trained models.
- [Graph Convolutional Neural Network Approach to Antibiotic Discovery (2020)](https://www.welcometothejungle.com/en/articles/btc-covid19-convolutional-neural-network) ([HN](https://news.ycombinator.com/item?id=22898551))
- [KPNNs](https://github.com/epigen/KPNN) - Knowledge-primed neural networks.
- [ResNeSt](https://github.com/zhanghang1989/ResNeSt) - Split-Attention Network.
- [Shortcut Learning in Deep Neural Networks (2020)](https://github.com/rgeirhos/shortcut-perspective)
- [Discourse-Aware Attention Model for Abstractive Summarization of Long Documents](https://github.com/armancohan/long-summarization)
- [Perovskite neural trees (2020)](https://www.nature.com/articles/s41467-020-16105-y) ([HN](https://news.ycombinator.com/item?id=23107722))
- [RigNet: Neural Rigging for Articulated Characters (2020)](https://zhan-xu.github.io/rig-net/) ([Reddit](https://www.reddit.com/r/MachineLearning/comments/ggakn3/r_rignet_neural_rigging_for_articulated_characters/))
- [Convolutional neural networks for artistic style transfer (2017)](https://harishnarayanan.org/writing/artistic-style-transfer/)
- [Certifiable Robustness to adversarial Attacks; What is the Point? | Nick Frosst (2020)](https://www.youtube.com/watch?v=OfSxYqU-6s0)
- [LAG: Latent Adversarial Generator](https://github.com/google-research/lag)
- [Towards improved generalization in few-shot classification (2019)](https://tmramalho.github.io/science/2019/12/07/towards-improved-generalization-in-few-shot-classification/)
- [Convolutional Neural Networks in One Dimension](https://end-to-end-machine-learning.teachable.com/p/321-convolutional-neural-networks)
- [Neural Network Pruning (2020)](https://nathanhubens.github.io/posts/deep%20learning/2020/05/22/pruning.html)
- [Hyperbolic RNN in PyTorch](https://github.com/ferrine/hyrnn)
- [deeplearn-rs](https://github.com/tedsta/deeplearn-rs) - Deep learning in Rust.
- [Neural networks trained to communicate with each other without any training data](https://twitter.com/noahtren/status/1269035375051386880)
- [Classical Piano Composer](https://github.com/Skuldur/Classical-Piano-Composer) - Allows you to train a neural network to generate midi music files that make use of a single instrument.
- [Weight Standardization](https://github.com/joe-siyuan-qiao/WeightStandardization) - Normalization method to accelerate micro-batch training.
- [Teaching Machines to Draw (2017)](https://blog.otoro.net/2017/05/19/teaching-machines-to-draw/) ([In action](https://otoro.net/sketch-rnn/))
- [Benchmarking Neural Network Robustness to Common Corruptions and Perturbations](https://github.com/hendrycks/robustness)
- [pix2code](https://github.com/tonybeltramelli/pix2code) - Generating Code from a Graphical User Interface Screenshot.
- [Gated Linear Networks (2019)](https://arxiv.org/abs/1910.01526) ([HN](https://news.ycombinator.com/item?id=23528247))
- [Curve Detectors (2020)](https://distill.pub/2020/circuits/curve-detectors/)
- [Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains](https://github.com/tancik/fourier-feature-networks)
- [Neural Networks and Deep Learning](https://www.notion.so/Neural-Networks-and-Deep-Learning-f7ff3bae25de4f0085fd52fc8e810827) - What they are and how they work.
- [Teaching physics to neural networks removes 'chaos blindness' (2020)](https://phys.org/news/2020-06-physics-neural-networks-chaos.html) ([HN](https://news.ycombinator.com/item?id=23597426))
- [Understanding Convolutional Neural Networks](https://poloclub.github.io/cnn-explainer/) ([Code](https://github.com/poloclub/cnn-explainer)) ([HN](https://news.ycombinator.com/item?id=23710799))
- [Business Card Neural Network (2020)](https://imois.in/posts/card-network/)
- [Functional Neural Networks (2020)](https://b-thi.github.io/Posts/FNNs.html)
- [Attention Is All You Need (2017)](https://www.youtube.com/watch?v=iDulhoQ2pro)
- [Getting Artificial Neural Networks Closer to Animal Brains (2020)](https://maraoz.com/2020/07/12/brains-vs-anns/)
- [Foolbox Native](https://github.com/bethgelab/foolbox) - Python toolbox to create adversarial examples that fool neural networks in PyTorch, TensorFlow, and JAX.
- [Genann](https://github.com/codeplea/genann) - Minimal, well-tested library for training and using feedforward artificial neural networks (ANN) in C.
- [High-Frequency Component Helps Explain the Generalization of Convolutional Neural Networks (2020)](https://blog.ml.cmu.edu/2020/08/14/high-frequency-component-helps-explain-the-generalization-of-convolutional-neural-networks/)
- [Awesome Pruning](https://github.com/he-y/Awesome-Pruning) - Curated list of neural network pruning resources.
- [Hopfield Networks is All You Need (2020)](https://arxiv.org/abs/2008.02217) ([Code](https://github.com/ml-jku/hopfield-layers)) ([Article](https://ml-jku.github.io/hopfield-layers/)) ([HN](https://news.ycombinator.com/item?id=26990000))
- [Sparse Networks from Scratch: Faster Training without Losing Performance (2019)](https://timdettmers.com/2019/07/11/sparse-networks-from-scratch/)
- [Jigsaw Labs - Learn Neural Nets](https://www.jigsawlabs.io/#neural_nets)
- [Implementing a Neural Network in C](https://www.cs.bham.ac.uk/~jxb/INC/nn.html) ([Code](https://github.com/mathmagson/neuralnetwork))
- [Web Neural Network API](https://webmachinelearning.github.io/webnn/) - Dedicated low-level API for neural network inference hardware acceleration. [Polyfill](https://github.com/webmachinelearning/webnn-polyfill)
- [Clarifying exceptions and visualizing tensor operations in deep learning code (2020)](https://explained.ai/tensor-sensor/index.html)
- [Tensor Sensor](https://github.com/parrt/tensor-sensor) - Generate more helpful exception messages for numpy/pytorch matrix algebra expressions. ([Tweet](https://twitter.com/jeremyphoward/status/1313584515206451200))
- [Explaining RNNs without neural networks (2020)](https://explained.ai/rnn/index.html)
- [A visual explanation for regularization of linear models (2020)](https://explained.ai/regularization/index.html)
- [A Guide to Deep Learning and Neural Networks (2020)](https://serokell.io/blog/deep-learning-and-neural-network-guide)
- [Handwriting Synthesis](https://github.com/sjvasquez/handwriting-synthesis) - Handwriting Synthesis with RNNs.
- [How DeepMind learns physics simulators with Graph Networks (w/ author interview) (2020)](https://www.youtube.com/watch?v=JSed7OBasXs)
- [Build Your Own Artificial Neural Network. It’s Easy! (2020)](http://nautil.us//blog/build-your-own-artificial-neural-network-its-easy)
- [Neural Circuit Policies Enabling Auditable Autonomy](https://github.com/mlech26l/keras-ncp)
- [FermiNet: Fermionic Neural Networks](https://github.com/deepmind/ferminet) ([Quantum Physics and Chemistry from First Principles (2020)](https://deepmind.com/blog/article/FermiNet)) ([Tweet](https://twitter.com/deepmind/status/1318257586983096320))
- [What is the Role of a Neuron?](https://github.com/davidbau/dissect)
- [Marabou](https://github.com/NeuralNetworkVerification/Marabou) - SMT-based tool that can answer queries about a network’s properties by transforming these queries into constraint satisfaction problems.
- [Demonstration of the attention mechanism with some toy experiments and explanations](https://github.com/greentfrapp/attention-primer)
- [Augerino](https://github.com/g-benton/learning-invariances) - Codebase for Learning Invariances in Neural Networks.
- [ELI5](https://github.com/TeamHG-Memex/eli5) - Python package which helps to debug machine learning classifiers and explain their predictions.
- [Cream of the Crop: Distilling Prioritized Paths For One-Shot Neural Architecture Search](https://github.com/microsoft/Cream)
- [Brian2](https://github.com/brian-team/brian2) - Free, open source simulator for spiking neural networks. ([Web](https://briansimulator.org/))
- [Neural Networks from Scratch in Python](https://nnfs.io/)
- [Naszilla](https://github.com/naszilla/naszilla) - Python library for neural architecture search (NAS).
- [The Unreasonable Syntactic Expressivity of RNNs (2020)](https://nlp.stanford.edu/~johnhew/rnns-hierarchy.html)
- [DeepMath Conference](https://deepmath-conference.com/) - Conference on the Mathematical Theory of DNN's. ([HN](https://news.ycombinator.com/item?id=25015941))
- [Coding a Neural Network: A Beginner's Guide (2020)](https://www.youtube.com/watch?v=TIEKzVwS12g)
- [Eiffel2](https://github.com/Ale9806/Eiffel2) - Neural Network architecture Visualization tool.
- [Graph Convolutional Neural Networks (GCNN) models](https://github.com/google/gcnn-survey-paper)
- [Elegy](https://github.com/poets-ai/elegy) - Neural Networks framework based on Jax inspired by Keras and Haiku.
- [SpinalNet](https://github.com/dipuk0506/SpinalNet) - Deep Neural Network with Gradual Input.
- [Deeply-supervised Nets](https://github.com/s9xie/DSN)
- [diagNNose](https://github.com/i-machine-think/diagNNose) - Python library that facilitates a broad set of tools for analysing hidden activations of neural models.
- [MiniSom](https://github.com/JustGlowing/minisom) - Minimalistic implementation of the Self Organizing Maps.
- [Basics of Convolution (2020)](https://ashwinsharma.tech/basics-of-convolution)
- [DeepGCNs: Can GCNs Go as Deep as CNNs?](https://github.com/lightaime/deep_gcns_torch)
- [Tinn](https://github.com/glouw/tinn) - 200 line dependency free neural network library written in C99.
- [musicnn](https://github.com/jordipons/musicnn) - Set of pre-trained musically motivated convolutional neural networks for music audio tagging.
- [Convolution Is Fancy Multiplication](https://betterexplained.com/articles/intuitive-convolution/) ([HN](https://news.ycombinator.com/item?id=25190770))
- [Tools to Design or Visualize Architecture of Neural Network](https://github.com/ashishpatel26/Tools-to-Design-or-Visualize-Architecture-of-Neural-Network)
- [ENNUI](https://math.mit.edu/ennui/) - Elegant Neural Network User Interface. ([Code](https://github.com/martinjm97/ENNUI))
- [Dynamic Graph CNN for Learning on Point Clouds](https://github.com/WangYueFt/dgcnn)
- [robustness](https://github.com/MadryLab/robustness) - Library for experimenting with, training and evaluating neural networks, with a focus on adversarial robustness.
- [JAX, M.D.](https://github.com/google/jax-md) - Accelerated, Differentiable, Molecular Dynamics. ([Paper](https://arxiv.org/abs/1912.04232))
- [Neural Reverse Engineering of Stripped Binaries using Augmented Control Flow Graphs](https://github.com/tech-srl/Nero)
- [NN SVG](https://alexlenail.me/NN-SVG/AlexNet.html) - Generate publication-ready NN-architecture schematics. ([HN](https://news.ycombinator.com/item?id=25272360))
- [e3nn](https://github.com/e3nn/e3nn) - Modular framework for neural networks with Euclidean symmetry.
- [Delve](https://github.com/delve-team/delve) - Python package for visualizing deep learning model training.
- [Graph Mining @ NeurIPS 2020](https://gm-neurips-2020.github.io/) ([Talks](https://www.youtube.com/playlist?list=PLY5kjoYG4AfHQWhYB7cNS5X2QlMg5WIpV))
- [jax_verify](https://github.com/deepmind/jax_verify) - Neural network verification in JAX.
- [Self-supervised learning through the eyes of a child (2020)](https://arxiv.org/abs/2007.16189) ([Code](https://github.com/eminorhan/baby-vision))
- [Object-based attention for spatio-temporal reasoning: Outperforming neuro-symbolic models with flexible distributed architectures (2020)](https://arxiv.org/pdf/2012.08508.pdf)
- [Soft Threshold Weight Reparameterization for Learnable Sparsity (2020)](https://arxiv.org/abs/2002.03231) ([Code](https://github.com/RAIVNLab/STR))
- [Understanding the Difficulty of Training Transformers (2020)](https://arxiv.org/abs/2004.08249) ([Code](https://github.com/LiyuanLucasLiu/Transformer-Clinic))
- [Awesome Implicit Neural Models](https://github.com/massastrello/awesome-implicit-neural-models)
- [Edit-distance as objective function papers](https://github.com/1ytic/edit-distance-papers) - Curated list of papers dedicated to edit-distance as objective function.
- [SuPar](https://github.com/yzhangcs/parser) - Collection of state-of-the-art models for Dependency Parsing, Constituency Parsing and Semantic Dependency Parsing.
- [Drawing early-bird tickets: Towards more efficient training of deep networks (2020)](https://arxiv.org/abs/1909.11957) ([Code](https://github.com/RICE-EIC/Early-Bird-Tickets))
- [CountNet: Speaker Count Estimation using Deep Neural Networks](https://github.com/faroit/CountNet)
- [Applications of Deep Neural Networks Course (2021)](https://sites.wustl.edu/jeffheaton/t81-558/) ([Code](https://github.com/jeffheaton/t81_558_deep_learning))
- [DDSL: Deep Differential Simplex Layer for Neural Networks](https://github.com/maxjiang93/DDSL)
- [Making sense of sensory input (2021)](https://www.sciencedirect.com/science/article/pii/S0004370220301855)
- [char-rnn](https://github.com/karpathy/char-rnn) - Multi-layer Recurrent Neural Networks (LSTM, GRU, RNN) for character-level language models in Torch.
- [Awesome Equivariant Networks](https://github.com/Chen-Cai-OSU/awesome-equivariant-network)
- [Named Tensor Notation](https://namedtensor.github.io/) ([Code](https://github.com/namedtensor/notation))
- [Applications of Deep Neural Networks v2 (2020)](https://arxiv.org/abs/2009.05673) ([HN](https://news.ycombinator.com/item?id=25898628))
- [Make Your Own Neural Network Blog](https://makeyourownneuralnetwork.blogspot.com/)
- [Make Your Own Neural Network Book](https://www.amazon.com/Make-Your-Own-Neural-Network/dp/1530826608/) ([Code](https://github.com/makeyourownneuralnetwork/makeyourownneuralnetwork))
- [Representation Learning for Attributed Multiplex Heterogeneous Network (2019)](https://arxiv.org/abs/1905.01669) ([Code](https://github.com/THUDM/GATNE))
- [Awesome VAEs](https://github.com/matthewvowels1/Awesome-VAEs) - Curated list of awesome work on VAEs, disentanglement, representation learning, and generative models.
- [Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting (2020)](https://arxiv.org/abs/2012.07436) ([Code](https://github.com/zhouhaoyi/Informer2020))
- [Training Neural Networks is ER-complete (2021)](https://arxiv.org/abs/2102.09798)
- [Geoff Hinton 2021 – How to represent part-whole hierarchies in a neural network](https://arxiv.org/abs/2102.12627) ([HN](https://news.ycombinator.com/item?id=26270668))
- [Neural Network Matrix Visualization (2021)](https://iism.org/article/neural-network-matrix-visualization-61)
- [Multimodal Neurons in Artificial Neural Networks (2021)](https://openai.com/blog/multimodal-neurons/) ([HN](https://news.ycombinator.com/item?id=26347613)) ([Code](https://github.com/openai/CLIP-featurevis))
- [OpenAI Microscope](https://microscope-azure-edge.openai.com/models) - Collection of visualizations of every significant layer and neuron of several common “model organisms” which are often studied in interpretability.
- [Real time Interactive Visualization of Convolutional Neural Networks in Unity](https://vimeo.com/274236414)
- [Techniques for Reducing Overfitting (2021)](https://www.youtube.com/watch?v=KOBmBjlMVAE) ([Tweet](https://twitter.com/rasbt/status/1369045968738476035))
- [Accelerating Neural Networks on Mobile and Web with Sparse Inference (2021)](https://ai.googleblog.com/2021/03/accelerating-neural-networks-on-mobile.html)
- [Quantization for Neural Networks (2020)](https://leimao.github.io/article/Neural-Networks-Quantization/)
- [Introduction to Automatic Hyperparameter Tuning](https://www.neuraxle.org/stable/hyperparameter_tuning.html)
- [Neural Networks Block Movement Pruning](https://github.com/huggingface/nn_pruning)
- [Torch-Dreams](https://github.com/Mayukhdeb/torch-dreams) - Making neural networks more interpretable, for research and art.
- [Are Deep Neural Networks Dramatically Overfitted? (2019)](https://lilianweng.github.io/lil-log/2019/03/14/are-deep-neural-networks-dramatically-overfitted.html) ([HN](https://news.ycombinator.com/item?id=26695976))
- [NASLib](https://github.com/automl/NASLib) - Neural Architecture Search (NAS) library for facilitating NAS research for the community by providing interfaces to several state-of-the-art NAS search spaces and optimizers.
- [Neural Network Visualization](https://github.com/julrog/nn_vis) - Visualization of neural network architectures and parameters.
- [Restricted Boltzmann Machine in Haskell](https://github.com/aeyakovenko/rbm)
- [X-Transformers](https://github.com/lucidrains/x-transformers) - Simple but complete full-attention transformer with a set of promising experimental features from various papers. ([HN](https://news.ycombinator.com/item?id=27089208))
- [Introduction to Attention Mechanism (2021)](https://erdem.pl/2021/05/introduction-to-attention-mechanism)
- [Understanding Positional Encoding in Transformers (2021)](https://erdem.pl/2021/05/understanding-positional-encoding-in-transformers)
- [Measuring XAI methods with Infidelity and Sensitivity (2021)](https://erdem.pl/2021/03/measuring-xai-methods-with-infidelity-and-sensitivity)
- [Quasi-Recurrent Neural Networks (2016)](https://arxiv.org/abs/1611.01576) ([Code](https://github.com/salesforce/pytorch-qrnn))
- [deepdream.c](https://github.com/znah/deepdream_c) - Experiment trying to implement Convolutional Neural Network inference and back-propagation using a minimal subset of C89 language and standard library features.
- [Adapting Neural Networks for the Estimation of Treatment Effects (2018)](https://arxiv.org/abs/1906.02120) ([Code](https://github.com/claudiashi57/dragonnet))
- [Constructions in combinatorics via neural networks (2021)](https://arxiv.org/abs/2104.14516) ([Code](https://github.com/zawagner22/cross-entropy-for-combinatorics))
- [Artificial Neural Nets Finally Yield Clues to How Brains Learn (2021)](https://overcast.fm/+JGHe8QPBw)
- [Neural Additive Models: Interpretable Machine Learning with Neural Nets (2020)](https://arxiv.org/abs/2004.13912) ([Code](https://github.com/rish-16/nam-pytorch))
- [Neural-Backed Decision Trees](https://research.alvinwan.com/neural-backed-decision-trees/) ([Code](https://github.com/alvinwan/neural-backed-decision-trees))
- [Introduction to Neural Network Verification Book](https://verifieddeeplearning.com/)
- [ERAN](https://github.com/eth-sri/eran) - ETH Robustness Analyzer for Deep Neural Networks.
- [What are Transformer Neural Networks? (2021)](https://www.youtube.com/watch?v=XSSTuhyAmnI)
- [Thinking Like Transformers (2021)](https://arxiv.org/abs/2106.06981) ([HN](https://news.ycombinator.com/item?id=27528004))
- [TIL: Convolutional Filters Are Weights (2017)](https://jeiwan.net/posts/til-convolution-filters-are-weights/)
- [Solving Mixed Integer Programs Using Neural Networks (2020)](https://arxiv.org/abs/2012.13349) ([Tweet](https://twitter.com/DeepMind/status/1419642398553120772))
- [What Are Convolutional Neural Networks? (2021)](https://serokell.io/blog/introduction-to-convolutional-neural-networks)
- [Fooling Neural Networks](https://slazebni.cs.illinois.edu/fall18/lec12_adversarial.pdf) ([HN](https://news.ycombinator.com/item?id=28085512))
- [Introduction to Neural Network Verification (2021)](https://arxiv.org/abs/2109.10317)
- [Explainable neural networks that simulate reasoning (2021)](https://www.nature.com/articles/s43588-021-00132-w)
- [Evolving Neural Networks through Augmenting Topologies](http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf) ([Code](https://github.com/suhdonghwi/neat))
- [Minimal, clean example of lstm neural network training in python, for learning purposes](https://github.com/nicodjimenez/lstm)
- [What nice mathematical results there are about neural networks? (2021)](https://www.reddit.com/r/MachineLearning/comments/q072ov/d_what_nice_mathematical_results_there_are_about/)
- [Temporal and Object Quantification Networks (2021)](http://toqnet.csail.mit.edu/) ([Code](https://github.com/C-SUNSHINE/TOQ-Nets-PyTorch-Release))
- [Encoding Events for Neural Networks (2021)](https://theorangeduck.com/page/encoding-events-neural-networks)
- [Telestrations Neural Networks (2020)](https://danielegrattarola.github.io/posts/2020-01-21/telestrations.html)
- [NN-SVG](https://github.com/alexlenail/NN-SVG) - Publication-ready NN-architecture schematics. ([Web](http://alexlenail.me/NN-SVG/))
- [Scientists built deep neural networks that can map between infinite dimensional spaces (2021)](https://www.quantamagazine.org/latest-neural-nets-solve-worlds-hardest-equations-faster-than-ever-before-20210419)
- [CNN Explainer - Interpreting Convolutional Neural Networks (2021)](https://gsurma.medium.com/cnn-explainer-interpreting-convolutional-neural-networks-1-n-e81c62cbb660)
- [Transformers from Scratch (2019)](http://peterbloem.nl/blog/transformers)
- [Transformers from Scratch (2021)](https://e2eml.school/transformers.html) ([HN](https://news.ycombinator.com/item?id=29315107))
- [General and Scalable Parallelization for Neural Networks (2021)](https://ai.googleblog.com/2021/12/general-and-scalable-parallelization.html)
- [8 Types of Activation Functions in Neural Networks (2021)](https://thehackweekly.com/8-most-popular-types-of-activation-functions-in-neural-networks/)
- [Building a Neural Network in Go (2021)](https://ataylor.io/blog/go-mlp/)
- [Echo State Networks in Python](https://github.com/cknd/pyESN)
- [Neural Networks for Inference, Inference for Neural Networks (2019)](https://github.com/stefanwebb/dphil-thesis-final/blob/master/main.pdf)
- [Let's Play Distill: Building Blocks (2019)](https://www.youtube.com/watch?v=h6vLETyCzPo) ([Tweet](https://twitter.com/nickcammarata/status/1476774347767386115))
- [Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer (2017)](https://arxiv.org/abs/1701.06538) ([Code](https://github.com/davidmrau/mixture-of-experts))
- [Neural Network From Scratch (2022)](https://sirupsen.com/napkin/neural-net) ([HN](https://news.ycombinator.com/item?id=29796789))
- [Noether’s Theorem, Symmetries, and Invariant Neural Networks](https://fabianfuchsml.github.io/noether/)
- [CNNs and Equivariance - Part 1/2](https://fabianfuchsml.github.io/equivariance1of2/)
- [Building a Neural Network in Pure Lisp without Built-in Numbers using only Atoms and Lists (2022)](https://woodrush.github.io/blog/posts/2022-01-16-neural-networks-in-pure-lisp.html)
- [Neural Methods in Simulation-Based Inference (2022)](https://willwolf.io/2022/01/04/neural-methods-in-sbi/)
- [Avoiding Catastrophe: Active Dendrites Enable Multi-Task Learning in Dynamic Environments (2021)](https://arxiv.org/abs/2201.00042)
- [Computer scientists prove why bigger neural networks do better (2022)](https://www.quantamagazine.org/computer-scientists-prove-why-bigger-neural-networks-do-better-20220210/) ([HN](https://news.ycombinator.com/item?id=30288092))
- [On the Difficulty of Extrapolation with NN Scaling (2022)](http://lukemetz.com/difficulty-of-extrapolation-nn-scaling/)
- [Depth Estimation by Convolutional Neural Networks (2016)](https://www.fit.vut.cz/study/thesis/18852/) ([Code](https://github.com/janivanecky/Depth-Estimation))
- [Generative Flow Networks (2022)](https://yoshuabengio.org/2022/03/05/generative-flow-networks/)
- [Feature Learning in Infinite-Width Neural Networks (2021)](https://arxiv.org/abs/2011.14522) ([Code](https://github.com/edwardjhu/TP4))
- [µTransfer: A technique for hyperparameter tuning of enormous neural networks (2022)](https://www.microsoft.com/en-us/research/blog/%C2%B5transfer-a-technique-for-hyperparameter-tuning-of-enormous-neural-networks/)
- [Restoring and attributing ancient texts using deep neural networks](https://github.com/deepmind/ithaca)
- [Reproducing Yann LeCun 1989 paper "Backpropagation Applied to Handwritten Zip Code Recognition"](https://github.com/karpathy/lecun1989-repro)
- [Deep Neural Nets: 33 years ago and 33 years from now (2022)](https://karpathy.github.io/2022/03/14/lecun1989/) ([Reddit](https://www.reddit.com/r/MachineLearning/comments/tf8owz/d_deep_neural_nets_33_years_ago_and_33_years_from/)) ([HN](https://news.ycombinator.com/item?id=30673821))
- [ONNC](https://github.com/ONNC/onnc) - Open Neural Network Compiler. ([Web](https://onnc.ai/))
- [Provably robust neural networks](https://github.com/locuslab/convex_adversarial) - Method for training neural networks that are provably robust to adversarial attacks.
- [Rust + WebAssembly + Neural Network](https://github.com/ldm0/wasm_nn)
- [Neural Networks are not the only universal approximators, so why are they so uniquely effective? (2022)](https://www.reddit.com/r/MachineLearning/comments/tqjd3w/d_neural_networks_are_not_the_only_universal/)
- [Awesome Spiking Neural Networks](https://github.com/vvvityaaa/awesome-spiking-neural-networks)
- [Transformers for software engineers (2022)](https://blog.nelhage.com/post/transformers-for-software-engineers/) ([HN](https://news.ycombinator.com/item?id=30883636))
- [Exploring Neural Networks Visually in the Browser (2022)](https://cprimozic.net/blog/neural-network-experiments-and-visualizations/)
- [Neural Network Visualization in the Browser](https://nn-viz.ameo.design/) - Neural network library written from scratch in Rust along with a web-based application for building + training neural networks + visualizing their outputs. ([Code](https://github.com/Ameobea/neural-network-from-scratch))
- [Sharpened Cosine Similarity](https://github.com/brohrer/sharpened-cosine-similarity) - Alternative to convolution for neural networks.
- [Google AI Blog: Controlling Neural Networks with Rule Representations (2022)](https://ai.googleblog.com/2022/01/controlling-neural-networks-with-rule.html)
- [Epistemic Neural Networks](https://github.com/deepmind/enn) - Library for uncertainty representation and training in neural networks.
- [Transformer in Triton](https://github.com/lucidrains/triton-transformer) - Implementation of a Transformer, but completely in Triton.
- [This AI Does Not Exist](https://thisaidoesnotexist.com/) - Generate realistic descriptions of made-up machine learning models. ([Code](https://github.com/thesephist/modelexicon))
- [Perplexity](https://github.com/andrew-johnson-4/perplexity) - Language is a notational semantic for documenting neural networks through diagrams.
- [Meta-AF: Meta-Learning for Adaptive Filters](https://github.com/adobe-research/MetaAF)
- [Sequence Transduction with Recurrent Neural Networks (2021)](https://arxiv.org/abs/1211.3711) ([Code](https://github.com/awni/transducer))
- [Papers and Codes for the deep learning in hyperbolic space](https://github.com/xiaoiker/Awesome-Hyperbolic-NeuralNetworks)
- [Friends don’t let friends train small diffusion models (2022)](https://nonint.com/2022/05/04/friends-dont-let-friends-train-small-diffusion-models/) ([HN](https://news.ycombinator.com/item?id=31513714))
- [Physicists are building neural networks out of vibrations, voltages and lasers (2022)](https://www.quantamagazine.org/how-to-make-the-universe-think-for-us-20220531/) ([HN](https://news.ycombinator.com/item?id=31579873))
- [Techniques for Training Large Neural Networks (2022)](https://openai.com/blog/techniques-for-training-large-neural-networks/) ([HN](https://news.ycombinator.com/item?id=31682887))
- [How fast can we perform a forward pass? (2022)](https://bounded-regret.ghost.io/how-fast-can-we-perform-a-forward-pass/) - How fast can you run a transformer model? ([Tweet](https://twitter.com/JacobSteinhardt/status/1539286865500438528))
- [Neural Network Loss Landscapes: What do we know? (2021)](https://damueller.com/#/blog-post/NNLLs) ([HN](https://news.ycombinator.com/item?id=32131153))
- [Logic Through the Lens of Neural Networks](https://cprimozic.net/blog/boolean-logic-with-neural-networks/)
