# Machine learning

[Phil Wang](https://github.com/lucidrains) always recreates many cutting edge ML papers with PyTorch. [This course](https://book.sciml.ai/) & [Math for ML](https://mml-book.github.io/) seem great. [Hugging Face](https://huggingface.co/) is incredible community & [tools](https://twitter.com/abhi1thakur/status/1533416501792935938). [Transformer architectures](https://twitter.com/michael_nielsen/status/1511853865150287873) & [Diffusion Models](https://www.youtube.com/watch?v=fbLgFrlTnGU) are great. [MLU-Explain](https://mlu-explain.github.io/) is a [great ML visual explainer](https://news.ycombinator.com/item?id=31455919).

Looking into using [envd](https://github.com/tensorchord/envd) together with [PyTorch Lightning](https://www.pytorchlightning.ai/) for my ML experiments.

## Notes

- A big part of the utility of math (especially in ML) is having breadth rather than depth. The strategy of picking out specific things you don't know from papers and looking them up is only effective if you have the breadth in your background to understand the answers you find.
  - Broad knowledge is also what helps you manage the exponential tree of complexity you're encountering.
    - You won't have seen all the things you come across, but you'll develop the ability to make good judgements about what you need to read to achieve your goals. You'll learn how to recognize when a reference you're reading is more (or less) technical than you need, and how to search for something more appropriate. You'll also learn how and when you can use results without understanding the details.
  - Finally, as a general grad student strategy trying to learn everything just in time is not a path to success. Even if you had the perfect math oracle that you want it would be setting you up to be left behind. All the oracle gives you is the ability to catch up quickly to the ideas of others. Your job as a grad student is to generate new knowledge and to do that you need to seek things out on your own, not just follow along the latest trend. Part of your job is to go out hunting for ideas that your peers haven't found yet and bring them back to your field.
- [In supervised learning, you have a bunch of data, a specific question you want to answer, and access to the correct answer to many instances of that question. In unsupervised learning, you have a bunch of data points, and you want to find meaningful patterns in the structure of that data. In reinforcement learning, you have a task you want to take actions to accomplish, and you don't have any access to knowing what the best action is, but after each action you get a rough idea of how good the result was.](https://www.reddit.com/r/MachineLearning/comments/7780ok/r_alphago_zero_learning_from_scratch_deepmind/dol3knx/ "permalink")
- AI doesn't need to follow the human model, just like planes don't need to flap their wings like a bird. For most jobs AI will be very different from humans. Even when AI acts as human for entertainment I would imagine them being very different internally, as their job is to mimic aspects of human behaviors, not actually a human as a whole.
- Almost all of machine learning is about representing data as vectors and performing linear and non-linear transformations in order to perform classification, regression, etc.
- Most of ML is fitting models to data. To fit a model you minimize some error measure as a function of its real valued parameters, e.g. the weights of the connections in a neural network. The algorithms to do the minimization are based on gradient descent, which depends on derivatives, i.e. differential calculus.
- [Learn optimization before studying machine learning if you really want to understand what's going on.](https://twitter.com/Adam235711/status/1391067131169574914)
- [What idiot called it "machine learning" instead of "bias automation".](https://twitter.com/fasterthanlime/status/868840530813353985)
- [If you were to learn only 1 method for explaining machine learning models, it should be Shapley values (SHAP): 1. Model-agnostic: Use with any model. 2. Theoretic foundation: Game theory. 3. Good software ecosystem. 4. Local and global explanations.](https://twitter.com/ChristophMolnar/status/1486635139190992896)
- [What idiot called it "machine learning" instead of "bias automation".](https://twitter.com/fasterthanlime/status/1397352603508518912)

## Links

- [Neural Networks and Deep Learning book](http://neuralnetworksanddeeplearning.com/)
- [Deep Learning Papers Reading Roadmap](https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap)
- [Ask HN: Best way to get started with AI?](https://news.ycombinator.com/item?id=15689399)
- [Ask HN: What maths are critical to pursuing ML/AI?](https://news.ycombinator.com/item?id=15116379)
- [Ask HN: 'Crash Courses' for Mathematics Related to DL, ML and Data Analysis](https://news.ycombinator.com/item?id=16508873)
- [Computational Statistics and Machine Learning Revision Notes](https://github.com/acbraith/CSML_notes)
- [Stanford CS229 course](https://github.com/econti/cs229)
- [Readings in applied data science](https://github.com/hadley/stats337)
- [Learn ML in 3 months](https://github.com/llSourcell/Learn_Machine_Learning_in_3_Months)
- [Deep Learn](https://github.com/GauravBh1010tt/DeepLearn) - Implementation of research papers on Deep Learning+ NLP+ CV in Python using Keras, TensorFlow and Scikit Learn.
- [Building Brundage Bot](https://hackernoon.com/building-brundage-bot-10252facf3d1)
- [Summaries of ML papers](https://github.com/aleju/papers)
- [Code and data for paper "Deep Painterly Harmonization"](https://github.com/luanfujun/deep-painterly-harmonization)
- [FB AI Tools](https://facebook.ai/developers/tools)
- [Best Practices for ML Engineering](https://developers.google.com/machine-learning/rules-of-ml/)
- [Machine Learning From Scratch](https://github.com/eriklindernoren/ML-From-Scratch)
- [Dive Into ML](http://hangtwenty.github.io/dive-into-machine-learning/)
- [Fermat's Library NIPS comments](http://fermatslibrary.com/nips)
- [Heroes of Deep Learning: Andrew Ng interviews Ian Goodfellow](https://www.youtube.com/watch?v=pWAc9B2zJS4)
- [Machine Learning for Humans](https://medium.com/machine-learning-for-humans/why-machine-learning-matters-6164faf1df12) - Great article.
- [Deep Learning for Siri’s Voice: On-device Deep Mixture Density Networks for Hybrid Unit Selection Synthesis](https://machinelearning.apple.com/2017/08/06/siri-voices.html)
- [The Google Brain Team — Looking Back on 2017](https://ai.googleblog.com/2018/01/the-google-brain-team-looking-back-on.html?m=1)
- [Building the Software 2.0 Stack by Andrej Karpathy from Tesla (2018)](https://www.figure-eight.com/building-the-software-2-0-stack-by-andrej-karpathy-from-tesla/)
- [Deep Learning World](https://github.com/astorfi/Deep-Learning-World)
- [Machine Learning cheatsheets for Stanford's CS 229](https://github.com/afshinea/stanford-cs-229-machine-learning)
- [RAAIS 2018 - François Chollet (Creator of Keras)](https://www.youtube.com/watch?v=2L2u303FAs8)
- [KubeFlow](https://github.com/kubeflow/kubeflow) - Machine Learning Toolkit for Kubernetes. ([Winding Road to Better Machine Learning Infrastructure Through Tensorflow Extended and Kubeflow](https://engineering.atspotify.com/2019/12/13/the-winding-road-to-better-machine-learning-infrastructure-through-tensorflow-extended-and-kubeflow/))
- [KALE (Kubeflow Automated pipeLines Engine)](https://github.com/kubeflow-kale/kale) - Aims at simplifying the Data Science experience of deploying Kubeflow Pipelines workflows.
- [MIT AGI: Deep Learning (Yoshua Bengio) (2018)](https://www.youtube.com/watch?v=azOmzumh0vQ)
- [TL-GAN: transparent latent-space GAN](https://github.com/SummitKwan/transparent_latent_gan) - Use supervised learning to illuminate the latent space of GAN for controlled generation and edit.
- [Grokking Deep Learning](https://github.com/iamtrask/Grokking-Deep-Learning) - Repository accompanying "Grokking Deep Learning" book.
- [HN: Can we rule out near-term AGI? (2018)](https://news.ycombinator.com/item?id=18405025)
- [Introduction to Grenade (Haskell library for Deep Learning)](https://www.huwcampbell.com/posts/2017-02-17-introduction-to-grenade.html)
- [Grenade](https://github.com/HuwCampbell/grenade) - Deep Learning in Haskell.
- [Deep Learning 1: Introduction to Machine Learning Based AI](https://www.youtube.com/watch?v=iOh7QUZGyiU)
- [Deep Learning cheatsheets for Stanford's CS 230 (2018)](https://github.com/afshinea/stanford-cs-230-deep-learning)
- [Deep Learning Book Chapter Summaries](https://github.com/dalmia/Deep-Learning-Book-Chapter-Summaries) - Attempting to make the Deep Learning Book easier to understand.
- [PracticalAI](https://github.com/GokuMohandas/practicalAI) - Practical approach to learning machine learning.
- [Ask HN: How to incorporate machine learning into day job? (2018)](https://news.ycombinator.com/item?id=18650646)
- [RLgraph](https://github.com/rlgraph/rlgraph) - Flexible computation graphs for deep reinforcement learning.
- [Nevergrad](https://github.com/facebookresearch/nevergrad) - Gradient-free optimization platform.
- [Machine Learning Cheat Sheet](https://ml-cheatsheet.readthedocs.io/en/latest/)
- [GANs and Divergence Minimization (2018)](https://colinraffel.com/blog/gans-and-divergence-minimization.html)
- [Convolution arithmetic](https://github.com/vdumoulin/conv_arithmetic) - Technical report on convolution arithmetic in the context of deep learning.
- [FloydHub](https://www.floydhub.com/) - Managed cloud platform for data scientists.
- [Style Transfer as Optimal Transport](https://github.com/VinceMarron/style_transfer) - Algorithm that transfers the distribution of visual characteristics, or style, of a reference image onto a subject image via an Optimal Transport plan.
- [Looking Back at Google’s Research Efforts in 2018](https://ai.googleblog.com/2019/01/looking-back-at-googles-research.html)
- [Recommenders](https://github.com/Microsoft/Recommenders) - Examples and best practices for building recommendation systems, provided as Jupyter notebooks.
- [Deep Learning State of the Art (2019) - MIT](https://www.youtube.com/watch?v=53YvP6gdD7U)
- [AdaNet](https://github.com/tensorflow/adanet) - Lightweight TensorFlow-based framework for automatically learning high-quality models with minimal expert intervention.
- [DAWNBench](https://dawn.cs.stanford.edu/benchmark/) - Benchmark suite for end-to-end deep learning training and inference.
- [Interpretable Machine Learning (2022)](https://christophm.github.io/interpretable-ml-book/) - Guide for Making Black Box Models Explainable. ([Code](https://github.com/christophM/interpretable-ml-book)) ([2nd edition](https://leanpub.com/interpretable-machine-learning))
- [All You Need to Know About Deep Learning - A kick-starter (2019)](https://github.com/osforscience/deep-learning-ocean)
- [KubeFlow Pipelines](https://github.com/kubeflow/pipelines) - Machine learning (ML) toolkit that is dedicated to making deployments of ML workflows on Kubernetes simple, portable, and scalable.
- [Summary of some ML papers](https://github.com/kweonwooj/papers)
- [Practical Deep Learning for Coders 2019](https://www.fast.ai/2019/01/24/course-v3/) - ([HN](https://news.ycombinator.com/item?id=19000027)) ([GitHub](https://github.com/fastai/course-v3))
- [Notebooks for the "A walk with fastai2" Study Group and Lecture Series](https://github.com/muellerzr/Practical-Deep-Learning-for-Coders-2.0)
- [The Matrix Calculus You Need For Deep Learning](https://explained.ai/matrix-calculus/index.html) ([HN](https://news.ycombinator.com/item?id=21661545)) ([HN 2](https://news.ycombinator.com/item?id=26676729)) ([Paper](https://arxiv.org/abs/1802.01528))
- [Machine Learning Feynman Experience](https://github.com/leandromineti/ml-feynman-experience) - Collection of concepts I tried to implement using only Python, NumPy and SciPy on Google Colaboratory.
- [Tensor2Tensor](https://github.com/tensorflow/tensor2tensor) - Library of deep learning models and datasets designed to make deep learning more accessible and accelerate ML research.
- [Deep learning drizzle](https://deep-learning-drizzle.github.io/) - Various ML, reinforcement learning video lectures. ([Code](https://github.com/kmario23/deep-learning-drizzle))
- [Xfer](https://github.com/amzn/xfer) - Transfer Learning library for Deep Neural Networks.
- [List of summer schools in machine learning + related fields](https://github.com/sshkhr/awesome-mlss)
- [Most Cited Deep Learning Papers](https://github.com/terryum/awesome-deep-learning-papers)
- [Machine Learning CS Columbia Course (2019)](http://www.cs.columbia.edu/%7Everma/classes/ml/index.html)
- [Learning to Discover Efficient Mathematical Identities](https://github.com/kkurach/math_learning) - Exploring how machine learning techniques can be applied to the discovery of efficient mathematical identities.
- [CleverHans](https://github.com/tensorflow/cleverhans) - Adversarial example library for constructing attacks, building defenses, and benchmarking both.
- [Google AI Research](https://github.com/google-research/google-research) - Contains code released by Google AI Research.
- [Machine Learning Mindmap / Cheatsheet](https://github.com/dformoso/machine-learning-mindmap)
- [Curated list of network embedding techniques](https://github.com/chihming/awesome-network-embedding)
- [Deploying Deep Learning](https://github.com/dusty-nv/jetson-inference) - Training guide for inference and deep vision runtime library for NVIDIA DIGITS and Jetson Xavier/TX1/TX2.
- ["Adversarial Machine Learning" with Ian Goodfellow (2018)](https://www.youtube.com/watch?v=3-qazNQS2JU)
- [HN: Yann LeCun, Geoffrey Hinton and Yoshua Bengio win Turing Award (2019)](https://news.ycombinator.com/item?id=19499515)
- [Large scale K-means and K-nn implementation on NVIDIA GPU / CUDA](https://github.com/src-d/kmcuda)
- [fairseq](https://github.com/facebookresearch/fairseq) - Sequence-to-sequence learning toolkit for Torch from Facebook AI Research tailored to Neural Machine Translation (NMT).
- [TinyFlow](https://github.com/tqchen/tinyflow) - Tutorial code on how to build your own Deep Learning System in 2k Lines.
- [Deep Learning Models](https://github.com/rasbt/deeplearning-models) - Collection of various deep learning architectures, models, and tips.
- [Multi-Level Intermediate Representation Overview](https://github.com/tensorflow/mlir) - MLIR project aims to define a common intermediate representation (IR) that will unify the infrastructure required to execute high performance machine learning models in TensorFlow and similar ML frameworks. ([Talks](https://mlir.llvm.org/talks/)) ([HN](https://news.ycombinator.com/item?id=22429107)) ([Slides](http://llvm.org/devmtg/2019-04/slides/Keynote-ShpeismanLattner-MLIR.pdf))
- [PySparNN](https://github.com/facebookresearch/pysparnn) - Approximate Nearest Neighbor Search for Sparse Data in Python.
- [Machine Learning Course with Python](https://github.com/machinelearningmindset/machine-learning-course)
- [ICML](https://icml.cc/) - International Conference on Machine Learning.
- [Integrating Domain Knowledge into Deep Learning by Ruslan Salakhutdinov (2019)](https://www.youtube.com/watch?v=b8ABJZ7lfXU)
- [Differentiation for Hackers](https://github.com/MikeInnes/diff-zoo) - The goal of this handbook is to demystify algorithmic differentiation, the tool that underlies modern machine learning.
- [Homemade Machine Learning](https://github.com/trekhleb/homemade-machine-learning)
- [Machine Learning Systems are Stuck in a Rut (2019)](https://dl.acm.org/citation.cfm?id=3321441) ([HN](https://news.ycombinator.com/item?id=20301619))
- [Literature of Deep Learning for Graphs](https://github.com/DeepGraphLearning/LiteratureDL4Graph)
- [Supplementary Materials for "Unsupervised word embeddings capture latent knowledge from materials science literature", Nature](https://github.com/materialsintelligence/mat2vec)
- [Solution of assignment in 2011 Stanford Machine Learning Class](https://github.com/everpeace/ml-class-assignments)
- [Autocompletion with deep learning (2019)](https://tabnine.com/blog/deep)
- [Rules of Machine Learning: Best Practices for ML Engineering](http://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf)
- [Python Machine Learning Book (2019)](https://www.packtpub.com/product/python-machine-learning-third-edition/9781789955750) ([3rd edition code](https://github.com/rasbt/python-machine-learning-book-3rd-edition)) ([2nd edition code](https://github.com/rasbt/python-machine-learning-book-2nd-edition))
- [ML and DS Applications in Industry](https://github.com/firmai/industry-machine-learning) - Curated list of applied machine learning and data science notebooks and libraries across different industries.
- [Awesome production machine learning](https://github.com/EthicalML/awesome-production-machine-learning)
- [Awesome Gradient Boosting Research Papers](https://github.com/benedekrozemberczki/awesome-gradient-boosting-papers)
- [HoloClean](https://github.com/HoloClean/holoclean) - Machine Learning System for Data Enrichment.
- [Snorkel](https://github.com/snorkel-team/snorkel) - System for quickly generating training data with weak supervision.
- [RAdam](https://github.com/LiyuanLucasLiu/RAdam) - On The Variance Of The Adaptive Learning Rate And Beyond.
- [Google ML/AI Comic](https://cloud.google.com/products/ai/ml-comic-1/)
- [Machine Learning Notebooks](https://github.com/ageron/handson-ml2) - Series of Jupyter notebooks that walk you through the fundamentals of Machine Learning and Deep Learning in Python using Scikit-Learn, Keras and TensorFlow 2.
- [Streamlit](https://github.com/streamlit/streamlit) - Fastest way to build custom ML tools. ([Web](https://streamlit.io/)) ([Awesome Streamlit](https://github.com/MarcSkovMadsen/awesome-streamlit)) ([Streamlit Cheat Sheet](https://github.com/daniellewisDL/streamlit-cheat-sheet)) ([Tips, tricks, methods, and techniques for building apps with streamlit](https://github.com/pmbaumgartner/streamlitopedia)) ([Best of Streamlit](https://github.com/jrieke/best-of-streamlit))
- [A Gentle Introduction to Bayes’ Theorem for Machine Learning (2019)](https://news.ycombinator.com/item?id=21151032) ([HN](https://news.ycombinator.com/item?id=21151032))
- [Practical Deep Learning for Coders](https://course.fast.ai/) ([Notes](https://github.com/reshamas/fastai_deeplearn_part1)) ([Code](https://github.com/fastai/course22))
- [Part 2: Deep Learning from the Foundations](https://course.fast.ai/part2)
- [Computational Linear Algebra for Coders](https://github.com/fastai/numerical-linear-algebra)
- [Introduction to Machine Learning for Coders](http://course18.fast.ai/ml)
- [Papers with Code](https://paperswithcode.com/) - The latest in machine learning. ([HN](https://news.ycombinator.com/item?id=29688214))
- [Gradient Descent Derivation (2014)](https://mccormickml.com/2014/03/04/gradient-descent-derivation/)
- [Best of Machine Learning Newsletter](https://bestofml.com/)
- [TASO](https://github.com/jiazhihao/taso) - Tensor Algebra SuperOptimizer for Deep Learning.
- [An Exponential Learning Rate Schedule for Deep Learning (2019)](https://arxiv.org/abs/1910.07454)
- [Billion-scale semi-supervised learning for state-of-the-art image and video classification (2019)](https://ai.facebook.com/blog/billion-scale-semi-supervised-learning)
- [TRAINS](https://github.com/allegroai/trains) - Auto-Magical Experiment Manager & Version Control for AI.
- [Differentiable Optimization-Based Modeling for Machine Learning (2019)](https://github.com/bamos/thesis)
- [Notebooks and code for the book "Introduction to Machine Learning with Python"](https://github.com/amueller/introduction_to_ml_with_python)
- [Awesome Deep Learning Project Ideas](https://github.com/NirantK/awesome-project-ideas)
- [Top-down, practical guide to learn AI, Deep learning and Machine Learning](https://github.com/emilwallner/How-to-learn-Deep-Learning)
- [Most Aesthetically Pleasing ML Research Papers](https://www.reddit.com/r/MachineLearning/comments/bp6l9y/d_most_aesthetically_pleasing_ml_research_papers/)
- [Polyaxon](https://polyaxon.com/) - Platform for reproducible and scalable machine learning and deep learning on Kubernetes. ([GitHub](https://github.com/polyaxon)) ([Code](https://github.com/polyaxon/polyaxon))
- [Different projects built using fast.ai](https://forums.fast.ai/t/share-you-work-here-highlights/57140)
- [Spell](https://spell.run/) - Fastest and most powerful end-to-end platform for machine learning and deep learning.
- [ML portfolio tips (2019)](https://twitter.com/EmilWallner/status/1184723538810413056)
- [DeepMind Research](https://github.com/deepmind/deepmind-research) - Contains implementations and illustrative code to accompany DeepMind publications.
- [Deep Learning Tutorials](https://github.com/lisa-lab/DeepLearningTutorials)
- [Prodify](https://prodi.gy/) - Radically efficient machine teaching. An annotation tool powered by active learning.
- [Runway](https://runwayml.com/) - Professional video editing powered by machine learning — all on the web. ([HN](https://news.ycombinator.com/item?id=27766655))
- [An Extended Version Of The Scikit-Learn Cheat Sheet (2014)](https://medium.com/@chris_bour/an-extended-version-of-the-scikit-learn-cheat-sheet-5f46efc6cbb)
- [Notes on Machine Learning](https://wiki.kourouklides.com/wiki/Machine_Learning)
- [Notes on Deep Learning](https://wiki.kourouklides.com/wiki/Deep_Learning)
- [Awesome free deep learning papers](https://github.com/HFTrader/awesome-free-deep-learning-papers)
- [Teachable Machine](https://teachablemachine.withgoogle.com/) - Fast, easy way to create machine learning models for your sites, apps, and more – no expertise or coding required.
- [Deep Learning Interview Topics](https://github.com/vlgiitr/DL_Topics)
- [Ask HN: Why do so many startups claim machine learning is their long game? (2019)](https://news.ycombinator.com/item?id=21528246)
- [End-to-End Machine Learning Courses](https://end-to-end-machine-learning.teachable.com/courses/)
- [End-to-End Machine Learning Library](https://e2eml.school/blog.html)
- [Course material for STAT 479: Machine Learning (FS 2019) taught by Sebastian Raschka at University Wisconsin-Madison](https://github.com/rasbt/stat479-machine-learning-fs19)
- [Clipper](https://github.com/ucbrise/clipper) - Prediction serving system that sits between user-facing applications and a wide range of commonly used machine learning models and frameworks.
- [AI building blocks - from scratch with Python (2018)](https://datadan.io/ai-building-blocks-from-scratch-with-python)
- [ARUBA: Learning-to-Learn with Less Regret (2019)](https://blog.ml.cmu.edu/2019/11/22/aruba/)
- [Machine Learning Systems Design](https://github.com/chiphuyen/machine-learning-systems-design)
- [Guide to Production Level Deep Learning](https://github.com/alirezadir/Production-Level-Deep-Learning)
- [Lessons learned building an ML trading system that turned $5k into $200k (2019)](https://www.tradientblog.com/2019/11/lessons-learned-building-an-ml-trading-system-that-turned-5k-into-200k/) ([HN](https://news.ycombinator.com/item?id=21647038))
- [Deep Learning for Programmers](https://aiprobook.com/deep-learning-for-programmers/)
- [Arcade Learning Environment](https://github.com/mgbellemare/Arcade-Learning-Environment) - Simple object-oriented framework that allows researchers and hobbyists to develop AI agents for Atari 2600 games.
- [Space to discuss the future of the ML ecosystem in Rust](https://github.com/rust-ml/discussion)
- [Awesome System for Machine Learning](https://github.com/HuaizhengZhang/Awesome-System-for-Machine-Learning)
- [Collection of explainer tutorials on how machine learning and statistical concepts work](https://end-to-end-machine-learning.teachable.com/p/machine-learning-signal-processing-statistics-concepts)
- [2019’s Top Machine and Deep Learning Research Papers](https://heartbeat.fritz.ai/2019s-Gtop-machine-and-deep-learning-research-papers-1ec363f29e85?gi=86d0e6c2ea9f) ([HN](https://news.ycombinator.com/item?id=21743950))
- [NeurIPS 2019 Schedule](https://nips.cc/Conferences/2019/Schedule)
- [Machine Learning Crash Course with TensorFlow APIs](https://developers.google.com/machine-learning/crash-course) - Google's fast-paced, practical introduction to machine learning.
- [What was your favorite paper of 2019 and why? (2019)](https://www.reddit.com/r/MachineLearning/comments/e8the3/d_what_was_your_favorite_paper_of_2019_and_why/)
- [Ask HN: Full-on machine learning for 2020, what are the best resources?](https://news.ycombinator.com/item?id=21924298)
- [Dive into Deep Learning](https://d2l.ai/) - Interactive deep learning book with code, math, and discussions, based on the NumPy interface. ([HN](https://news.ycombinator.com/item?id=21948698)) ([Code](https://github.com/d2l-ai/d2l-en))
- [Resources to learn more about Machine Learning and Artificial Intelligence](https://github.com/brylevkirill/notes)
- [Foundations of Machine Learning book](https://mitpress.mit.edu/books/foundations-machine-learning-second-edition) - New edition of a graduate-level machine learning textbook that focuses on the analysis and theory of algorithms.
- [Deep Learning book](https://www.deeplearningbook.org/) - Resource intended to help students and practitioners enter the field of machine learning in general and deep learning in particular. ([Code](https://github.com/zsdonghao/deep-learning-book)) ([Notes](https://github.com/greentfrapp/deep-learning-book-notes)) ([Exercises](https://github.com/goodfeli/dlbook_exercises)) ([LaTeX files for book notation](https://github.com/goodfeli/dlbook_notation)) ([PDF](https://github.com/daviddao/deep-learning-book/blob/master/DeepLearningBook.pdf)) ([PDF 2](https://github.com/janishar/mit-deep-learning-book-pdf))
- [Introduction to Deep Learning - Eugene Charniak](https://mitpress.mit.edu/books/introduction-deep-learning) - Project-based guide to the basics of deep learning.
- [Hands-On Machine Learning with Scikit-Learn, Keras, and Tensorflow: Concepts, Tools, and Techniques to Build Intelligent Systems](https://www.goodreads.com/book/show/40363665-hands-on-machine-learning-with-scikit-learn-keras-and-tensorflow)
- [Topological Techniques for Unsupervised Learning (2019)](https://www.youtube.com/watch?v=7pAVPjwBppo)
- [Meet AdaMod: a new deep learning optimizer with memory (2020)](https://medium.com/@lessw/meet-adamod-a-new-deep-learning-optimizer-with-memory-f01e831b80bd)
- [Deep Learning State of the Art (2020)](https://www.youtube.com/watch?v=0VH1Lim8gL8)
- [The Case for Bayesian Deep Learning (2020)](https://cims.nyu.edu/~andrewgw/caseforbdl/) ([HN](https://news.ycombinator.com/item?id=22023490)) ([Reddit](https://www.reddit.com/r/MachineLearning/comments/eng1gl/the_case_for_bayesian_deep_learning/))
- [Machine Learning Summer School (2020)](http://mlss.tuebingen.mpg.de/2020/)
- [Machine Learning Summer School videos (2009)](http://videolectures.net/mlss09uk_cambridge/)
- [Turi Create](https://github.com/apple/turicreate) - Simplifies the development of custom machine learning models.
- [Private machine learning progress](https://github.com/OpenMined/private-ai-resources)
- [Demucs](https://github.com/facebookresearch/demucs) - Code for the paper Music Source Separation in the Waveform Domain.
- [Apple at NeurIPS 2019](https://machinelearning.apple.com/2019/12/02/apple-at-neurips-2019.html)
- [Magenta](https://magenta.tensorflow.org/) - Make Music and Art Using Machine Learning. ([JS Code](https://github.com/magenta/magenta-js)) ([GitHub](https://github.com/magenta))
- [An overview of gradient descent optimization algorithms (2016)](https://ruder.io/optimizing-gradient-descent/)
- [What are the current significant trends in ML that are NOT Deep Learning related? (2020)](https://www.reddit.com/r/MachineLearning/comments/eq3da0/d_what_are_the_current_significant_trends_in_ml/)
- [Trax](https://github.com/google/trax) - Helps you understand and explore advanced deep learning.
- [ATMSeer: Increasing Transparency and Controllability in Automated Machine Learning](https://dai.lids.mit.edu/projects/atmseer/) ([Code](https://github.com/HDI-Project/ATMSeer))
- [Cambridge Machine Learning Group](http://mlg.eng.cam.ac.uk/)
- [Convolutional Conditional Neural Processes (2020)](https://openreview.net/forum?id=Skey4eBYPS)
- [Privacy Preserving AI (Andrew Trask) (2020)](https://www.youtube.com/watch?v=4zrU54VIK6k)
- [Emil’s Story as a Self-Taught AI Researcher (2020)](https://blog.floydhub.com/emils-story-as-a-self-taught-ai-researcher/)
- [Humans of Machine Learning](https://blog.floydhub.com/tag/humans-of-ml/)
- [Machine Learning Flashcards](https://machinelearningflashcards.com/) ([HN](https://news.ycombinator.com/item?id=22629959))
- [Awesome Software Engineering for Machine Learning](https://github.com/SE-ML/awesome-seml)
- [Awesome Data Labeling](https://github.com/heartexlabs/awesome-data-labeling) - Curated list of awesome data labeling tools.
- [Machine Learning in Python: Main developments and technology trends in data science, machine learning, and artificial intelligence (2020)](https://arxiv.org/abs/2002.04803)
- [fastai: A Layered API for Deep Learning (2020)](https://arxiv.org/abs/2002.04688) ([HN](https://news.ycombinator.com/item?id=22324023))
- [The Deep Learning Compiler: A Comprehensive Survey (2020)](https://arxiv.org/abs/2002.03794)
- [Perceptrons explained](https://owenshen24.github.io/perceptron/)
- [A Simple Framework for Contrastive Learning of Visual Representations (2020)](https://arxiv.org/abs/2002.05709) ([Tweet](https://twitter.com/tingchenai/status/1228337240708874241)) ([Code](https://github.com/leftthomas/SimCLR))
- [MediaPipe](https://github.com/google/mediapipe) - Cross-platform framework for building multimodal applied machine learning pipelines.
- [ML courses by Zico Kolter](http://zicokolter.com/courses/)
- [List of AI Residency Programs](https://github.com/dangkhoasdc/awesome-ai-residency)
- [MIT Introduction to Deep Learning course (2020)](http://introtodeeplearning.com/) ([Code](https://github.com/aamini/introtodeeplearning)) ([Videos](https://www.youtube.com/playlist?list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI))
- [Stanford Deep Multi-Task and Meta Learning course (2019)](http://cs330.stanford.edu/)
- [FastAI book draft (2020)](https://github.com/fastai/fastbook) ([HN](https://news.ycombinator.com/item?id=22449562)) ([Notebooks](https://github.com/fastai/book_nbs))
- [Pattern Recognition and Machine Learning by Christopher M. Bishop Book](https://www.goodreads.com/book/show/55881.Pattern_Recognition_and_Machine_Learning) ([Code](https://github.com/ctgk/PRML)) ([PDF](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf)) ([Code/Notes](https://github.com/gerdm/prml))
- [Google Colaboratory](https://github.com/googlecolab/backend-container) - Research project created to help disseminate machine learning education and research.
- [Resources for teaching machine learning](https://github.com/kierisi/teaching_ml/blob/master/teaching_ml_resources.md)
- [Population Based Augmentation](https://github.com/arcelien/pba) - Algorithm that quickly and efficiently learns data augmentation functions for neural network training.
- [NVIDIA Deep Learning Examples for Tensor Cores](https://github.com/NVIDIA/DeepLearningExamples)
- [Introduction to Deep Learning and Generative Models course](http://pages.stat.wisc.edu/~sraschka/teaching/stat453-ss2020/) ([Code](https://github.com/rasbt/stat453-deep-learning-ss20))
- [Collection of Conference & School Notes in Machine Learning](https://github.com/RobertTLange/visual-machine-learning-notes)
- [AutoML-Zero](https://github.com/google-research/google-research/tree/master/automl_zero#automl-zero) - Open source code for the paper: "AutoML-Zero: Evolving Machine Learning Algorithms From Scratch". ([HN](https://news.ycombinator.com/item?id=22539117))
- [fastAI course v4](https://github.com/fastai/course-v4)
- [Ask HN: What is your ML stack like? (2020)](https://news.ycombinator.com/item?id=21516311)
- [MLflow](https://mlflow.org/) - Open source platform to manage the ML lifecycle, including experimentation, reproducibility and deployment. ([Code](https://github.com/mlflow/mlflow/))
- [Deep Unsupervised Learning (2020)](https://sites.google.com/view/berkeley-cs294-158-sp20/home)
- [Machine Learning: a Probabilistic Perspective book](https://www.cs.ubc.ca/~murphyk/MLbook/) ([Code](https://github.com/probml/pyprobml))
- [Introduction to Machine Learning - Carnegie Mellon University (2019)](http://www.cs.cmu.edu/%7Eninamf/courses/315sp19/)
- [Notes on ML courses](https://github.com/alisher0717/machine-learning-notes)
- [Made With ML](https://madewithml.com/) - Share what you've Made With ML. ([Code](https://github.com/GokuMohandas/MadeWithML)) ([MLOps Course](https://github.com/GokuMohandas/applied-ml))
- [Backpropagation 101 (2020)](https://thinc.ai/docs/backprop101) - How to trick yourself into understanding backprop without even trying.
- [A Spacetime Approach to Generalized Cognitive Reasoning in Multi-scale Learning (2017)](https://arxiv.org/abs/1702.04638)
- [Open Source Deep Learning Glossary](https://github.com/jrdi/dl-glossary)
- [Awesome Graph Classification](https://github.com/benedekrozemberczki/awesome-graph-classification) - Collection of important graph embedding, classification and representation learning papers with implementations.
- [fast.ai](https://www.fast.ai/) - Making neural nets uncool again. ([Code](https://github.com/fastai/fastai)) ([Docs](https://docs.fast.ai/)) ([Course launch](https://www.fast.ai/2020/08/21/fastai2-launch/)) ([HN](https://news.ycombinator.com/item?id=24237207))
- [Interactive Tools for ML, DL and Math](https://github.com/Machine-Learning-Tokyo/Interactive_Tools)
- [Deep learning with graph-structured representations (2020)](https://pure.uva.nl/ws/files/46900201/Thesis.pdf)
- [Interactive Machine Learning Experiments](https://github.com/trekhleb/machine-learning-experiments) ([Web](https://trekhleb.github.io/machine-learning-experiments/#/))
- [AxCell: Automatic Extraction of Results from Machine Learning Papers (2020)](https://arxiv.org/abs/2004.14356)
- [Awesome Machine Learning and AI Courses](https://github.com/luspr/awesome-ml-courses)
- [How do you keep up with new research? (2020)](https://www.reddit.com/r/MachineLearning/comments/gko05p/discussion_how_do_you_guys_keep_up_with_new/)
- [OpenLTH: A Framework for Lottery Tickets and Beyond](https://github.com/facebookresearch/open_lth)
- [Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning](https://github.com/ruqizhang/csgmcmc)
- [Awesome Interpretable Machine Learning](https://github.com/lopusz/awesome-interpretable-machine-learning)
- [DLPack: Open In Memory Tensor Structure](https://github.com/dmlc/dlpack)
- [SVM tutorial](https://www.svm-tutorial.com/) ([HN](https://news.ycombinator.com/item?id=23368246))
- [DeepMind x UCL | Deep Learning Lecture Series (2020)](https://www.youtube.com/playlist?list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF)
- [Nicholas Carlini: Making and Measuring Progress in Adversarial Machine Learning (2019)](https://www.youtube.com/watch?v=jD3L6HiH4ls)
- [Deep Learning in Production](https://github.com/ahkarami/Deep-Learning-in-Production) - Notes and references about deploying deep learning-based models in production.
- [Stanford Class on Deep Multi-Task and Meta-Learning (2019)](https://cs330.stanford.edu/) ([HN](https://news.ycombinator.com/item?id=23474846))
- [Weights & Biases](https://wandb.ai/home) - Developer tools for ML. Experiment tracking, hyperparameter optimization, model and dataset versioning. ([Code](https://github.com/wandb/client)) ([Docs](https://docs.wandb.ai/)) ([Examples](https://github.com/wandb/examples)) ([Community](https://community.wandb.ai/))
- [Protocols and Structures for Inference (PSI) spec](http://psi.cecs.anu.edu.au/spec/) - Aims to develop an architecture for presenting machine learning algorithms, their inputs (data) and outputs (predictors) as resource-oriented RESTful web services.
- [ML Engineer Roadmap](https://github.com/chris-chris/ml-engineer-roadmap)
- [Machine Learning for Everyone - In simple words. With real-world examples.](https://vas3k.com/blog/machine_learning/)
- [Deep learning на пальцах](https://dlcourse.ai/) ([Code](https://github.com/sim0nsays/dlcourse_ai))
- [How to add AI to your app without knowing anything about AI (2020)](https://jaredpalmer.com/blog/add-ai-to-your-app-without-knowing-anything-about-ai)
- [What I learned from looking at 200 machine learning tools (2020)](https://huyenchip.com/2020/06/22/mlops.html) ([HN](https://news.ycombinator.com/item?id=23620757))
- [Interactive Machine Learning List](https://p.migdal.pl/interactive-machine-learning-list/) ([Code](https://github.com/stared/interactive-machine-learning-list/))
- [Sema](https://sema.codes/) - Live Code Language Design Playground. ([Code](https://github.com/mimic-sussex/sema))
- [Model Zoo](https://modelzoo.dev/) - Deploy your model with a single line of code. ([HN](https://news.ycombinator.com/item?id=23678633))
- [Introduction to Machine Learning with Julia](https://juliaacademy.com/p/introduction-to-machine-learning)
- [Reverb](https://github.com/deepmind/reverb) - Efficient and easy-to-use data storage and transport system designed for machine learning research.
- [System design patterns for machine learning](https://github.com/mercari/ml-system-design-pattern)
- [Income strategies to support your ML research (2020)](https://twitter.com/EmilWallner/status/1278321048346341379)
- [Synthetic Data for Deep Learning (2019)](https://arxiv.org/abs/1909.11512)
- [NeurIPS](https://neurips.cc/) - Conference on Neural Information Processing Systems.
- [Machine Learning Mastery](https://machinelearningmastery.com/)
- [Distill](https://distill.pub/) - Latest articles about machine learning.
- [Compute access for ML training (2020)](https://twitter.com/EmilWallner/status/1276071724224831489)
- [Scann: Scalable Nearest Neighbors](https://github.com/google-research/google-research/tree/master/scann) ([HN](https://news.ycombinator.com/item?id=23737338))
- [CML](https://cml.dev/) - Continuous Machine Learning: Bring DevOps to Data Science. ([HN](https://news.ycombinator.com/item?id=23759332)) ([Code](https://github.com/iterative/cml)) ([Web Code](https://github.com/iterative/cml.dev))
- [TensorFlow, Keras and deep learning, without a PhD](https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/#0) ([HN](https://news.ycombinator.com/item?id=23867892))
- [Apple Machine Learning Research](https://machinelearning.apple.com/) ([HN](https://news.ycombinator.com/item?id=23944506))
- [Model Card Toolkit](https://github.com/tensorflow/model-card-toolkit) - Streamlines and automates generation of Model Cards, machine learning documents that provide context and transparency into a model's development and performance. ([Article](https://ai.googleblog.com/2020/07/introducing-model-card-toolkit-for.html))
- [Top ML Books recommended by experts](https://mentorcruise.com/books/ml/)
- [Best practices for performance and cost optimization for machine learning](https://cloud.google.com/solutions/machine-learning/best-practices-for-ml-performance-cost)
- [Bethge Lab](http://bethgelab.org/) - Perceiving Neural Networks.
- [Graphcore code examples](https://github.com/graphcore/examples)
- [Machine learning examples and tutorials](https://github.com/lazyprogrammer/machine_learning_examples)
- [Vintage Factor Analysis with Varimax Performs Statistical Inference (2020)](https://arxiv.org/abs/2004.05387)
- [An Opinionated Guide to ML Research (2020)](http://joschu.net/blog/opinionated-guide-ml-research.html)
- [Amazon's Machine Learning University](https://www.amazon.science/latest-news/machine-learning-course-free-online-from-amazon-machine-learning-university) ([HN](https://news.ycombinator.com/item?id=24167034))
- [Progress, Notes, Summaries and a lot of Questions on Machine Learning](https://github.com/RobertTLange/reading-notes-ml)
- [SciML](https://sciml.ai/) - Open Source Software for Scientific Machine Learning.
- [Mihaela Rosca ML notes](https://github.com/mihaelacr/paper-notes)
- [Compression of Deep Learning Models for Text: A Survey (2020)](https://arxiv.org/abs/2008.05221)
- [The Computational Limits of Deep Learning (2020)](https://arxiv.org/abs/2007.05558) ([HN](https://news.ycombinator.com/item?id=24192117))
- [ML Ops: Machine Learning Operations](https://ml-ops.org/) ([Awesome](https://github.com/visenger/awesome-mlops)) ([References](https://ml-ops.org/content/references.html))
- [Benchmarks of approximate nearest neighbor libraries in Python](https://github.com/erikbern/ann-benchmarks) ([Web](http://ann-benchmarks.com/))
- [MIT Deep Learning course](https://github.com/lexfridman/mit-deep-learning)
- [Visualizing Deep Learning (2020)](https://www.youtube.com/playlist?list=PLyPKqVSnetmEOp_g_hfabuRAs9ET-shl_)
- [Books for Machine Learning, Deep Learning, and related topics](https://github.com/loveunk/Deep-learning-books)
- [Graph Representation Learning Book](https://www.cs.mcgill.ca/~wlh/grl_book/) ([Reddit](https://www.reddit.com/r/MachineLearning/comments/iezafd/r_graph_representation_learning_book_by_will/))
- [Effective testing for machine learning systems (2020)](https://www.jeremyjordan.me/testing-ml/) ([HN](https://news.ycombinator.com/item?id=24332202))
- [Machine Learning from Scratch](https://dafriedman97.github.io/mlbook/content/introduction.html) ([HN](https://news.ycombinator.com/item?id=24332303)) ([Code](https://github.com/dafriedman97/mlbook))
- [Compose](https://github.com/FeatureLabs/compose) - Machine learning tool for automated prediction engineering. It allows you to structure prediction problems and generate labels for supervised learning.
- [Daily scikit-learn tips](https://github.com/justmarkham/scikit-learn-tips)
- [Applied ML](https://github.com/eugeneyan/applied-ml) - Curated papers, articles, and blogs on data science & machine learning in production.
- [Understanding Convolution in Deep Learning (2015)](https://timdettmers.com/2015/03/26/convolution-deep-learning/)
- [21 Habits I Picked Up While Learning Machine Learning (2019)](http://blog.varunajayasiri.com/practices_learned_while_learning_machine_learning.html)
- [Hacker News for ML](https://mln.dev/top/1)
- [Think Fast: Tensor Streaming Processor for Accelerating Deep Learning Workloads (2020)](https://conferences.computer.org/isca/pdfs/ISCA2020-4QlDegUf3fKiwUXfV0KdCm/466100a145/466100a145.pdf)
- [My Deep Learning Toolchain (2020)](https://rosshemsley.co.uk/posts/deep_learning_toolchain/)
- [igel](https://github.com/nidhaloff/igel) - Machine learning tool that allows you to train/fit, test and use models without writing code. ([HN](https://news.ycombinator.com/item?id=24671525))
- [Gradient Boosted Decision Trees (2020)](https://www.simonwardjones.co.uk/posts/gradient_boosted_decision_trees/) ([HN](https://news.ycombinator.com/item?id=24700250))
- [NeurIPS 2020 Accepted Papers](https://neurips.cc/Conferences/2020/AcceptedPapersInitial)
- [explained.ai](https://explained.ai/) - Deep explanations of machine learning and related topics.
- [How to visualize decision trees (2018)](https://explained.ai/decision-tree-viz/index.html)
- [How to explain gradient boosting (2018)](https://explained.ai/gradient-boosting/index.html)
- [Beware Default Random Forest Importances (2018)](https://explained.ai/rf-importance/index.html)
- [The Mechanics of Machine Learning](https://mlbook.explained.ai/)
- [Yann LeCun Spring 2020 DL Course (Videos, Slides, Jupyter Notebooks)](https://atcold.github.io/pytorch-Deep-Learning/) ([HN](https://news.ycombinator.com/item?id=24715307)) ([Article](https://nyudatascience.medium.com/yann-lecuns-deep-learning-course-at-cds-is-now-fully-online-accessible-to-all-787ddc8bf0af))
- [Yann LeCun Deep Learning Course 2021](https://atcold.github.io/NYU-DLSP21/) ([HN](https://news.ycombinator.com/item?id=27387154))
- [ML Guide: Feature Store vs Data Warehouse (2020)](https://www.logicalclocks.com/blog/feature-store-vs-data-warehouse) ([HN](https://news.ycombinator.com/item?id=24718301))
- [Grid AI](https://www.grid.ai/) - Seamlessly train hundreds of Machine Learning models on the cloud from your laptop. ([HN](https://news.ycombinator.com/item?id=24720681))
- [Getting Started with Applied ML Research (2020)](https://elvissaravia.substack.com/p/getting-started-with-applied-ml-research)
- [Machine Learning Engineering book by Andriy Burkov](http://www.mlebook.com/wiki/doku.php)
- [Determined](https://github.com/determined-ai/determined) - Deep Learning Training Platform. ([Web](https://determined.ai/))
- [Phasic Policy Gradient](https://github.com/openai/phasic-policy-gradient)
- [Juergen Schmidhuber ML reading list (2015)](https://www.reddit.com/r/MachineLearning/comments/2xcyrl/i_am_j%C3%BCrgen_schmidhuber_ama/cp5c0py/)
- [Machine Learning Primer for Interviews](https://www.confetti.ai/assets/ml-primer/ml_primer.pdf)
- [Confetti AI](https://www.confetti.ai/) - Ace Your Machine Learning Interviews.
- [Intro to Deep Learning: Use TensorFlow and Keras to build and train neural networks by Kaggle](https://www.kaggle.com/learn/intro-to-deep-learning)
- [Manifold](https://github.com/uber/manifold) - Model-agnostic visual debugging tool for machine learning. ([Web](http://manifold.mlvis.io/))
- [Making With ML YouTube series](https://github.com/google/making_with_ml)
- [Topological Autoencoders (2020)](https://michaelmoor.ml/blog/topoae/main/) ([Code](https://github.com/BorgwardtLab/topological-autoencoders))
- [Awesome Teachable Machine List](https://github.com/SashiDo/awesome-teachable-machine) - Curated list of awesome machine learning projects built with Google's Teachable Machine.
- [How to put machine learning models into production (2020)](https://stackoverflow.blog/2020/10/12/how-to-put-machine-learning-models-into-production/)
- [Example Machine Learning Scripts for Numerai's Tournament (2020)](https://github.com/numerai/example-scripts)
- [Synthetic Data Vault (SDV)](https://github.com/sdv-dev/SDV) - Synthetic Data Generation for tabular, relational, time series data. ([Web](https://sdv.dev/))
- [Penn Machine Learning Benchmarks](https://github.com/EpistasisLab/pmlb) - Large, curated repository of benchmark datasets for evaluating supervised machine learning algorithms. ([Web](https://epistasislab.github.io/pmlb/))
- [2020 Machine Learning Roadmap](https://github.com/mrdbourke/machine-learning-roadmap)
- [Responsible Machine Learning](https://github.com/ModelOriented/DrWhy) - Collection of tools for eXplainable AI (XAI). ([Web](https://modeloriented.github.io/DrWhy/))
- [MI2 DataLab](https://mi2-warsaw.github.io/) - Group of mathematicians and computer scientists that love to play with data. ([GitHub](https://github.com/ModelOriented))
- [Papers of Robust ML](https://github.com/P2333/Papers-of-Robust-ML) - Mainly focus on defenses.
- [Why Deep Learning Works Even Though It Shouldn’t (2020)](https://moultano.wordpress.com/2020/10/18/why-deep-learning-works-even-though-it-shouldnt/) ([Lobsters](https://lobste.rs/s/qzbfzc/why_deep_learning_works_even_though_it))
- [Some Notable Recent ML Papers and Future Trends (2020)](https://arankomatsuzaki.wordpress.com/2020/10/15/some-notable-recent-ml-papers-and-future-trends/)
- [Wiki: 2020 ML Interviews Resources & Advice(s)](https://forums.fast.ai/t/wiki-2020-ml-interviews-resources-advice-s/70528)
- [Interpretable Machine Learning -- A Brief History, State-of-the-Art and Challenges (2020)](https://arxiv.org/abs/2010.09337)
- [Over 200 of the Best Machine Learning, NLP, and Python Tutorials (2018)](https://medium.com/machine-learning-in-practice/over-200-of-the-best-machine-learning-nlp-and-python-tutorials-2018-edition-dd8cf53cb7dc)
- [What is a Feature Store? (2020)](https://www.tecton.ai/blog/what-is-a-feature-store/)
- [Awesome AutoML Papers](https://github.com/hibayesian/awesome-automl-papers) - Curated list of automated machine learning papers, articles.
- [Machine Learning Systems Design at Stanford course (2020)](https://huyenchip.com/2020/10/27/ml-systems-design-stanford.html)
- [Preferred Networks](https://preferred.jp/en/) - Develops practical applications of deep learning and other cutting-edge technologies. ([GitHub](https://github.com/pfnet))
- [ML Art](https://mlart.co/) - Curated showcase of creative machine learning artworks and projects.
- [Decision Making under Uncertainty course](https://web.stanford.edu/class/aa228/cgi-bin/wp/) ([Algorithms for Decision Making book](https://github.com/sisl/algorithmsbook/)) ([Concise Deep Learning Overview (2020)](https://web.stanford.edu/group/sisl/public/dm/chapter-31.pdf) ([HN](https://news.ycombinator.com/item?id=24908999))) ([Book Website](https://algorithmsbook.com/))
- [Effective testing for machine learning systems (2020)](https://www.jeremyjordan.me/testing-ml/)
- [Reading List for Topics in Multimodal Machine Learning](https://github.com/pliang279/awesome-multimodal-ml)
- [Awesome Multimodal Research](https://github.com/Eurus-Holmes/Awesome-Multimodal-Research)
- [ML and DL related contests, competitions and conference challenges](https://github.com/skrish13/ml-contests-conf)
- [ML Visuals](https://github.com/dair-ai/ml-visuals) - Contains figures and templates which you can reuse and customize to improve your scientific writing.
- [DL Visuals](https://github.com/dvgodoy/dl-visuals) - Deep Learning Visuals.
- [Deep Learning with Catalyst course](https://github.com/catalyst-team/dl-course)
- [OpenMined Courses](https://courses.openmined.org/) - Learn how privacy technology is changing our world and how you can lead the charge.
- [Adversarial ML Threat Matrix](https://github.com/mitre/advmlthreatmatrix)
- [DeepMind Educational Resources](https://github.com/deepmind/educational)
- [Deep Learning (for Audio) with Python](https://www.youtube.com/playlist?list=PL-wATfeyAMNrtbkCNsLcpoAyBBRJZVlnf) ([Code](https://github.com/musikalkemist/DeepLearningForAudioWithPython))
- [Awesome Tensor Compilers](https://github.com/merrymercy/awesome-tensor-compilers)
- [Adversarial Robustness Toolbox](https://github.com/Trusted-AI/adversarial-robustness-toolbox) - Python library for Machine Learning Security.
- [AI Summer](https://theaisummer.com/) - Learn Deep Learning and Artificial Intelligence. ([GitHub](https://github.com/The-AI-Summer))
- [How Attention works in Deep Learning (2020)](https://theaisummer.com/attention/)
- [Brain Tokyo Workshop](https://github.com/google/brain-tokyo-workshop) - Research materials released by members of the Google Brain team in Tokyo.
- [A Novel Framework for Explaining Machine Learning Using Shapley Values (2020)](https://arxiv.org/abs/1909.08128) ([HN](https://news.ycombinator.com/item?id=25180778))
- [create-ml-app](https://github.com/shreyashankar/create-ml-app) - Template Makefile for ML projects in Python.
- [telesto.ai](https://telesto.ai/) - Competitive marketplace, where you can work on real-life machine learning challenges.
- [ML from the Fundamentals](https://rickwierenga.com/blog/ml-fundamentals) - Machine learning in a "from the first principles" style. ([Code](https://github.com/rickwierenga/MLFundamentals))
- [Interpretability in Machine Learning: An Overview (2020)](https://thegradient.pub/interpretability-in-ml-a-broad-overview/)
- [Implicit Rank-Minimizing Autoencoder (2020)](https://arxiv.org/abs/2010.00679) ([Code](https://github.com/facebookresearch/irmae))
- [ML/CV/NLP study resources](https://github.com/mileistone/study_resources)
- [MIT Mądry Lab](http://madry-lab.ml/) - Towards a Principled Science of Deep Learning. ([GitHub](https://github.com/MadryLab))
- [Scaling Down Deep Learning (2020)](https://greydanus.github.io/2020/12/01/scaling-down/) ([HN](https://news.ycombinator.com/item?id=25314066))
- [Every Model Learned by Gradient Descent Is Approximately a Kernel Machine (2020)](https://arxiv.org/abs/2012.00152) ([HN](https://news.ycombinator.com/item?id=25314830))
- [DeepFaceLab](https://github.com/iperov/DeepFaceLab) - Leading software for creating deepfakes.
- [Deep Learning DIY](https://dataflowr.github.io/website/) ([Code](https://github.com/dataflowr/notebooks)) ([GitHub](https://github.com/dataflowr)) ([Website Code](https://github.com/dataflowr/website))
- [Using JAX to accelerate our research (2020)](https://deepmind.com/blog/article/using-jax-to-accelerate-our-research) ([HN](https://news.ycombinator.com/item?id=25332526))
- [Stanford MLSys Seminar Series (2020)](https://mlsys.stanford.edu/)
- [MLCommons](https://mlcommons.org/en/) - Machine learning innovation to benefit everyone.
- [Automated discovery of machine learning optimizations (2020)](https://searchworks.stanford.edu/view/13680855)
- [A Visual Tour of Backpropagation (2020)](https://blog.jinay.dev/posts/backprop/)
- [Deep Learning GPU Benchmarks](https://lambdalabs.com/gpu-benchmarks) ([Code](https://github.com/lambdal/lambda-tensorflow-benchmark))
- [What I wish someone had told me about tensor computation libraries (2020)](https://eigenfoo.xyz/tensor-computation-libraries/) ([HN](https://news.ycombinator.com/item?id=25435028))
- [Machine learning could be fundamentally unexplainable (2020)](https://cerebralab.com/Machine_learning_could_be_fundamentally_unexplainable)
- [Minimum Viable Study Plan for Machine Learning Interviews](https://github.com/khangich/machine-learning-interview)
- [Awesome JAX](https://github.com/n2cholas/awesome-jax)
- [Machine Learning Productivity Hacks (2019)](http://amid.fish/ml-productivity)
- [Learn Deep Learning: Powerful Mental Models to Accelerate Your Journey (2020)](https://gumroad.com/l/learn_deep_learning) ([Tweet](https://twitter.com/radekosmulski/status/1340705699521769474))
- [OpenNMT](https://opennmt.net/) - Open source ecosystem for neural machine translation and neural sequence learning. ([GitHub](https://github.com/OpenNMT))
- [How much hyperparameter tuning do you typically end up doing? (2020)](https://www.reddit.com/r/MachineLearning/comments/khyk9r/d_for_those_in_the_industry_how_much/)
- [ZenML](https://github.com/zenml-io/zenml) - Extensible, open-source MLOps framework for using production-ready Machine Learning pipelines. ([Web](https://zenml.io/home))
- [MIT Parallel Computing and Scientific Machine Learning course (2020)](https://github.com/mitmath/18337)
- [Invariant Risk Minimization (2019)](https://arxiv.org/abs/1907.02893v1) ([Code](https://github.com/facebookresearch/InvariantRiskMinimization))
- [Awesome Federated Learning](https://github.com/chaoyanghe/Awesome-Federated-Learning)
- [Awesome Fraud Detection Research Papers](https://github.com/benedekrozemberczki/awesome-fraud-detection-papers)
- [Probabilistic Machine Learning: An Introduction](https://probml.github.io/pml-book/book1.html) ([HN](https://news.ycombinator.com/item?id=25593262))
- [Awesome Machine Learning Interpretability](https://github.com/jphall663/awesome-machine-learning-interpretability)
- [Reflections on my (Machine Learning) PhD Journey (2020)](https://maithraraghu.com/blog/2020/Reflections_on_my_Machine_Learning_PhD_Journey/)
- [ML beyond Curve Fitting: An Intro to Causal Inference and do-Calculus (2018)](https://www.inference.vc/untitled/) ([HN](https://news.ycombinator.com/item?id=25645205))
- [Distributed deep learning and inference without sharing raw data](https://splitlearning.github.io/) ([Code](https://github.com/splitlearning/splitlearning.github.io))
- [Famous ML papers/concepts that are hard to understand (2021)](https://www.reddit.com/r/MachineLearning/comments/krkxog/d_lets_start_2021_by_confessing_to_which_famous/)
- [MLJAR Automated Machine Learning](https://github.com/mljar/mljar-supervised) - Automates Machine Learning Pipeline with Feature Engineering and Hyper-Parameters Tuning. ([Web](https://mljar.com/)) ([HN](https://news.ycombinator.com/item?id=25644733))
- [Best of Machine Learning with Python](https://github.com/ml-tooling/best-of-ml-python)
- [Deep Learning's Most Important Ideas - A Brief Historical Review (2020)](https://dennybritz.com/blog/deep-learning-most-important-ideas/)
- [Awesome Anomaly Detection](https://github.com/hoya012/awesome-anomaly-detection)
- [Extending JAX with custom C++ and CUDA code](https://github.com/dfm/extending-jax)
- [Mathematical Engineering of Deep Learning Course (2021)](https://deeplearningmath.org/)
- [Paper List for Style Transfer in Text](https://github.com/fuzhenxin/Style-Transfer-in-Text)
- [Machine learning with large-scale graphs course](https://snap-stanford.github.io/cs224w-notes/) ([Notes](https://github.com/snap-stanford/cs224w-notes))
- [Single-Machine Simulation of Federated Learning Systems (2021)](https://flower.dev/blog/2021-01-14-single-machine-simulation-of-federated-learning-systems)
- [Awesome AutoML](https://github.com/windmaple/awesome-AutoML)
- [Optimization Methods for Machine Learning and Engineering (2021)](https://www.youtube.com/playlist?list=PLdkTDauaUnQpzuOCZyUUZc0lxf4-PXNR5)
- [Three mysteries in deep learning: Ensemble, knowledge distillation, and self-distillation (2021)](https://www.microsoft.com/en-us/research/blog/three-mysteries-in-deep-learning-ensemble-knowledge-distillation-and-self-distillation/)
- [Awesome Federated Computing](https://github.com/tushar-semwal/awesome-federated-computing)
- [Noah ML Research](https://github.com/huawei-noah/noah-research) - Research related code released by Huawei Noah's Ark Lab.
- [Prototypical Networks for Few-shot Learning (2017)](https://arxiv.org/abs/1703.05175) ([Code](https://github.com/orobix/Prototypical-Networks-for-Few-shot-Learning-PyTorch))
- [Domain generalization papers/resources](https://github.com/amber0309/Domain-generalization)
- [The Universal Training Loop of Machine Learning (2021)](https://liuliu.me/eyes/the-universal-training-loop-of-machine-learning/)
- [Learning Curve Theory (2021)](https://arxiv.org/abs/2102.04074)
- [ML Surveys](https://github.com/eugeneyan/ml-surveys) - Survey papers summarizing advances in deep learning, NLP, CV, graphs, reinforcement learning, recommendations, graphs, etc.
- [Practical Deep Learning Course](https://github.com/yandexdataschool/Practical_DL)
- [Diverse Counterfactual Explanations (DiCE) for ML](https://github.com/interpretml/DiCE) - Generate Diverse Counterfactual Explanations for any machine learning model. ([Docs](https://interpret.ml/DiCE/))
- [Interpretable Machine Learning](https://github.com/navdeep-G/interpretable-ml) - Techniques & resources for training interpretable ML models, explaining ML models, and debugging ML models.
- [Awesome Causality](https://github.com/napsternxg/awesome-causality) - Resources related to causality.
- [How to Understand ML Papers Quickly (2021)](https://blog.evjang.com/2021/01/understanding-ml.html)
- [Patterns, Predictions, and Actions Book](https://mlstory.org/) - A story about machine learning.
- [Full Stack Deep Learning Course (2021)](https://fullstackdeeplearning.com/spring2021/) ([Code](https://github.com/filipafcastro/fullstack_deeplearning_course))
- [Physical Principles for Scalable Neural Recording](https://arxiv.org/ftp/arxiv/papers/1306/1306.5709.pdf)
- [Learn About Transformers: A Recipe (2021)](https://elvissaravia.substack.com/p/learn-about-transformers-a-recipe)
- [An Inferential Perspective on Federated Learning (2021)](https://blog.ml.cmu.edu/2021/02/19/an-inferential-perspective-on-federated-learning/)
- [Free Lunch for Few-shot Learning: Distribution Calibration (2020)](https://arxiv.org/abs/2101.06395) ([Code](https://github.com/ShuoYang-1998/Few_Shot_Distribution_Calibration))
- [Enlightening Guide to Machine Learning Interviews](https://github.com/alirezadir/machine-learning-interview-enlightener)
- [How Machine Language Works (2021)](https://www.youtube.com/watch?v=HWpi9n2H3kE)
- [Sliced Score Matching: A Scalable Approach to Density and Score Estimation (2019)](https://yang-song.github.io/blog/2019/ssm/)
- [Accelerating Natural Gradient with Higher-Order Invariance (2018)](https://yang-song.github.io/blog/2018/geo/)
- [Some interesting observations about machine learning publication practices from an outsider (2021)](https://www.reddit.com/r/MachineLearning/comments/lvwt3l/d_some_interesting_observations_about_machine/)
- [Understanding deep learning requires rethinking generalization (2021)](https://cacm.acm.org/magazines/2021/3/250713-understanding-deep-learning-still-requires-rethinking-generalization/fulltext) ([HN](https://news.ycombinator.com/item?id=26346226))
- [MIT HAN Lab](https://hanlab.mit.edu/) - Accelerate Deep Learning Computing. ([GitHub](https://github.com/mit-han-lab))
- [Feature Stores - A Hierarchy of Needs (2021)](https://eugeneyan.com/writing/feature-stores/)
- [Visualizing Representations: Deep Learning and Human Beings (2015)](http://colah.github.io/posts/2015-01-Visualizing-Representations/) ([Tweet](https://twitter.com/ch402/status/1367586896801492992))
- [Transformers](https://github.com/sannykim/transformers) - Collection of resources to study Transformers in depth.
- [Incomplete Deep Learning Guide](https://github.com/sannykim/deep-learning-guide)
- [A Year at Google Brain (2020)](https://www.debugmind.com/2020/01/04/paths-to-the-future-a-year-at-google-brain/) ([HN](https://news.ycombinator.com/item?id=26374143))
- [Pretrained Transformers as Universal Computation Engines (2021)](https://arxiv.org/abs/2103.05247) ([Code](https://github.com/kzl/universal-computation))
- [Testing Machine Learning Systems: Code, Data and Models](https://madewithml.com/courses/applied-ml/testing/) ([Tweet](https://twitter.com/GokuMohandas/status/1369261247993176066))
- [Finding Mona Lisa in the Game of Life (2021)](https://avinayak.github.io/algorithms/programming/2021/02/19/finding-mona-lisa-in-the-game-of-life.html) ([HN](https://news.ycombinator.com/item?id=26384403))
- [Geometric deep learning, from Euclid to drug design (2021)](https://www.youtube.com/watch?v=8IwJtFNXr1U&t=210s) ([Reddit](https://www.reddit.com/r/MachineLearning/comments/m8ewph/geometric_foundations_of_deep_learning_research/))
- [GeoGuessing with Deep Learning (2021)](https://healeycodes.com/geoguessing-with-deep-learning/)
- [Awesome Incremental Learning / Lifelong learning](https://github.com/xialeiliu/Awesome-Incremental-Learning)
- [Out of Distribution Generalization in Machine Learning (2021)](https://arxiv.org/abs/2103.02667)
- [Label Errors](https://labelerrors.com/) - Label errors in benchmark ML test sets. ([Lobsters](https://lobste.rs/s/v28crd/label_errors_benchmark_ml_test_sets)) ([Code](https://github.com/cleanlab/label-errors))
- [What will the major ML research trends be in the 2020s?](https://www.reddit.com/r/MachineLearning/comments/mfnhki/d_what_will_the_major_ml_research_trends_be_in/)
- [Machine Learning and Deep Learning Courses (2021)](https://elvissaravia.substack.com/p/machine-learning-and-deep-learning)
- [Awesome Domain Adaptation](https://github.com/zhaoxin94/awesome-domain-adaptation)
- [Why machine learning struggles with causality (2021)](https://bdtechtalks.com/2021/03/15/machine-learning-causality/)
- [TabNet: Attentive Interpretable Tabular Learning (2020)](https://arxiv.org/abs/1908.07442) ([Code](https://github.com/dreamquark-ai/tabnet))
- [AutoML.org](https://www.automl.org/) ([GitHub](https://github.com/automl))
- [How I built a €25K Machine Learning Rig (2021)](https://www.emilwallner.com/p/ml-rig) ([Reddit](https://www.reddit.com/r/MachineLearning/comments/ml6u5u/p_how_i_built_a_25k_machine_learning_rig/))
- [Learning Fast Algorithms for Linear Transforms Using Butterfly Factorizations (2019)](https://arxiv.org/abs/1903.05895)
- [Machine Learning Collection](https://github.com/aladdinpersson/Machine-Learning-Collection) - Resource for learning about ML, DL, PyTorch and TensorFlow.
- [Joint Universal Syntactic and Semantic Parsing (2021)](https://arxiv.org/abs/2104.05696)
- [A Comprehensive Introduction to Bayesian Deep Learning (2021)](https://www.topbots.com/comprehensive-introduction-to-bayesian-deep-learning/)
- [Stanford Machine Learning with Graphs Course (2021)](http://web.stanford.edu/class/cs224w/)
- [Keepsake](https://github.com/replicate/keepsake) - Version control for machine learning. ([Web](https://keepsake.ai/))
- [Learning Versatile Neural Architectures by Propagating Network Codes](https://github.com/dingmyu/NCP)
- [Machine learning is going real-time (2020)](https://huyenchip.com/2020/12/27/real-time-machine-learning.html)
- [Awesome Normalizing Flows](https://github.com/janosh/awesome-normalizing-flows)
- [Differentiable Model Compression via Pseudo Quantization Noise (2021)](https://arxiv.org/abs/2104.09987) ([Code](https://github.com/facebookresearch/diffq))
- [The Rise of HuggingFace (2021)](https://marksaroufim.substack.com/p/huggingface)
- [See through Gradients: Image Batch Recovery via GradInversion (2021)](https://arxiv.org/abs/2104.07586) ([Reddit](https://www.reddit.com/r/MachineLearning/comments/n0o6dn/d_new_paper_shows_that_federated_learning_is/))
- [Recommendation System using ML and DL](https://github.com/amitkaps/recommendation)
- [Mathematical Foundations of Machine Learning (2020)](https://www.dropbox.com/s/mffzmuo9fvs5j6m/Study_Guide.pdf)
- [How to Write Design Docs for Machine Learning Systems](https://eugeneyan.com/writing/ml-design-docs/) ([Code](https://github.com/eugeneyan/ml-design-docs))
- [Reproducible Deep Learning (2021)](https://www.sscardapane.it/teaching/reproducibledl/) - PhD Course in Data Science. ([Code](https://github.com/sscardapane/reprodl2021))
- [Unsupervised Contrastive Learning of Sound Event Representations (2020)](https://arxiv.org/abs/2011.07616) ([Code](https://github.com/edufonseca/uclser20/blob/main/README.md))
- [Differentially Private Learning Needs Better Features (or Much More Data) (2021)](https://arxiv.org/abs/2011.11660)
- [Bias, variance, and their relationship with machine learning algorithms explained (2021)](https://twitter.com/svpino/status/1390969728504565761)
- [Unsupervised Contrastive Learning of Sound Event Representations](https://github.com/edufonseca/uclser20)
- [Kobra](https://kobra.dev/) - Visual programming language for machine learning. ([HN](https://news.ycombinator.com/item?id=27135573))
- [Delving into Deep Imbalanced Regression (2021)](https://arxiv.org/abs/2102.09554) ([Code](https://github.com/YyzHarry/imbalanced-regression))
- [Comprehensive Survey on Transfer Learning](http://datamining.rutgers.edu/publication/A%20Comprehensive%20Survey%20on%20Transfer%20Learning.pdf)
- [Applied Deep Learning Course](https://github.com/maziarraissi/Applied-Deep-Learning) ([Videos](https://www.youtube.com/playlist?list=PLoEMreTa9CNmuxQeIKWaz7AVFd_ZeAcy4))
- [Pay Attention to MLPs (2021)](https://arxiv.org/abs/2105.08050) ([Tweet](https://twitter.com/Hanxiao_6/status/1394742841033641985)) ([Code](https://github.com/lucidrains/g-mlp-pytorch))
- [E(n) Equivariant Normalizing Flows for Molecule Generation in 3D (2021)](https://arxiv.org/abs/2105.09016) ([Tweet](https://twitter.com/wellingmax/status/1395281027824857088))
- [Fast and Slow Learning of Recurrent Independent Mechanisms (2021)](https://arxiv.org/abs/2105.08710) ([Tweet](https://twitter.com/anirudhg9119/status/1395889099102380032))
- [Weekly Papers](https://papers.labml.ai/papers/weekly) ([Daily](https://papers.labml.ai/papers/daily))
- [Sharpness-Aware Minimization for Efficiently Improving Generalization (2020)](https://arxiv.org/abs/2010.01412) ([Code](https://github.com/Jannoshh/simple-sam))
- [Apple - Making Mobile Applications Accessible with Machine Learning (2021)](https://machinelearning.apple.com/research/mobile-applications-accessible)
- [NYU Deep Learning Spring 2021](https://github.com/Atcold/NYU-DLSP21) ([Videos](https://www.youtube.com/playlist?list=PLLHTzKZzVU9e6xUfG10TkTWApKSZCzuBI))
- [JAX learning resources (2021)](https://www.reddit.com/r/MachineLearning/comments/no3r7m/d_jax_learning_resources/)
- [Machine Learning with Python Cookbook Book (2018)](https://www.oreilly.com/library/view/machine-learning-with/9781491989371/)
- [Understanding Dimensionality Reduction with UMAP](https://pair-code.github.io/understanding-umap/)
- [Neural Algorithmic Reasoning (2021)](https://arxiv.org/abs/2105.02761) ([Tweet](https://twitter.com/s_scardapane/status/1399378122894684166))
- [A Pragmatic Look at Deep Imitation Learning](https://github.com/Kaixhin/imitation-learning)
- [Stanford CS229: Machine Learning Course (2021)](http://cs229.stanford.edu/) ([Notes](https://github.com/mossr/machine_learning_book))
- [Informative Dropout for Robust Representation Learning: A Shape-bias Perspective (2020)](https://arxiv.org/abs/2008.04254) ([Code](https://github.com/bfshi/InfoDrop))
- [Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval (2020)](https://arxiv.org/abs/2007.00808) ([Code](https://github.com/microsoft/ANCE))
- [Fairification: Making Unfair Programs Fair (2017)](https://barghouthi.github.io/2017/05/01/debiasing/)
- [Fairness and machine learning: Limitations and Opportunities](https://fairmlbook.org/)
- [Practical Deep Learning for Cloud, Mobile, and Edge (2019)](https://www.oreilly.com/library/view/practical-deep-learning/9781492034858/)
- [Pretrained Encoders are All You Need (2021)](https://arxiv.org/abs/2106.05139) ([Code](https://github.com/PAL-ML/PEARL_v1))
- [The Modern Mathematics of Deep Learning (2021)](https://arxiv.org/abs/2105.04026) ([HN](https://news.ycombinator.com/item?id=27485574))
- [An Attention Free Transformer (2021)](https://arxiv.org/abs/2105.14103) ([Code](https://github.com/rish-16/aft-pytorch))
- [Towards Causal Representation Learning (2021)](https://arxiv.org/abs/2102.11107)
- [SAINT: Improved Neural Networks for Tabular Data via Row Attention and Contrastive Pre-Training (2021)](https://arxiv.org/abs/2106.01342) ([Code](https://github.com/somepago/saint))
- [AdaMatch: A Unified Approach to Semi-Supervised Learning and Domain Adaptation (2021)](https://arxiv.org/abs/2106.04732) ([Video](https://www.youtube.com/watch?v=ORufPOY8H14))
- [Distributed Machine Learning Patterns Book (2021)](https://www.manning.com/books/distributed-machine-learning-patterns) ([Code](https://github.com/terrytangyuan/distributed-ml-patterns))
- [Revisiting Deep Learning Models for Tabular Data (2021)](https://arxiv.org/abs/2106.11959)
- [Introduction to Machine Learning Interviews Book](https://huyenchip.com/ml-interviews-book/) ([Code](https://github.com/chiphuyen/ml-interviews-book))
- [Introduction to Machine Learning 2019 at ETH Zürich](https://las.inf.ethz.ch/teaching/introml-s19) ([Summary](https://github.com/eth-cs-student-summaries/Introduction-to-Machine-Learning))
- [Awesome Community Detection Research Papers](https://github.com/benedekrozemberczki/awesome-community-detection)
- [Understanding Deep Learning (2021)](https://www.youtube.com/playlist?list=PLFE-LjWAAP9Q74cGaUF3yqUhqo2kOYY20)
- [The Scaling Hypothesis](https://www.gwern.net/Scaling-hypothesis)
- [ML YouTube Courses](https://github.com/dair-ai/ML-YouTube-Courses)
- [Neuromatch Academy Deep Learning (NMA-DL) syllabus](https://github.com/NeuromatchAcademy/course-content-dl)
- [Stanford AI Lab Papers and Talks at CVPR 2021](https://ai.stanford.edu/blog/cvpr-2021/)
- [SCARF: Self-Supervised Contrastive Learning using Random Feature Corruption (2021)](https://arxiv.org/abs/2106.15147)
- [Machine Learning for Beginners - A Curriculum](https://github.com/microsoft/ML-For-Beginners)
- [You Don’t Need Math For Machine Learning (2021)](https://towardsdatascience.com/you-dont-need-math-for-machine-learning-e168b7d973d4)
- [Data Augmentation Resources](https://github.com/AgaMiko/data-augmentation-review)
- [Extremely revealing books that explains everything behind machine learning? (2021)](https://www.reddit.com/r/learnmachinelearning/comments/ofnl9d/extremely_revealing_books_that_explains/)
- [ML@B](https://ml.berkeley.edu/) - Machine Learning at Berkeley.
- [Awesome Graph Self-Supervised Learning](https://github.com/LirongWu/awesome-graph-self-supervised-learning)
- [Contrastive Representation Learning (2021)](https://lilianweng.github.io/lil-log/2021/05/31/contrastive-representation-learning.html) ([HN](https://news.ycombinator.com/item?id=27812862))
- [Learn Machine Learning Resources](https://machinelearning.to/)
- [Popular Machine Learning Interview Questions (2021)](https://www.thinkdataanalytics.com/machine-learning-interview-questions/)
- [Solving Machine Learning Performance Anti-Patterns: a Systematic Approach (2021)](https://paulbridger.com/posts/nsight-systems-systematic-optimization/)
- [Bayesian learning via stochastic gradient langevin dynamics (2011)](https://dl.acm.org/doi/10.5555/3104482.3104568)
- [Megaverse: Simulating Embodied Agents at One Million Experiences per Second](https://www.megaverse.info/) ([Paper](https://arxiv.org/abs/2107.08170)) ([Code](https://github.com/alex-petrenko/megaverse))
- [Detecting Adversarial Examples Is (Nearly) As Hard As Classifying Them (2021)](https://openreview.net/forum?id=6pgY2PkoXb0) ([Tweet](https://twitter.com/florian_tramer/status/1418911926508216321))
- [Linear unit-tests for invariance discovery (2021)](https://arxiv.org/abs/2102.10867) ([Code](https://github.com/facebookresearch/InvarianceUnitTests))
- [In Search of Lost Domain Generalization (2020)](https://arxiv.org/abs/2007.01434) ([Code](https://github.com/facebookresearch/DomainBed))
- [Understanding and improving out-of-distribution generalisation with Agnieszka Słowik (2021)](https://www.youtube.com/watch?v=W3XE9yD5H4A)
- [Algorithmic Concept-based Explainable Reasoning (2021)](https://arxiv.org/abs/2107.07493) ([Tweet](https://twitter.com/PetarV_93/status/1415937593225760771))
- [Tsinghua Machine Learning Group](https://ml.cs.tsinghua.edu.cn/) ([GitHub](https://github.com/thu-ml))
- [Zero-Shot Learning Resources](https://github.com/sbharadwajj/awesome-zero-shot-learning)
- [Machine Learning Collection](https://github.com/microsoft/machine-learning-collection)
- [Open MLOps – Open-Source Production Machine Learning (2021)](https://datarevenue.com/en-blog/open-mlops-open-source-production-machine-learning) ([HN](https://news.ycombinator.com/item?id=28052182))
- [A Gentle Introduction To Gradient Descent Procedure (2021)](https://machinelearningmastery.com/a-gentle-introduction-to-gradient-descent-procedure/)
- [Stanford MLSys Seminars](https://www.youtube.com/playlist?list=PLSrTvUm384I9PV10koj_cqit9OfbJXEkq)
- [Painless Uncertainty for Deep Learning (2021)](https://www.machinelearningforscience.de/en/painless-uncertainty-for-deep-learning/)
- [How to avoid machine learning pitfalls: a guide for academic researchers (2021)](https://arxiv.org/abs/2108.02497)
- [MLOps-Basics](https://github.com/graviraja/MLOps-Basics)
- [Machine & Deep Learning Compendium](https://book.mlcompendium.com/) ([Code](https://github.com/orico/www.mlcompendium.com))
- [Differentiable Factor Graph Optimization for Learning Smoothers (2021)](https://github.com/brentyi/dfgo)
- [A visual introduction to Gaussian Belief Propagation (2021)](https://gaussianbp.github.io/) ([HN](https://news.ycombinator.com/item?id=28367177))
- [Bootstrap your own latent: A new approach to self-supervised Learning (2020)](https://arxiv.org/abs/2006.07733) ([Code](https://github.com/Spijkervet/BYOL))
- [Tutorial: Performance Engineering for Machine Learning and Scientific Computing (2017)](https://dblalock.github.io/Performance-Engineering-Tutorial/)
- [Must-read papers on Recommender System](https://github.com/hongleizhang/RSPapers)
- [Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts (2018)](http://www.kdd.org/kdd2018/accepted-papers/view/modeling-task-relationships-in-multi-task-learning-with-multi-gate-mixture-) ([Code](https://github.com/drawbridge/keras-mmoe))
- [Machine Learning Bookcamp: Build a portfolio of real-life projects (2021)](https://www.manning.com/books/machine-learning-bookcamp) ([Code](https://github.com/alexeygrigorev/mlbookcamp-code))
- [Product Recommendations (2019)](http://bugra.github.io/posts/2019/8/15/product-recommendations/)
- [Stanford CRFM](https://crfm.stanford.edu/) - Stanford Center for Research on Foundation Models. ([GitHub](https://github.com/stanford-crfm))
- [[1810.04650] Multi-Task Learning as Multi-Objective Optimization (2019)](https://arxiv.org/abs/1810.04650) ([Code](https://github.com/isl-org/MultiObjectiveOptimization))
- [Hyperparameter Search with spaCy and Weights & Biases (2021)](https://wandb.ai/wandb/wandb_spacy_sweeps/reports/Hyperparameter-Search-with-spaCy-and-Weights-Biases--Vmlldzo5NDA2MjE) ([Tweet](https://twitter.com/_ScottCondron/status/1435981838212911109))
- [Dive into Machine Learning](https://github.com/hangtwenty/dive-into-machine-learning)
- [The Values Encoded in Machine Learning Research (2021)](https://arxiv.org/abs/2106.15590) ([Tweet](https://twitter.com/tdietterich/status/1439666761834459136))
- [An overview of the theory of overparameterized machine learning (2021)](https://arxiv.org/abs/2109.02355)
- [Geometric Deep Learning Blueprint (2021)](https://www.youtube.com/watch?v=bIZB1hIJ4u8)
- [Multi-Armed Bandits and Pure-Exploration (2020)](https://www.youtube.com/watch?v=h-dYzjF8eFA)
- [The First Rule of Machine Learning: Start Without Machine Learning (2021)](https://eugeneyan.com/writing/first-rule-of-ml/) ([HN](https://news.ycombinator.com/item?id=28613099))
- [An Introduction to Weighted Automata in Machine Learning (2021)](https://awnihannun.com/writing/automata_ml.html) ([Code](https://github.com/awni/automata_ml))
- [Ultimate FREE Machine Learning Study Plan](https://github.com/python-engineer/ml-study-plan)
- [node2vec: Scalable Feature Learning for Networks](https://snap.stanford.edu/node2vec/) ([Code](https://github.com/aditya-grover/node2vec))
- [Learning to Superoptimize Real-world Programs (2021)](https://arxiv.org/abs/2109.13498)
- [Data Movement Is All You Need: A Case Study on Optimizing Transformers (2020)](https://arxiv.org/abs/2007.00072) ([Code](https://github.com/spcl/substation))
- [Reading List for Topics in Representation Learning](https://github.com/Mehooz/awesome-representation-learning)
- [Курс по машинному обучению для 3 курса факультета ВМК МГУ (2021)](https://github.com/MSU-ML-COURSE/ML-COURSE-21-22)
- [Deep Learning with Python, Second Edition (2021)](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff) ([Code](https://github.com/fchollet/deep-learning-with-python-notebooks))
- [Some ML tools (2021)](https://twitter.com/GaryMarcus/status/1447206961045336066)
- [Unsolved Problems in ML Safety (2021)](https://arxiv.org/abs/2109.13916) ([HN](https://news.ycombinator.com/item?id=28809233))
- [Evaluating Predictive Distributions: Does Bayesian Deep Learning Work? (2021)](https://arxiv.org/abs/2110.04629) ([Code](https://github.com/deepmind/neural_testbed)) ([Tweet](https://twitter.com/DeepMind/status/1447975332489859076))
- [Arsenii Ashukha: Ensemble Generation (2020)](https://www.youtube.com/watch?v=bj933t6rqFw)
- [Imitating Deep Learning Dynamics via Stochastic Differential Equations (2021)](https://arxiv.org/abs/2110.05960) ([HN](https://news.ycombinator.com/item?id=28864171))
- [What are some ideas that are hyped up in machine learning research but don't actually get used in industry (and vice versa)? (2021)](https://www.reddit.com/r/MachineLearning/comments/q86kqn/d_what_are_some_ideas_that_are_hyped_up_in/)
- [Variational Graph Auto-Encoders (2016)](https://arxiv.org/abs/1611.07308) ([Code](https://github.com/DaehanKim/vgae_pytorch))
- [Diffusion Normalizing Flow (2021)](https://arxiv.org/abs/2110.07579)
- [Approximately Correct Machine Intelligence (ACMI) Lab](https://acmilab.org/) - Research on machine learning, its social impacts, and applications to healthcare. ([GitHub](https://github.com/acmi-lab)) ([Twitter](https://twitter.com/acmi_lab))
- [Machine Learning, Kolmogorov Complexity, and Squishy Bunnies (2019)](https://theorangeduck.com/page/machine-learning-kolmogorov-complexity-squishy-bunnies)
- [Fast Machine Learning Lab](https://fastmachinelearning.org/) ([GitHub](https://github.com/fastmachinelearning))
- [Meaning of interpolation in ML (2021)](https://twitter.com/fchollet/status/1450524400227287040)
- [Learning in High Dimension Always Amounts to Extrapolation (2021)](https://arxiv.org/abs/2110.09485) ([Tweet](https://twitter.com/ylecun/status/1450560732483948545))
- [Awesome Transformer Architecture Search](https://github.com/automl/awesome-transformer-search)
- [Katana ML Skipper](https://github.com/katanaml/katana-skipper) - Simple and flexible ML workflow engine. It helps to orchestrate events across a set of microservices and create executable flow to handle requests.
- [PaRoT: A Practical Framework for Robust Deep Neural Network Training (2021)](https://arxiv.org/abs/2001.02152)
- [Superposition of many models into one (2019)](https://arxiv.org/abs/1902.05522) ([Tweet](https://twitter.com/thisismyhat/status/1096480539601657856))
- [Meta-Learning Requires Meta-Augmentation (2020)](https://arxiv.org/abs/2007.05549)
- [Shaking the foundations: delusions in sequence models for interaction and control (2021)](https://arxiv.org/abs/2110.10819) ([Tweet](https://twitter.com/janexwang/status/1453027447151157251))
- [Introduction to Deep Learning (I2DL) (2021)](https://www.youtube.com/playlist?list=PLQ8Y4kIIbzy_OaXv86lfbQwPHSomk2o2e)
- [Mosaicking to Distill: Knowledge Distillation from Out-of-Domain Data (2021)](https://arxiv.org/abs/2110.15094) ([Code](https://github.com/zju-vipa/MosaicKD))
- [Advanced-Foundations-of-ML](https://github.com/yashsavani/Advanced-Foundations-of-ML)
- [Implicit MLE: Backpropagating Through Discrete Exponential Family Distributions (2021)](https://arxiv.org/abs/2106.01798) ([Code](https://github.com/uclnlp/torch-imle))
- [Deep Learning Recommendation Model for Personalization and Recommendation Systems](https://github.com/facebookresearch/dlrm)
- [MLflow Examples](https://github.com/amesar/mlflow-examples)
- [8-bit Optimizers via Block-wise Quantization (2021)](https://arxiv.org/abs/2110.02861) ([Code](https://github.com/facebookresearch/bitsandbytes))
- [Efficiently Modeling Long Sequences with Structured State Spaces (2021)](https://arxiv.org/abs/2111.00396) ([Code](https://github.com/HazyResearch/state-spaces))
- [Get started with JAX](https://github.com/gordicaleksa/get-started-with-JAX) ([Videos](https://www.youtube.com/playlist?list=PLBoQnSflObckOARbMK9Lt98Id0AKcZurq))
- [How does Jax allocate memory on a TPU? An interactive C++ walkthrough](https://gist.github.com/shawwn/0e524d4a7a5d8fb152a86616559cc02a) ([HN](https://news.ycombinator.com/item?id=29128998))
- [Skyformer: Remodel Self-Attention with Gaussian Kernel and Nyström Method (2021)](https://arxiv.org/abs/2111.00035) ([Code](https://github.com/pkuzengqi/Skyformer))
- [Introduction to Deep Learning (2021)](https://sebastianraschka.com/blog/2021/dl-course.html) - 170 Video Lectures from Adaptive Linear Neurons to Zero-shot Classification with Transformers.
- [Gradients are Not All You Need (2021)](https://arxiv.org/abs/2111.05803) ([Tweet](https://twitter.com/Luke_Metz/status/1458661090326286336))
- [FC2T2: The Fast Continuous Convolutional Taylor Transform with Applications in Vision and Graphics (2021)](https://arxiv.org/abs/2111.00110) ([Summary](https://www.youtube.com/watch?v=e6gXoMA5te4))
- [An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modelingvon (2018)](https://arxiv.org/abs/1803.01271) ([Code](https://github.com/locuslab/TCN))
- [Model compression via distillation and quantization (2019)](https://arxiv.org/abs/1802.05668) ([Code](https://github.com/antspy/quantized_distillation))
- [ML Collective](https://mlcollective.org/) - Independent, nonprofit organization with a mission to make research opportunities accessible and free. ([Classics and Trends](https://mlcollective.org/dlct/))
- [Awesome MLOps](https://github.com/kelvins/awesome-mlops)
- [Machine Learning Zoomcamp](https://github.com/alexeygrigorev/mlbookcamp-code/tree/master/course-zoomcamp) ([Code](https://github.com/ziritrion/ml-zoomcamp))
- [Yann LeCun’s 2021 Deep Learning Course at CDS (2021)](https://cds.nyu.edu/deep-learning/) ([HN](https://news.ycombinator.com/item?id=29218520))
- [Interactive Gradient Descent Demo (2021)](https://blog.skz.dev/gradient-descent)
- [Why Momentum Really Works (2017)](https://distill.pub/2017/momentum/)
- [HNPE: Leveraging Global Parameters for Neural Posterior Estimation (2021)](https://arxiv.org/abs/2102.06477) ([Tweet](https://twitter.com/plc_rodrigues/status/1460654220944809986))
- [Facebook AI Similarity Search (Faiss)](https://www.pinecone.io/learn/faiss-tutorial/) ([HN](https://news.ycombinator.com/item?id=29291047))
- [Combined Scaling for Zero-shot Transfer Learning (2021)](https://arxiv.org/abs/2111.10050)
- [Awesome Distributed Deep Learning](https://github.com/bharathgs/Awesome-Distributed-Deep-Learning)
- [Neuro Evolution Of Augmented Topologies (2021)](https://fev.al/posts/neat/) ([HN](https://news.ycombinator.com/item?id=29296158))
- [machine-config-operator](https://github.com/openshift/machine-config-operator) - Managing updates and configuration changes to essentially everything between the kernel and kubelet.
- [Factorized Fourier Neural Operators (2021)](https://arxiv.org/abs/2111.13802) ([Code](https://github.com/alasdairtran/fourierflow))
- [NeurIPS 2021 Best Paper Awards (2021)](https://blog.neurips.cc/2021/11/30/announcing-the-neurips-2021-award-recipients/)
- [What areas of deep learning are under-explored? (2021)](https://www.reddit.com/r/MachineLearning/comments/r9yzub/d_in_your_opinion_what_areas_of_deep_learning_are/)
- [cnvrg.io](https://cnvrg.io/) - Full Stack Machine Learning Operating System.
- [Learning with not Enough Data Part 1: Semi-Supervised Learning (2021)](https://lilianweng.github.io/lil-log/2021/12/05/semi-supervised-learning.html) ([HN](https://news.ycombinator.com/item?id=29456732))
- [Efficient Training of Audio Transformers with Patchout (2021)](https://arxiv.org/abs/2110.05069) ([Code](https://github.com/kkoutini/PaSST))
- [Machine Learning for Creativity and Design](https://neuripscreativityworkshop.github.io/2021/)
- [Maximum Likelihood Training of Score-Based Diffusion Models (2021)](https://arxiv.org/abs/2101.09258) ([Code](https://github.com/yang-song/score_flow))
- [Learning Gradient Fields for Shape Generation (2020)](http://www.cs.cornell.edu/~ruojin/ShapeGF/) ([Code](https://github.com/RuojinCai/ShapeGF))
- [Making Friends with Machine Learning - YouTube](https://www.youtube.com/playlist?list=PLRKtJ4IpxJpDxl0NTvNYQWKCYzHNuy2xG)
- [Schedule - NeurIPS 2021](https://deepmind.events/events/neurips2021/resources)
- [The Neural Data Router: Adaptive Control Flow in Transformers Improves Systematic Generalization (2021)](https://arxiv.org/abs/2110.07732) ([Code](https://github.com/RobertCsordas/ndr))
- [Momentum Residual Neural Networks (2021)](https://arxiv.org/abs/2102.07870) ([Code](https://github.com/michaelsdr/momentumnet))
- [Awesome-Zero-Shot-Learning](https://github.com/WilliamYi96/Awesome-Zero-Shot-Learning)
- [Awesome Treasure of Transformers Models Collection](https://github.com/ashishpatel26/Treasure-of-Transformers)
- [Self-attention Does Not Need $O(n^2)$ Memory (2021)](https://arxiv.org/abs/2112.05682v2) ([Code](https://github.com/AminRezaei0x443/memory-efficient-attention)) ([Code](https://github.com/lucidrains/memory-efficient-attention-pytorch))
- [Neural Discrete Representation Learning (2021)](https://arxiv.org/abs/1711.00937) ([Code](https://github.com/MishaLaskin/vqvae))
- [VSE++: Improving Visual-Semantic Embeddings with Hard Negatives (2018)](https://arxiv.org/abs/1707.05612) ([Code](https://github.com/fartashf/vsepp))
- [JAX ResNet](https://github.com/n2cholas/jax-resnet) - Implementations and checkpoints for ResNet, Wide ResNet, ResNeXt, ResNet-D, and ResNeSt in JAX (Flax).
- [Best AI and Deep learning books to read in 2022](https://theaisummer.com/deep-learning-books-2022/)
- [Machine Learning for Combinatorial Optimization - NeurIPS 2021 Competition](https://www.ecole.ai/2021/ml4co-competition/) ([Code](https://github.com/ds4dm/ml4co-competition))
- [Tutorial and Summary of Machine Learning](https://github.com/zchen0211/ML-tutorial)
- [Never Give Up: Learning Directed Exploration Strategies (2020)](https://arxiv.org/abs/2002.06038) ([Code](https://github.com/Coac/never-give-up))
- [A Step Toward Quantifying Independently Reproducible Machine Learning Research (2019)](https://arxiv.org/abs/1909.06674) ([Tweet](https://twitter.com/_onionesque/status/1476769719256498177))
- [ML Hub](https://github.com/ml-tooling/ml-hub) - Multi-user development platform for machine learning teams. Simple to setup within minutes.
- [Adversarial Explainable AI](https://github.com/hbaniecki/adversarial-explainable-ai)
- [AI/ML Tutorials List](https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials)
- [Awesome Diffusion Models](https://github.com/heejkoo/Awesome-Diffusion-Models)
- [Autoencoder-based deep metric learning for network intrusion detection (2021)](https://www.sciencedirect.com/science/article/abs/pii/S002002552100462X) ([Code](https://github.com/gsndr/RENOIR))
- [Graph Adversarial Learning Literature](https://github.com/safe-graph/graph-adversarial-learning-literature)
- [Trustworthy Machine Learning by Kush R. Varshney](http://www.trustworthymachinelearning.com/)
- [Recommender System Suits](https://github.com/hongleizhang/RSAlgorithms) - Open source toolkit for recommender system.
- [Randomized Ensembled Double Q-Learning: Learning Fast Without a Model (2021)](https://arxiv.org/abs/2101.05982) ([Code](https://github.com/watchernyu/REDQ))
- [STATS320: Machine Learning Methods for Neural Data Analysis Course (2021)](https://github.com/slinderman/stats320)
- [Deep Learning Interviews: Hundreds of fully solved job interview questions from a wide range of key topics in AI (2021)](https://arxiv.org/abs/2201.00650) ([Code](https://github.com/BoltzmannEntropy/interviews.ai)) ([HN](https://news.ycombinator.com/item?id=29876742))
- [Diffusion-Models-Seminar](https://github.com/sangyun884/Diffusion-Models-Seminar)
- [Awesome Graph Representation Learning](https://github.com/kaiyuanzh/awesome-graph-representation-learning)
- [Machine Learning System Resources (2022)](https://www.bodunhu.com/blog/posts/machine-learning-system-resources/)
- [Dynamic Tensor Rematerialization (2021)](https://arxiv.org/abs/2006.09616) ([Review](https://www.bodunhu.com/blog/posts/paper-review-dynamic-tensor-rematerialization/))
- [Designing a Practical Degradation Model for Deep Blind Image Super-Resolution (2021)](https://arxiv.org/abs/2103.14006) ([Code](https://github.com/cszn/BSRGAN))
- [A Theoretical Framework for Target Propagation (2020)](https://arxiv.org/abs/2006.14331) ([Code](https://github.com/meulemansalex/theoretical_framework_for_target_propagation))
- [SE(3)-Transformers: 3D Roto-Translation Equivariant Attention Networks (2020)](https://arxiv.org/abs/2006.10503) ([Code](https://github.com/FabianFuchsML/se3-transformer-public))
- [Iterative SE(3)-Transformers (2021)](https://arxiv.org/abs/2102.13419) ([Article](https://fabianfuchsml.github.io/se3iterative/))
- [Permutation Invariance, DeepSets and Universal Function Approximation](https://fabianfuchsml.github.io/permutationinvariance/)
- [Review: Deep Learning on Sets](https://fabianfuchsml.github.io/learningonsets/)
- [Contrastive Self-Supervised Learning (2020)](https://ankeshanand.com/blog/2020/01/26/contrative-self-supervised-learning.html)
- [Top AI Conference Papers with Code](https://github.com/MLNLP-World/Top-AI-Conferences-Paper-with-Code)
- [Awesome Deep Learning papers for industrial Search, Recommendation and Advertising](https://github.com/guyulongcs/Awesome-Deep-Learning-Papers-for-Search-Recommendation-Advertising)
- [JaxTon](https://github.com/vopani/jaxton) - 100 exercises to learn JAX.
- [Deep Multi-attribute Graph Representation Learning on Protein Structures (2020)](https://arxiv.org/abs/2012.11762)
- [Variational Diffusion Models (2021)](https://arxiv.org/abs/2107.00630) ([Code](https://github.com/yoyololicon/variational-diffwave))
- [Cheat sheet for the "Deep Learning" course at ETH Zürich](https://github.com/andbloch/eth-dl-cheat-sheet)
- [Convolutional Networks on Graphs for Learning Molecular Fingerprints (2015)](https://arxiv.org/abs/1509.09292) ([Code](https://github.com/HIPS/neural-fingerprint))
- [Cheatsheet for the Advanced Machine Learning Lecture 2020, ETH Zurich](https://github.com/veroniquek/aml_cheatsheet/blob/main/cheatsheet.pdf)
- [Tutorial on amortized optimization for learning to optimize over continuous domains (2022)](https://arxiv.org/abs/2202.00665) ([Code](https://github.com/facebookresearch/amortized-optimization-tutorial))
- [Growing 3D Artefacts and Functional Machines with Neural Cellular Automata (2021)](https://arxiv.org/abs/2103.08737) ([Code](https://github.com/real-itu/3d-artefacts-nca))
- [Generative Flow Networks for Discrete Probabilistic Modeling (2022)](https://arxiv.org/abs/2202.01361) ([Code](https://github.com/zdhNarsil/EB_GFN))
- [Awesome Contrastive Learning](https://github.com/asheeshcric/awesome-contrastive-self-supervised-learning)
- [ML-fairness-gym](https://github.com/google/ml-fairness-gym) - Components for building simple simulations that explore the potential long-run impacts of deploying machine learning-based decision systems in social environments.
- [MultiBench: Multiscale Benchmarks for Multimodal Representation Learning](https://github.com/pliang279/MultiBench)
- [Learning Features with Parameter-Free Layers (2022)](https://github.com/naver-ai/PfLayer)
- [Gaussian Processes for Machine Learning: Book](http://www.gaussianprocess.org/gpml/)
- [IQ-Learn: Inverse soft-Q Learning for Imitation (2021)](https://arxiv.org/abs/2106.12142) ([Code](https://github.com/Div99/IQ-Learn))
- [On Neural Differential Equations (2022)](https://arxiv.org/abs/2202.02435) ([Reddit](https://www.reddit.com/r/MachineLearning/comments/snmtzn/r_phd_thesis_on_neural_differential_equations/)) ([Tweet](https://twitter.com/PatrickKidger/status/1491069456185200640))
- [Datamodels: Predicting Predictions from Training Data (2022)](https://arxiv.org/abs/2202.00622) ([Data](https://github.com/MadryLab/datamodels-data))
- [Understanding Black-box Predictions via Influence Functions (2020)](https://arxiv.org/abs/1703.04730) ([PyTorch Code](https://github.com/nimarb/pytorch_influence_functions))
- [Parameter Prediction for Unseen Deep Architectures (NeurIPS 2021)](https://github.com/facebookresearch/ppuda)
- [Language-Agnostic Representation Learning of Source Code from Structure and Context (2021)](https://arxiv.org/abs/2103.11318) ([Code](https://github.com/danielzuegner/code-transformer))
- [Machine Learning Open Source University](https://github.com/d0r1h/ML-University)
- [Exploring hyperparameter meta-loss landscapes with Jax (2021)](http://lukemetz.com/exploring-hyperparameter-meta-loss-landscapes-with-jax/)
- [Transformers Can Do Bayesian Inference (2022)](https://arxiv.org/abs/2112.10510)
- [Norm-based Analysis of Transformer](https://github.com/gorokoba560/norm-analysis-of-transformer) - Implementations for 2 papers introducing to analyze Transformers using vector norms.
- [Point-NeRF: Point-based Neural Radiance Fields (2022)](https://xharlie.github.io/projects/project_sites/pointnerf/index.html) ([Code](https://github.com/Xharlie/pointnerf))
- [ML training compute has been doubling every 6 months since 2010](https://twitter.com/ohlennart/status/1493521176286609412) ([HN](https://news.ycombinator.com/item?id=30348925))
- [Using JAX in 2022](https://www.assemblyai.com/blog/why-you-should-or-shouldnt-be-using-jax-in-2022/) ([HN](https://news.ycombinator.com/item?id=30349687))
- [Should We Be Using JAX in 2022?](https://www.reddit.com/r/MachineLearning/comments/st8b11/d_should_we_be_using_jax_in_2022/)
- [Parallel Computing and Scientific Machine Learning (SciML): Methods and Applications](https://book.sciml.ai/) ([Code](https://github.com/SciML/SciMLBook))
- [Awesome Neural ODE](https://github.com/Zymrael/awesome-neural-ode) - Resources regarding the interplay between differential equations, deep learning, dynamical systems, control and numerical methods.
- [LLC: Accurate, Multi-purpose Learnt Low-dimensional Binary Codes (2021)](https://arxiv.org/abs/2106.01487) ([Code](https://github.com/RAIVNLab/LLC))
- [TinyML Paper and Projects](https://github.com/gigwegbe/tinyml-papers-and-projects)
- [Multiplicative Filter Networks (2021)](https://openreview.net/forum?id=OmtmcPkkhT) ([Code](https://github.com/boschresearch/multiplicative-filter-networks))
- [Class-incremental learning: survey and performance evaluation on image classification (2020)](https://arxiv.org/abs/2010.15277) ([Code](https://github.com/mmasana/FACIL))
- [Appendix: More Is Different In Other Domains (2022)](https://bounded-regret.ghost.io/appendix-more-is-different-in-related-fields/)
- [Robustness and Accuracy Could Be Reconcilable by (Proper) Definition (2022)](https://arxiv.org/abs/2202.10103) ([Code](https://github.com/P2333/SCORE))
- [Nebullvm](https://github.com/nebuly-ai/nebullvm) - All-in-one library for easy-to-use DL compilers.
- [SECANT: Self-Expert Cloning for Zero-Shot Generalization of Visual Policies (2021)](https://arxiv.org/abs/2106.09678) ([Code](https://github.com/LinxiFan/SECANT))
- [Open Platform for AI (OpenPAI)](https://github.com/microsoft/pai) - Resource scheduling and cluster management for AI.
- [Hugging Face Optimum](https://github.com/huggingface/optimum) - Accelerate Transformer models for training and inference on targeted hardware. ([Tweet](https://twitter.com/Thom_Wolf/status/1496768744747532290))
- [Gaussian Processes and Statistical Decision-making in Non-Euclidean Spaces (2022)](https://arxiv.org/abs/2202.10613) ([Tweet](https://twitter.com/avt_im/status/1496453031960981514))
- [What's hot for Machine Learning Research in 2022?](https://www.reddit.com/r/MachineLearning/comments/t04ekm/d_whats_hot_for_machine_learning_research_in_2022/)
- [Machine Learning with PyTorch and Scikit-Learn (2022)](https://sebastianraschka.com/blog/2022/ml-pytorch-book.html) ([HN](https://news.ycombinator.com/item?id=30473254)) ([Author AMA](https://www.reddit.com/r/MachineLearning/comments/t6lcyz/hey_all_im_sebastian_raschka_author_of_machine/))
- [General Cyclical Training of Neural Networks (2022)](https://arxiv.org/abs/2202.08835) ([Code](https://github.com/lnsmith54/CFL))
- [Machine Learning Interview Questions](https://github.com/andrewekhalel/MLQuestions)
- [Intro to Continual Learning](https://github.com/clam004/intro_continual_learning)
- [Gradients without Backpropagation (2022)](https://arxiv.org/abs/2202.08587) ([HN](https://news.ycombinator.com/item?id=30525214))
- [Variational Autoencoders Without the Variation (2022)](https://arxiv.org/abs/2203.00645)
- [What's your favorite unpopular/forgotten Machine Learning method? (2022)](https://www.reddit.com/r/MachineLearning/comments/t55lbw/d_whats_your_favorite_unpopularforgotten_machine/)
- [Neo: Generalizing Confusion Matrix Visualization to Hierarchical and Multi-Output Labels (2022)](https://machinelearning.apple.com/research/generalizing-confusion-matrix) ([Tweet](https://twitter.com/_jgoertler/status/1499139488693604362))
- [Probabilistic Machine Learning: Advanced Topics](https://probml.github.io/pml-book/book2.html) ([Code](https://github.com/probml/pml2-book))
- [AST: Audio Spectrogram Transformer (2021)](https://arxiv.org/abs/2104.01778) ([Code](https://github.com/YuanGongND/ast))
- [Practical Machine Learning](https://github.com/eugenesiow/practical-ml) - Learn by experimenting on state-of-the-art machine learning models and algorithms.
- [Tensor Programs V: Tuning Large Neural Networks via Zero-Shot Hyperparameter Transfer (2022)](https://arxiv.org/abs/2203.03466) ([Code](https://github.com/microsoft/mup))
- [Optimization for machine learning course (2022)](https://edu.epfl.ch/coursebook/en/optimization-for-machine-learning-CS-439) ([Code](https://github.com/epfml/OptML_course))
- [Awesome Long-Tailed Learning](https://github.com/Stomach-ache/awesome-long-tail-learning)
- [Offline Reinforcement Learning as One Big Sequence Modeling Problem (2021)](https://arxiv.org/abs/2106.02039) ([Code](https://github.com/jannerm/trajectory-transformer))
- [Deep Learning’s New Infrastructure (2022)](https://mirror.xyz/gensyn.eth/0SHaOYVPhATdTfw8Ypixoln_G5HF_NcVz9gEI7AXLTw)
- [Gensyn](https://www.gensyn.ai/) - Hyperscale, cost-efficient compute protocol for the world's deep learning models. ([Twitter](https://twitter.com/gensynai))
- [Software Engineering for AI/ML -- An Annotated Bibliography](https://github.com/ckaestne/seaibib)
- [Physics-Based Deep Learning](https://github.com/thunil/Physics-Based-Deep-Learning)
- [Be Your Own Teacher: Improve the Performance of Convolutional Neural Networks via Self Distillation (2019)](https://arxiv.org/abs/1905.08094) ([Code](https://github.com/luanyunteng/pytorch-be-your-own-teacher))
- [Tensil](https://www.tensil.ai/) - Open-Source ML Accelerators. ([HN](https://news.ycombinator.com/item?id=30643520)) ([Code](https://github.com/tensil-ai/tensil))
- [Ask HN: What ML platform are you using? (2022)](https://news.ycombinator.com/item?id=30658324)
- [Graphsignal](https://graphsignal.com/) - Machine Learning Profiler. ([HN](https://news.ycombinator.com/item?id=30628618))
- [Machine Learning and AI with Go](https://github.com/dwhitena/gc-ml)
- [Everything about Transfer Learning](https://github.com/jindongwang/transferlearning)
- [Making Deep Learning Go Brrrr From First Principles](https://horace.io/brrr_intro.html)
- [Machine Learning Guide](https://github.com/mikeroyal/Machine-Learning-Guide)
- [Building a ML Transformer in a Spreadsheet (2022)](https://www.youtube.com/watch?v=S9eKuRVigjY)
- [Lecture Notes for Machine Learning Theory (2021)](https://github.com/tengyuma/cs229m_notes/blob/main/master.pdf)
- [On Embeddings for Numerical Features in Tabular Deep Learning (2022)](https://arxiv.org/abs/2203.05556) ([Code](https://github.com/Yura52/tabular-dl-num-embeddings))
- [Automated Machine Learning in Action Book (2022)](https://www.manning.com/books/automated-machine-learning-in-action) ([Code](https://github.com/datamllab/automl-in-action-notebooks))
- [ML Course Notes](https://github.com/dair-ai/ML-Course-Notes)
- [The Mathematics of Artificial Intelligence (2022)](https://arxiv.org/abs/2203.08890)
- [Differentiable Sorting Networks for Scalable Sorting and Ranking Supervision (2021)](https://arxiv.org/abs/2105.04019) ([Code](https://github.com/Felix-Petersen/diffsort))
- [Fast TreeSHAP: Accelerating SHAP Value Computation for Trees (2021)](https://arxiv.org/abs/2109.09847) ([Code](https://github.com/linkedin/FastTreeSHAP))
- [Memorizing Transformers (2022)](https://arxiv.org/abs/2203.08913) ([Code](https://github.com/lucidrains/memorizing-transformers-pytorch)) ([HN](https://news.ycombinator.com/item?id=31448360))
- [DiffuseVAE: Efficient, Controllable and High-Fidelity Generation from Low-Dimensional Latents (2022)](https://arxiv.org/abs/2201.00308) ([Code](https://github.com/kpandey008/DiffuseVAE))
- [Metarank](https://www.metarank.ai/) - Low-code Machine Learning personalization service. ([Code](https://github.com/metarank/metarank)) ([HN](https://news.ycombinator.com/item?id=30778100))
- [Research on Tabular Deep Learning](https://github.com/Yura52/rtdl)
- [HuggingFace Blog](https://huggingface.co/blog) ([Code](https://github.com/huggingface/blog))
- [Learning to Prompt for Continual Learning (2022)](https://arxiv.org/abs/2112.08654) ([Code](https://github.com/google-research/l2p))
- [Group Equivariant Deep Learning (2022)](https://www.youtube.com/playlist?list=PL8FnQMH2k7jzPrxqdYufoiYVHim8PyZWd) ([Tweet](https://twitter.com/erikjbekkers/status/1507807031088062470))
- [Human-Centered Machine Learning (2022)](https://github.com/ChicagoHAI/human-centered-machine-learning)
- [Transformer models: an introduction and catalog — 2022 Edition](https://xamat.medium.com/transformers-models-an-introduction-and-catalogue-2022-edition-2d1e9039f376)
- [Bayesian Structure Learning with Generative Flow Networks (2022)](https://arxiv.org/abs/2202.13903) ([Code](https://github.com/tristandeleu/jax-dag-gflownet))
- [Neural Networks with Recurrent Generative Feedback (2020)](https://arxiv.org/abs/2007.09200) ([Code](https://github.com/yjhuangcd/CNNF))
- [Coursera Machine Learning MOOC by Andrew Ng](https://www.coursera.org/learn/machine-learning) ([Code](https://github.com/dibgerge/ml-coursera-python-assignments))
- [Chaos is a Ladder: A New Understanding of Contrastive Learning (2022)](https://openreview.net/pdf?id=ECvgmYVyeUz) ([Code](https://github.com/zhangq327/ARC))
- [Efficient-VDVAE: Less is more (2022)](https://arxiv.org/abs/2203.13751) ([Code](https://github.com/Rayhane-mamah/Efficient-VDVAE))
- [Transformer Quality in Linear Time (2022)](https://arxiv.org/abs/2202.10447) ([Code](https://github.com/lucidrains/FLASH-pytorch))
- [Machine Learning for Big Code and Naturalness](https://ml4code.github.io/) - Survey of Machine Learning for Big Code and Naturalness. ([Code](https://github.com/ml4code/ml4code.github.io))
- [Randomized Smoothing of All Shapes and Sizes (2020)](https://decentdescent.org/rs4a1.html) ([Code](https://github.com/tonyduan/rs4a))
- [Redesigning the Transformer Architecture with Insights from Multi-particle Dynamical Systems (2021)](https://arxiv.org/abs/2109.15142) ([Code](https://github.com/LCS2-IIITD/TransEvolve))
- [Deep Maths - machine learning and mathematics (2022)](https://www.youtube.com/watch?v=wbJQTtjlM_w)
- [Manim Machine Learning](https://github.com/helblazer811/ManimMachineLearning) - Focused on providing animations and visualizations of common machine learning concepts with the Manim Community Library.
- [Anyscale](https://www.anyscale.com/) - Effortlessly develop, scale and deploy AI, at any scale. ([GitHub](https://github.com/anyscale))
- [Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting (2021)](https://arxiv.org/abs/2106.13008) ([Code](https://github.com/thuml/Autoformer))
- [On the Bottleneck of Graph Neural Networks and its Practical Implications (2021)](https://arxiv.org/abs/2006.05205) ([Code](https://github.com/tech-srl/bottleneck))
- [ML Notebooks](https://github.com/dair-ai/ML-Notebooks) - Series of code examples for all sorts of machine learning tasks and applications.
- [Awesome Semi-Supervised Learning](https://github.com/yassouali/awesome-semi-supervised-learning)
- [FedScale: Benchmarking Model and System Performance of Federated Learning at Scale (2021)](https://arxiv.org/abs/2105.11367) ([Code](https://github.com/SymbioticLab/FedScale))
- [Augmenting Physical Models with Deep Networks for Complex Dynamics Forecasting (2021)](https://arxiv.org/abs/2010.04456) ([Code](https://github.com/yuan-yin/APHYNITY))
- [Understand transformer architectures (2022)](https://twitter.com/michael_nielsen/status/1511853865150287873)
- [The Future of Machine Learning Tools (2021)](https://skok.ai/machine%20learning/tools/2021/12/06/the-future-of-machine-learning-tools.html)
- [Transformers Are All You Need: Quick tour through the most popular Neural Net architecture (2022)](https://www.pinecone.io/learn/transformers/)
- [Transformers in Time Series](https://github.com/qingsongedu/time-series-transformers-review) - Curated list of awesome resources (paper, code, data, etc.) on transformers in time series.
- [SRBench: A Living Benchmark for Symbolic Regression (2022)](https://cavalab.org/srbench/) ([Code](https://github.com/cavalab/srbench))
- [How FAANG etc. architect their recommendation systems at scale](https://blog.fennel.ai/p/real-world-recommendation-system)
- [BigScience Research Workshop](https://bigscience.huggingface.co/)
- [SmallScience](https://github.com/SeanNaren/SmallScience) - My journey to training a large(ish) transformer model.
- [Temporal Spike Sequence Learning via Backpropagation for Deep Spiking Neural Networks (TSSL-BP)](https://proceedings.neurips.cc/paper/2020/hash/8bdb5058376143fa358981954e7626b8-Abstract.html) ([Code](https://github.com/stonezwr/TSSL-BP))
- [Recommender Systems, Not Just Recommender Models (2022)](https://medium.com/nvidia-merlin/recommender-systems-not-just-recommender-models-485c161c755e)
- [Reading Lists of Machine Learning, Natural Language Processing and etc.](https://github.com/IsaacChanghau/DL-NLP-Readings)
- [Argmax Flows and Multinomial Diffusion: Learning Categorical Distributions (2021)](https://arxiv.org/abs/2102.05379) ([Code](https://github.com/didriknielsen/argmax_flows)) ([Code](https://github.com/ehoogeboom/multinomial_diffusion))
- [The Principles of Deep Learning Theory (2021)](https://arxiv.org/abs/2106.10165) ([HN](https://news.ycombinator.com/item?id=31051540))
- [Understanding the Limitations of Variational Mutual Information Estimators (2019)](https://arxiv.org/abs/1910.06222) ([Code](https://github.com/ermongroup/smile-mi-estimator))
- [Tensor Puzzles](https://github.com/srush/Tensor-Puzzles) - Solve puzzles. Improve your PyTorch. ([Tweet](https://twitter.com/srush_nlp/status/1516066504885915655))
- [ACM FAccT - 2022 Accepted Papers](https://facctconference.org/2022/acceptedpapers.html)
- [How Attention works, in the field of artificial intelligence](https://github.com/lucidrains/attention)
- [Awesome Weak-Shot Learning](https://github.com/bcmi/Awesome-Weak-Shot-Learning)
- [Ultimate Awesome Transformer Attention](https://github.com/cmhungsteve/Awesome-Transformer-Attention)
- [What are Diffusion Models? (2022)](https://www.youtube.com/watch?v=fbLgFrlTnGU)
- [Apollo: An Adaptive Parameter-wise Diagonal Quasi-Newton Method for Nonconvex Stochastic Optimization (2020)](https://arxiv.org/abs/2009.13586)
- [Awesome Conformal Prediction](https://github.com/valeman/awesome-conformal-prediction)
- [The Machine Learning Job Market (2022)](https://evjang.com/2022/04/25/rome.html) ([HN](https://news.ycombinator.com/item?id=31155782))
- [Admin-Torch](https://github.com/microsoft/admin-torch) - Understanding the Difficulty of Training Transformers.
- [Sampling with Mirrored Stein Operators (2022)](https://arxiv.org/abs/2106.12506) ([Code](https://github.com/thjashin/mirror-stein-samplers)) ([Tweet](https://twitter.com/thjashin/status/1518973853678153728))
- [data2vec and the future of multimodal learning (2022)](https://towardsdatascience.com/data2vec-and-the-future-of-multimodal-learning-f33f9c781f48)
- [Mapping Fair ML](https://github.com/summerscope/mapping-fair-ml) - Curated list of links and resources for Fair ML and Data Ethics.
- [Open Source MLOps](https://github.com/fuzzylabs/awesome-open-mlops) - Fuzzy Labs guide to the universe of free and open source MLOps tools.
- [Why train when you can optimize?](https://justinmeiners.github.io/why-train-when-you-can-optimize/) ([HN](https://news.ycombinator.com/item?id=31205689)) ([Code](https://github.com/justinmeiners/why-train-when-you-can-optimize))
- [Data Engineering & Machine Learning Knowledge Hub](https://github.com/abhishek-ch/around-dataengineering)
- [Graph Contrastive Learning with Augmentations (2020)](https://arxiv.org/abs/2010.13902) ([Code](https://github.com/Shen-Lab/GraphCL))
- [Pseudo Numerical Methods for Diffusion Models on Manifolds (2022)](https://openreview.net/forum?id=PlKWVd2yBkY) ([Code](https://github.com/luping-liu/PNDM))
- [Practical MLOps Book (2021)](https://www.oreilly.com/library/view/practical-mlops/9781098103002/) ([Code](https://github.com/paiml/practical-mlops-book))
- [Disco Diffusion](https://github.com/alembics/disco-diffusion) - Notebooks, models and techniques for the generation of AI Art and Animations.
- [The Annotated Transformer: Attention is All You Need](http://nlp.seas.harvard.edu/annotated-transformer/) ([Code](https://github.com/harvardnlp/annotated-transformer))
- [Metaseq](https://github.com/facebookresearch/metaseq) - Codebase for working with Open Pre-trained Transformers.
- [Accelerating Bayesian Optimization for Biological Sequence Design with Denoising Autoencoders (2022)](https://arxiv.org/abs/2203.12742) ([Code](https://github.com/samuelstanton/lambo))
- [Learning with Noisy Labels](https://github.com/weijiaheng/Advances-in-Label-Noise-Learning)
- [Pathways: Asynchronous Distributed Dataflow for ML (2022)](https://arxiv.org/abs/2203.12533) ([Pathways: Google's New ML System](https://www.bodunhu.com/blog/posts/pathways-googles-new-ml-system/))
- [Google AI Blog: Alpa: Automated Model-Parallel Deep Learning (2022)](https://ai.googleblog.com/2022/05/alpa-automated-model-parallel-deep.html)
- [Compositional Attention: Disentangling Search and Retrieval (2021)](https://arxiv.org/abs/2110.09419) ([Code](https://github.com/sarthmit/Compositional-Attention)) ([Code](https://github.com/lucidrains/compositional-attention-pytorch)) ([Code](https://github.com/Rishit-dagli/Compositional-Attention))
- [Awesome Active Learning](https://github.com/baifanxxx/awesome-active-learning)
- [Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning (2022)](https://arxiv.org/abs/2205.05638) ([Code](https://github.com/r-three/t-few))
- [Introduction to Diffusion Models for Machine Learning (2022)](https://www.assemblyai.com/blog/diffusion-models-for-machine-learning-introduction/) ([HN](https://news.ycombinator.com/item?id=31355812))
- [BGU-CS-VIL/DeepDPM: "DeepDPM: Deep Clustering With An Unknown Number of Clusters" (2022)](https://arxiv.org/abs/2203.14309) ([Code](https://github.com/BGU-CS-VIL/DeepDPM))
- [Towards a Learning-Based Query Optimizer (2022)](https://engineering.databloom.ai/2022/05/towards-learning-based-query-optimizer.html) ([HN](https://news.ycombinator.com/item?id=31376141))
- [Scaling-up Diverse Orthogonal Convolutional Networks with a Paraunitary Framework (2021)](https://arxiv.org/abs/2106.09121)
- [Data Distributional Properties Drive Emergent Few-Shot Learning in Transformers (2022)](https://arxiv.org/abs/2205.05055) ([Tweet](https://twitter.com/scychan_brains/status/1526514761579614209))
- [Machine Learning Specialization - DeepLearning.AI](https://www.deeplearning.ai/program/machine-learning-specialization/) ([HN](https://news.ycombinator.com/item?id=31435801))
- [MLU-Explain](https://mlu-explain.github.io/) - Visual explanations of core machine learning concepts. ([HN](https://news.ycombinator.com/item?id=31455919))
- [Planning with Diffusion for Flexible Behavior Synthesis (2022)](https://diffusion-planning.github.io/) ([Code](https://github.com/jannerm/diffuser))
- [Solutions to Recommender Systems competitions](https://github.com/NVIDIA-Merlin/competitions)
- [Recipe for a General, Powerful, Scalable Graph Transformer (2022)](https://arxiv.org/abs/2205.12454) ([Code](https://github.com/rampasek/GraphGPS))
- [How to properly handle hyperparameter configs in ML repos (2022)](https://twitter.com/karpathy/status/1528808361558306817)
- [FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness (2022)](https://arxiv.org/abs/2205.14135) ([Code](https://github.com/HazyResearch/flash-attention))
- [Machine Learning Design patterns](https://github.com/msaroufim/ml-design-patterns) - Software Architecture for ML engineers.
- [Hopular: Modern Hopfield Networks for Tabular Data (2022)](https://arxiv.org/abs/2206.00664) ([Code](https://github.com/ml-jku/hopular))
- [Some thoughts on machine learning with small data (2022)](https://niklasriewald.com/2022/06/02/some-thoughts-on-machine-learning-with-small-data/) ([HN](https://news.ycombinator.com/item?id=31592769))
- [Most elegant/beautiful ideas in ML? (2022)](https://twitter.com/banburismus_/status/1532747777280593920)
- [Apple Silicon DL benchmarks](https://github.com/tcapelle/apple_m1_pro_python) - Collection of ML scripts to test the M1 Pro MacBook Pro.
- [Post-Modern ML Stack](https://github.com/jacopotagliabue/post-modern-stack)
- [Improving Discrete Latent Representations With Differentiable Approximation Bridges (2019)](https://arxiv.org/abs/1905.03658) ([Code](https://github.com/apple/ml-dab))
- [Semantic Search and GIFs](https://www.pinecone.io/learn/gif-search/) ([HN](https://news.ycombinator.com/item?id=31652839))
- [Materials for workshops on the Hugging Face ecosystem](https://github.com/huggingface/workshops)
- [Deploying Transformers on the Apple Neural Engine (2022)](https://machinelearning.apple.com/research/neural-engine-transformers) ([HN](https://news.ycombinator.com/item?id=31666476))
- [A comprehensive review of Binary Neural Network (2022)](https://arxiv.org/abs/2110.06804)
- [Self-organising Systems from Google](https://github.com/google-research/self-organising-systems)
- [Improved Denoising Diffusion Probabilistic Models (2021)](https://arxiv.org/abs/2102.09672) ([Code](https://github.com/openai/improved-diffusion))
- [What topics to learn to get 'cutting edge AI' (2022)](https://twitter.com/dan_abramov/status/1536095971779788802)
- [Probability flow solution of the Fokker-Planck equation (2022)](https://arxiv.org/abs/2206.04642)
- [Review of latest Score Based Generative Modeling papers](https://scorebasedgenerativemodeling.github.io/) - All diffusion papers reverse chronological.
- [Intro resources on diffusion/score-matching models (2022)](https://twitter.com/Thom_Wolf/status/1536263780568547328)
- [Meta Optimal Transport (2022)](https://arxiv.org/abs/2206.05262) ([Code](https://github.com/facebookresearch/meta-ot))
- [envd](https://github.com/tensorchord/envd) - Development environment for machine learning.
- [Awesome Open Source MLOps](https://github.com/gaocegege/awesome-open-source-mlops)
- [Generalised Implicit Neural Representations (2022)](https://arxiv.org/abs/2205.15674) ([Code](https://github.com/danielegrattarola/GINR))
- [Diffusers](https://github.com/huggingface/diffusers) - Provides pretrained diffusion models across multiple modalities, such as vision and audio, and serves as a modular toolbox for inference and training of diffusion models.
- [Lightning AI](https://lightning.ai/) - Use Lightning Apps to build everything from production-ready, multi-cloud ML systems to simple research demos.
- [Latent World Models For Intrinsically Motivated Exploration (2020)](https://arxiv.org/abs/2010.02302) ([Code](https://github.com/htdt/lwm))
- [Prioritized Training on Points that are Learnable, Worth Learning, and Not Yet Learnt (2022)](https://arxiv.org/abs/2206.07137) ([Code](https://github.com/OATML/RHO-Loss))
- [Self-Supervised Learning from Images: Up-to-date reading list](https://github.com/wvangansbeke/Self-Supervised-Learning-Overview)
- [How robust are pre-trained models to distribution shift? (2022)](https://arxiv.org/abs/2206.08871)
- [MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge (2022)](https://arxiv.org/abs/2206.08853) ([Code](https://github.com/MineDojo/MineDojo))
- [MLOPs Primer](https://github.com/dair-ai/MLOPs-Primer) - Collection of resources to learn about MLOPs.
- [Are wider nets better given the same number of parameters? (2020)](https://arxiv.org/abs/2010.14495) ([Code](https://github.com/google-research/wide-sparse-nets))
- [Brandon Amos's presentation slides](https://github.com/bamos/presentations)
- [Ethical Principles for Web Machine Learning](https://webmachinelearning.github.io/ethical-webmachinelearning/) ([Code](https://github.com/webmachinelearning/ethical-webmachinelearning))
- [MLC](https://github.com/mlc-ai/mlc-en) - Machine Learning Compiler.
- [Golan Levin's lectures](https://github.com/golanlevin/lectures)
- [RevBiFPN: The Fully Reversible Bidirectional Feature Pyramid Network (2022)](https://arxiv.org/abs/2206.14098) ([Code](https://github.com/CerebrasResearch/RevBiFPN))
- [Pen and paper exercises in machine learning](https://github.com/michaelgutmann/ml-pen-and-paper-exercises) ([Paper](https://arxiv.org/abs/2206.13446)) ([HN](https://news.ycombinator.com/item?id=31913057))
- [Dual Curriculum Design](https://github.com/facebookresearch/dcd) - Implementations of robust Dual Curriculum Design (DCD) algorithms for unsupervised environment design.
- [gDDIM: Generalized denoising diffusion implicit models (2022)](https://arxiv.org/abs/2206.05564) ([Code](https://github.com/qsh-zh/gDDIM))
- [Awesome Active Learning](https://github.com/SupeRuier/awesome-active-learning)
- [Designing Machine Learning Systems: An Iterative Process for Production-Ready Applications](https://www.oreilly.com/library/view/designing-machine-learning/9781098107956/) ([Code](https://github.com/chiphuyen/dmls-book))
- [The Berkeley Crossword Solver](https://bair.berkeley.edu/blog/2022/05/20/crosswords/)
- [MLC](https://github.com/mlc-ai/mlc-zh) - Machine Learning Compiler.
- [Recommender System on MovieLens dataset](https://github.com/rposhala/Recommender-System-on-MovieLens-dataset)
- [Awesome Radar Perception](https://github.com/ZHOUYI1023/awesome-radar-perception) - Curated list of radar datasets, detection, tracking and fusion.
- [MLGO: A Machine Learning Framework for Compiler Optimization (2022)](https://ai.googleblog.com/2022/07/mlgo-machine-learning-framework-for.html) ([HN](https://news.ycombinator.com/item?id=32007695))
- [Supporting GPU-accelerated Machine Learning with Kubernetes and Nix (2022)](https://canvatechblog.com/supporting-gpu-accelerated-machine-learning-with-kubernetes-and-nix-7c1da8e42f61)
- [Transfer Learning with Deep Tabular Models (2022)](https://arxiv.org/abs/2206.15306) ([Code](https://github.com/LevinRoman/tabular-transfer-learning))
- [Speech Denoising in the Waveform Domain with Self-Attention (2022)](https://arxiv.org/abs/2202.07790) ([Code](https://github.com/NVIDIA/CleanUNet))
- [SetVAE: Learning Hierarchical Composition for Generative Modeling of Set-Structured Data (2021)](https://arxiv.org/abs/2103.15619) ([Code](https://github.com/jw9730/setvae))
- [MIT: Deep Learning for Art, Aesthetics, and Creativity (2022)](https://ali-design.github.io/deepcreativity/)
- [500 AI Machine learning Deep learning Computer vision NLP Projects with code](https://github.com/ashishpatel26/500-AI-Machine-learning-Deep-learning-Computer-vision-NLP-Projects-with-code)
- [Deep Learning Curriculum](https://github.com/jacobhilton/deep_learning_curriculum)
- [Diffusion models](https://github.com/InFoCusp/diffusion_models) - Minimal standalone example of diffusion model.
- [Perceiver IO: A General Architecture for Structured Inputs & Outputs (2021)](https://arxiv.org/abs/2107.14795) ([Code](https://github.com/minqukanq/perceiver-io))
- [ML code generation vs. coding by hand: what we think programming will look like (2022)](https://wasp-lang.dev/blog/2022/06/24/ML-code-gen-vs-coding-by-hand-future) ([HN](https://news.ycombinator.com/item?id=32098144))
- [Self-Attention Between Datapoints: Going Beyond Individual Input-Output Pairs in Deep Learning (2021)](https://arxiv.org/abs/2106.02584) ([Code](https://github.com/OATML/non-parametric-transformers))
- [Recommender Systems course at Polimi](https://github.com/MaurizioFD/RecSys_Course_AT_PoliMi)
- [A General Recipe for Likelihood-free Bayesian Optimization (2022)](https://arxiv.org/abs/2206.13035) ([Code](https://github.com/lfbo-ml/lfbo))
- [Generative Coarse-Graining of Molecular Conformations (2022)](https://arxiv.org/abs/2201.12176) ([Code](https://github.com/wwang2/CoarseGrainingVAE))
- [Thoughts on ML Engineering After a Year of My PhD (2022)](https://www.shreya-shankar.com/phd-year-one/) ([HN](https://news.ycombinator.com/item?id=32147219))
- [[2206.03398] Towards a General Purpose CNN for Long Range Dependencies in ND (2022)](https://arxiv.org/abs/2206.03398) ([Code](https://github.com/david-knigge/ccnn))
- [Formal Algorithms for Transformers (2022)](https://arxiv.org/abs/2207.09238) ([HN](https://news.ycombinator.com/item?id=32163324))
- [Practical Deep Learning for Coders 2022](https://www.fast.ai/2022/07/21/dl-coders-22/) ([HN](https://news.ycombinator.com/item?id=32186647))
- [ML is not that good at predicting consumers' choices (2022)](https://statmodeling.stat.columbia.edu/2022/07/21/predicting-consumers-choices-in-the-age-of-the-internet-ai-and-almost-perfect-tracking-some-things-change-the-key-challenges-do-not/) ([HN](https://news.ycombinator.com/item?id=32181974))
- [TabTransformer: Tabular Data Modeling Using Contextual Embeddings (2020)](https://arxiv.org/abs/2012.06678) ([Code](https://github.com/lucidrains/tab-transformer-pytorch))
- [Automatic Symmetry Discovery with Lie Algebra Convolutional Network (2021)](https://arxiv.org/abs/2109.07103) ([Code](https://github.com/nimadehmamy/L-conv-code))
- [Awesome Time Series Papers](https://github.com/cure-lab/Awesome-time-series)
- [Deep Learning setup made easy with EC2 Remote Runner and Habana Gaudi (2022)](https://www.philschmid.de/habana-gaudi-ec2-runner)
- [Efficient Deep Learning Book](https://efficientdlbook.com/) ([Code](https://github.com/EfficientDL/book))
- [DALLE2 LAION](https://github.com/LAION-AI/dalle2-laion) - Collection of resources and tools for LAION's pre-trained DALLE-2 model.
- [Awesome Novel Class Discovery](https://github.com/JosephKJ/Awesome-Novel-Class-Discovery)
- [Harvard ML Course (2019)](https://harvard-iacs.github.io/2019-CS109A/pages/materials.html)
- [Transformers as Meta-Learners for Implicit Neural Representations (2022)](https://arxiv.org/abs/2208.02801) ([Code](https://github.com/yinboc/trans-inr))
- [AdaCat: Adaptive Categorical Discretization for Autoregressive Models (2022)](https://arxiv.org/abs/2208.02246) ([Code](https://github.com/ColinQiyangLi/AdaCat))
- [Awesome Decision Tree Research Papers](https://github.com/benedekrozemberczki/awesome-decision-tree-papers)
- [Why do tree-based models still outperform deep learning on tabular data? (2022)](https://arxiv.org/abs/2207.08815) ([HN](https://news.ycombinator.com/item?id=32333565))
- [Improving Sample Efficiency in Model-Free Reinforcement Learning from Images (2020)](https://arxiv.org/abs/1910.01741) ([Code](https://github.com/denisyarats/pytorch_sac_ae))
- [Robust Robotic Control from Pixels using Contrastive Recurrent State-Space Models (2021)](https://arxiv.org/abs/2112.01163) ([Code](https://github.com/apple/ml-core))
- [First Italian School on Geometric Deep Learning (2022)](https://www.youtube.com/playlist?list=PLn2-dEmQeTfRQXLKf9Fmlk3HmReGg3YZZ)
- [DeepTIMe: Deep Time-Index Meta-Learning for Non-Stationary Time-Series Forecasting (2022)](https://arxiv.org/abs/2207.06046) ([Code](https://github.com/salesforce/DeepTIMe))
- [Stable Diffusion Akashic Records](https://github.com/Maks-s/sd-akashic) - Compendium of informations regarding Stable Diffusion (SD).
- [Ask HN: In 2022, what is the proper way to get into machine/deep learning? (2022)](https://news.ycombinator.com/item?id=32480009)
