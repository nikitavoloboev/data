# Computer vision

[LiT (Locked-image Tuning)](https://twitter.com/giffmana/status/1508400604082806785) paper is neat. Trying to understand [Vision Transformers](https://github.com/lucidrains/vit-pytorch). [Kornia](https://github.com/kornia/kornia) seems like a great library. [Imagen](https://github.com/lucidrains/imagen-pytorch) is fascinating.

## Links

- [OpenCV](https://github.com/opencv/opencv) - Open Source Computer Vision Library. ([Web](https://opencv.org/)) ([OpenCV Course](https://www.youtube.com/watch?v=oXlwWbU8l2o))
- [Gluon CV Toolkit](https://github.com/dmlc/gluon-cv) - Provides implementations of the sate-of-the-art (SOTA) deep learning models in computer vision.
- [Pythia](https://github.com/facebookresearch/pythia) - Modular framework for vision and language multimodal research. Built on top of PyTorch.
- [video-object-removal](https://github.com/zllrunning/video-object-removal) - Just draw a bounding box and you can remove the object you want to remove.
- [GoCV](https://github.com/hybridgroup/gocv) - Go package for computer vision using OpenCV 4 and beyond.
- [Sandbox for training convolutional networks for computer vision](https://github.com/osmr/imgclsmob)
- [Get started with Computer Vision, Deep Learning, and OpenCV](https://www.pyimagesearch.com/start-here/)
- [TorchCV](https://github.com/donnyyou/torchcv) - PyTorch-Based Framework for Deep Learning in Computer Vision.
- [AI Habitat](https://github.com/facebookresearch/habitat-sim) - Flexible, high-performance 3D simulator for Embodied AI research.
- [Kornia](https://github.com/kornia/kornia) - Open Source Differentiable Computer Vision Library for PyTorch. ([Web](https://kornia.github.io//))
- [Roboflow](https://roboflow.com/) - Raw images to trained computer vision model. ([Article](https://nickarner.com/notes/roboflow-memo-february-1-2021/))
- [PySlowFast](https://github.com/facebookresearch/SlowFast) - Open source video understanding codebase from FAIR that provides state-of-the-art video classification models.
- [How to Convert a Picture to Numbers](https://brohrer.github.io/images_to_numbers.html)
- [Awesome Computer Vision](https://github.com/jbhuang0604/awesome-computer-vision)
- [The Ancient Secrets of Computer Vision (2018)](https://www.youtube.com/playlist?list=PLjMXczUzEYcHvw5YYSU92WrY8IwhTuq7p)
- [Variational Methods for Computer Vision lectures (2013)](https://www.youtube.com/watch?v=fpw26tpHGr8&list=PLTBdjV_4f-EJ7A2iIH5L5ztqqrWYjP2RI)
- [Classy Vision](https://github.com/facebookresearch/ClassyVision) - New end-to-end, PyTorch-based framework for large-scale training of state-of-the-art image and video classification models.
- [Meshroom](https://github.com/alicevision/meshroom) - 3D Reconstruction Software.
- [AliceVision](https://alicevision.org/) - Photogrammetric Computer Vision Framework. ([Code](https://github.com/alicevision/AliceVision)) ([GitHub](https://github.com/alicevision))
- [PyTorch3d](https://github.com/facebookresearch/pytorch3d) - Provides efficient, reusable components for 3D Computer Vision research with PyTorch. ([Web](https://pytorch3d.org/))
- [Face Recognition](https://github.com/ageitgey/face_recognition) - World's simplest facial recognition api for Python and the command line.
- [Deep Hough Voting for 3D Object Detection in Point Clouds](https://github.com/facebookresearch/votenet)
- [Point Cloud Library](https://github.com/PointCloudLibrary/pcl) - Standalone, large scale, open project for 2D/3D image and point cloud processing.
- [Disappearing-People](https://github.com/jasonmayes/Real-Time-Person-Removal) - Removing people from complex backgrounds in real time using TensorFlow.js in the web browser. ([HN](https://news.ycombinator.com/item?id=22353596))
- [Best Practices, code samples, and documentation for Computer Vision](https://github.com/microsoft/computervision-recipes)
- [Computer Vision Basics in Microsoft Excel](https://github.com/amzn/computer-vision-basics-in-microsoft-excel)
- [PolyGen: An Autoregressive Generative Model of 3D Meshes (2020)](https://arxiv.org/abs/2002.10880)
- [Sophus](https://github.com/strasdat/Sophus) - C++ implementation of Lie Groups using Eigen.
- [SOLT](https://github.com/MIPT-Oulu/solt) - Streaming over lightweight data transformations.
- [Awesome Interaction-aware Behavior and Trajectory Prediction](https://github.com/jiachenli94/Awesome-Interaction-aware-Trajectory-Prediction)
- [SynSin: End-to-end View Synthesis from a Single Image (2020)](http://www.robots.ox.ac.uk/~ow/synsin.html) ([Code](https://github.com/facebookresearch/synsin))
- [Pixel2Mesh](https://github.com/nywang16/Pixel2Mesh) - Generating 3D Mesh Models from Single RGB Images.
- [First Order Motion Model for Image Animation](https://aliaksandrsiarohin.github.io/first-order-model-website/) ([Code](https://github.com/AliaksandrSiarohin/first-order-model))
- [PyTorch improved version of TPAMI 2017 paper: Face Alignment in Full Pose Range: A 3D Total Solution](https://github.com/cleardusk/3DDFA)
- [Learning to See Through Obstructions](https://github.com/alex04072000/ObstructionRemoval)
- [Learning to Cluster Faces on an Affinity Graph (LTC)](https://github.com/yl-1993/learn-to-cluster)
- [Avatarify](https://github.com/alievk/avatarify) - Avatars for Zoom and Skype.
- [SPSR](https://github.com/Maclory/SPSR) - PyTorch implementation of Structure-Preserving Super Resolution with Gradient Guidance.
- [OISR-PyTorch](https://github.com/HolmesShuan/OISR-PyTorch) - PyTorch implementation of "ODE-inspired Network Design for Single Image Super-Resolution.
- [3D Photography using Context-aware Layered Depth Inpainting](https://github.com/vt-vl-lab/3d-photo-inpainting)
- [CenterMask : Real-Time Anchor-Free Instance Segmentation](https://github.com/youngwanLEE/CenterMask)
- [Interview with Dmytro Mushkin | Computer Vision Research | Kaggle, ML & Education (2020)](https://www.youtube.com/watch?v=lWwkbiufwNE)
- [Pytorch code for ICLR-20 Paper "Learning to Explore using Active Neural SLAM"](https://github.com/devendrachaplot/Neural-SLAM)
- [FaceTracker](https://github.com/kylemcdonald/FaceTracker) - Real time deformable face tracking in C++ with OpenCV 3.
- [Awesome Super Resolution](https://github.com/ChaofWang/Awesome-Super-Resolution)
- [Adversarial Latent Autoencoders](https://github.com/podgorskiy/ALAE)
- [ElasticFusion](https://github.com/mp3guy/ElasticFusion) - Real-time dense visual SLAM system capable of capturing comprehensive dense globally consistent surfel-based maps of room scale environments explored using an RGB-D camera.
- [StegaStamp: Invisible Hyperlinks in Physical Photographs](https://github.com/tancik/StegaStamp)
- [Pose Animator](https://github.com/yemount/pose-animator/) - Takes a 2D vector illustration and animates its containing curves in real-time based on the recognition result from PoseNet and FaceMesh. ([HN](https://news.ycombinator.com/item?id=23124786))
- [fvcore](https://github.com/facebookresearch/fvcore) - Collection of common code that's shared among different research projects in FAIR computer vision team.
- [Making Sense of Vision and Touch: Multimodal Representations for Contact-Rich Tasks (2020)](http://ai.stanford.edu/blog/selfsupervised-multimodal/)
- [ScreenPoint](https://github.com/cyrildiagne/screenpoint) - Project an image centroid to another image using OpenCV.
- [U^2-Net](https://github.com/NathanUA/U-2-Net) - Code for our newly accepted paper in Pattern Recognition 2020: "U^2-Net: Going Deeper with Nested U-Structure for Salient Object Detection".
- [TorchIO](https://github.com/fepegar/torchio) - Tools for medical image processing in deep learning.
- [Real time Image Animation in OpenCV using first order model](https://github.com/anandpawara/Real_Time_Image_Animation) ([HN](https://news.ycombinator.com/item?id=23312259))
- [OpenMV (Open-Source Machine Vision)](https://github.com/openmv/openmv) - Aims at making machine vision more accessible to beginners by developing a user-friendly, open-source, low-cost machine vision platform.
- [TSD](https://github.com/Sense-X/TSD) - 1st place models in Google OpenImage Detection Challenge 2019.
- [Training-Time-Friendly Network for Real-Time Object Detection](https://github.com/ZJULearning/ttfnet)
- [Big Transfer (BiT): General Visual Representation Learning](https://github.com/google-research/big_transfer)
- [Fast Human Pose Estimation CVPR2019](https://github.com/ilovepose/fast-human-pose-estimation.pytorch)
- [Deep High-Resolution Representation Learning for Human Pose Estimation](https://github.com/leoxiaobin/deep-high-resolution-net.pytorch)
- [Background Matting: The World is Your Green Screen](https://github.com/senguptaumd/Background-Matting)
- [DE⫶TR: End-to-End Object Detection with Transformers](https://github.com/facebookresearch/detr)
- [PIFu: Pixel-Aligned Implicit Function for High-Resolution Clothed Human Digitization](https://github.com/shunsukesaito/PIFu)
- [Tracking Objects as Points](https://github.com/xingyizhou/CenterTrack)
- [VIBE](https://github.com/mkocabas/VIBE) - Video Inference for Human Body Pose and Shape Estimation.
- [SRZoo](https://github.com/idearibosome/srzoo) - Integrated repository for super-resolution using deep learning.
- [mAP (mean Average Precision)](https://github.com/Cartucho/mAP) - Evaluates the performance of your neural net for object recognition.
- [Neural Pose Transfer by Spatially Adaptive Instance Normalization (2020)](https://github.com/jiashunwang/Neural-Pose-Transfer)
- [Awesome Neural Rendering](https://github.com/weihaox/awesome-neural-rendering)
- [Learning To Classify Images Without Labels](https://github.com/wvangansbeke/Unsupervised-Classification)
- [Deep Leakage From Gradients (2019)](https://github.com/mit-han-lab/dlg)
- [3Dflow](https://www.3dflow.net/) - Offers customized computer vision software solutions.
- [labelme](https://github.com/wkentaro/labelme) - Image Polygonal Annotation with Python.
- [imgviz](https://github.com/wkentaro/imgviz) - Image Visualization Tools.
- [Attention-Guided Hierarchical Structure Aggregation for Image Matting](https://github.com/wukaoliu/CVPR2020-HAttMatting)
- [YOLOv5 Is Here: State-of-the-Art Object Detection at 140 FPS (2020)](https://blog.roboflow.ai/yolov5-is-here/) ([HN](https://news.ycombinator.com/item?id=23478151)) ([Code](https://github.com/ultralytics/yolov5))
- [DetectoRS](https://github.com/joe-siyuan-qiao/DetectoRS) - Detecting Objects with Recursive Feature Pyramid and Switchable Atrous Convolution.
- [PyTorch implementation of paper Real-time Facial Surface Geometry from Monocular Video on Mobile GPUs](https://github.com/thepowerfuldeez/facemesh.pytorch)
- [VirTex: Learning Visual Representations from Textual Annotations](https://github.com/kdexd/virtex)
- [High-Resolution 3D Human Digitization from A Single Image](https://github.com/facebookresearch/pifuhd)
- [FairMOT](https://github.com/ifzhang/FairMOT) - Simple baseline for one-shot multi-object tracking.
- [Implicit Neural Representations with Periodic Activation Functions (2020)](https://vsitzmann.github.io/siren/)
- [MSeg: A Composite Dataset for Multi-Domain Segmentation](https://github.com/mseg-dataset/mseg-semantic)
- [Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results](https://github.com/CuriousAI/mean-teacher)
- [MMDetection](https://github.com/open-mmlab/mmdetection) - OpenMMLab Detection Toolbox and Benchmark.
- [Fourier Feature Networks in TensorFlow 2](https://github.com/noahtren/Fourier-Feature-Networks-TensorFlow-2)
- [Computer Vision Lab | ETH Zurich](https://vision.ee.ethz.ch/)
- [PyTorch Computer Vision Library for Experts and Beginners (2020)](https://medium.com/pytorch/pytorch-computer-vision-library-for-experts-and-beginners-84b9157584e5)
- [Computer Vision Pretrained Models](https://github.com/balavenkatesh3322/CV-pretrained-model)
- [Fawkes: Image “Cloaking” for Personal Privacy](http://sandlab.cs.uchicago.edu/fawkes/) ([HN](https://news.ycombinator.com/item?id=23917337))
- [Motion](https://github.com/Motion-Project/motion) - Software motion detector.
- [Supervised 3D Mesh Reconstruction (2020)](https://nextjournal.com/nirmal-suthar/supervised-3d-mesh-reconstruction)
- [NeRF in the Wild](https://nerf-w.github.io/) - Neural Radiance Fields for Unconstrained Photo Collections.
- [NASA: Neural Articulated Shape Approximation (2020)](https://arxiv.org/abs/1912.03207)
- [An Overview of Deep Learning Architectures in Few-Shot Learning Domain (2020)](https://arxiv.org/abs/2008.06365v2)
- [FutureMapping: The Computational Structure of Spatial AI Systems (2018)](https://arxiv.org/abs/1803.11288) ([Tweet](https://twitter.com/AjdDavison/status/1045617261925543937))
- [Optimal Peanut Butter and Banana Sandwiches (2020)](https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/) ([Twitter](https://twitter.com/eprosenthal/status/1298290961294950401))
- [Gesture Recognition with Line Integrals](https://justinmeiners.github.io/gesture-recognition/) ([Code](https://github.com/justinmeiners/gesture-recognition))
- [Computer Vision: Looking Back to Look Forward (2020)](http://slazebni.cs.illinois.edu/spring20/)
- [DAIN (Depth-Aware Video Frame Interpolation)](https://github.com/baowenbo/DAIN)
- [Picsellia](https://picsellia.com/) - Development platform dedicated to Computer Vision.
- [Official implementation of "PifPaf: Composite Fields for Human Pose Estimation" in PyTorch](https://github.com/vita-epfl/openpifpaf)
- [Object Recognition with Gradient-Based Learning (1999)](https://link.springer.com/chapter/10.1007/3-540-46805-6_19)
- [Imaginaire](https://github.com/NVlabs/imaginaire) - NVIDIA PyTorch GAN library with distributed and mixed precision support. ([Docs](http://imaginaire.cc/))
- [DeepBackSub](https://github.com/floe/deepbacksub) - Virtual Video Device for Background Replacement with Deep Semantic Segmentation.
- [Awesome Tiny Object Detection](https://github.com/kuanhungchen/awesome-tiny-object-detection)
- [Flow-edge Guided Video Completion](https://github.com/vt-vl-lab/FGVC)
- [5 Things to look for in a Computer Vision startup job (2020)](https://insights.ai-jobs.net/5-things-to-look-for-in-a-computer-vision-startup-job/)
- [Transformers for Image Recognition at Scale (2020)](https://www.youtube.com/watch?v=Gl48KciWZp0) ([HN](https://news.ycombinator.com/item?id=24754538))
- [nnU-Net](https://github.com/MIC-DKFZ/nnUNet) - Segmentation method that is designed to deal with the dataset diversity.
- [batchgenerators](https://github.com/MIC-DKFZ/batchgenerators) - Framework for data augmentation for 2D and 3D image classification and segmentation.
- [Lookuq](https://www.lookuq.com/create-your-own-app) - App to create object detection projects without coding. ([HN](https://news.ycombinator.com/item?id=24784680))
- [InsightFace](https://github.com/deepinsight/insightface) - Face Analysis Project on MXNet. ([Web](http://insightface.ai/))
- [PyTorch implementation of SwAV (Swapping Assignments between Views)](https://github.com/facebookresearch/swav)
- [Asymmetric Loss For Multi-Label Classification in PyTorch](https://github.com/Alibaba-MIIL/ASL)
- [Antialiased CNNs](https://github.com/adobe/antialiased-cnns) - Making Convolutional Networks Shift-Invariant Again.
- [Perceptual Similarity Metric and Dataset](https://github.com/richzhang/PerceptualSimilarity) - Unreasonable Effectiveness of Deep Features as a Perceptual Metric.
- [Deep Learning Anime Papers](https://github.com/deeppomf/DeepLearningAnimePapers)
- [Vision Transformer](https://github.com/google-research/vision_transformer) - Models from the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale.
- [Handsfree.js](https://github.com/MIDIBlocks/handsfree) - Wrapper library around computer vision models for working with face pointers, assistive tech, and creative expression. ([Web](https://handsfreejs.glitch.me/))
- [ZeroQ: A Novel Zero Shot Quantization Framework](https://github.com/amirgholami/ZeroQ)
- [SqueezeNext](https://github.com/amirgholami/SqueezeNext) - Contains the Caffe implementation of SqueezeNext.
- [ANODE: Adjoint Based Neural ODEs](https://github.com/amirgholami/anode)
- [Python Video Stabilization using OpenCV](https://github.com/AdamSpannbauer/python_video_stab)
- [Recent Advances in Vision and Language PreTrained Models (VL-PTMs)](https://github.com/yuewang-cuhk/awesome-vision-language-pretraining-papers)
- [TorchCV](https://github.com/kuangliu/torchcv) - PyTorch vision library mimics ChainerCV.
- [Vision Transformer in PyTorch](https://github.com/jeonsworld/ViT-pytorch)
- [MedicalTorch](https://github.com/perone/medicaltorch) - Medical imaging framework for PyTorch. ([Docs](https://medicaltorch.readthedocs.io/en/stable/))
- [imagecluster](https://github.com/elcorto/imagecluster) - Cluster images based on image content using a pre-trained deep neural network, optional time distance scaling and hierarchical clustering.
- [Detecto](https://github.com/alankbi/detecto) - Build fully-functioning computer vision models with PyTorch. ([Docs](https://detecto.readthedocs.io/en/latest/))
- [EmoPy](https://github.com/thoughtworksarts/EmoPy) - Deep neural net toolkit for emotion analysis via Facial Expression Recognition (FER).
- [PyTorch Implementation of "NVAE: A Deep Hierarchical Variational Autoencoder"](https://github.com/NVlabs/NVAE)
- [Label Decoupling Framework for Salient Object Detection](https://github.com/weijun88/LDF)
- [MONAI](https://github.com/Project-MONAI/MONAI) - PyTorch-based, open-source framework for deep learning in healthcare imaging, part of PyTorch Ecosystem. ([Web](https://monai.io/))
- [Generalized Focal Loss: Learning Qualified and Distributed Bounding Boxes for Dense Object Detection](https://github.com/implus/GFocal)
- [Faster R-CNN Explained for Object Detection Tasks (2020)](https://blog.paperspace.com/faster-r-cnn-explained-object-detection/)
- [How to Install OpenCV on a Raspberry Pi (2020)](https://www.jeremymorgan.com/tutorials/raspberry-pi/how-to-install-opencv-raspberry-pi/)
- [Contextual Encoder-Decoder Network for Visual Saliency Prediction](https://github.com/alexanderkroner/saliency)
- [PyImageSearch](https://www.pyimagesearch.com/) - Master Computer Vision, Deep Learning, and OpenCV.
- [Natural Adversarial Examples](https://github.com/hendrycks/natural-adv-examples) - Harder ImageNet Test Set.
- [How to upload 50 OpenCV frames into cloud storage within 1 second (2020)](https://medium.com/@venkateshpnk22/how-to-upload-50-opencv-frames-into-cloud-storage-within-1-second-653ee73d7711)
- [Egocentric Videoconferencing (2020)](http://gvv.mpi-inf.mpg.de/projects/EgoChat/) - Method for egocentric videoconferencing that enables handsfree video calls, for instance by people wearing smart glasses or other mixedreality devices. ([Video overview](https://www.youtube.com/watch?v=atzPvW95ahQ))
- [gradslam](https://github.com/gradslam/gradslam) - Open source differentiable dense SLAM library for PyTorch.
- [High-Resolution Daytime Translation Without Domain Labels](https://github.com/saic-mdal/HiDT)
- [Holistically-Nested Edge Detection](https://github.com/s9xie/hed)
- [pycls](https://github.com/facebookresearch/pycls) - Image classification codebase, written in PyTorch.
- [PyTorch implementation of High-Fidelity Generative Image Compression + Routines for neural image compression](https://github.com/Justin-Tan/high-fidelity-generative-compression)
- [How Useful is Self-Supervised Pretraining for Visual Tasks?](https://github.com/princeton-vl/selfstudy)
- [PULSE: Self-Supervised Photo Upsampling via Latent Space Exploration of Generative Models](https://github.com/adamian98/pulse)
- [InterHand2.6M: A Dataset and Baseline for 3D Interacting Hand Pose Estimation from a Single RGB Image](https://github.com/facebookresearch/InterHand2.6M)
- [Multi-object trackers in Python](https://github.com/adipandas/multi-object-tracker) - Easy to use implementation of various multi-object tracking algorithms.
- [Stanford Vision and Learning Lab](http://svl.stanford.edu/) ([GitHub](https://github.com/StanfordVL))
- [Learning computer vision. Overview of methods and software (2018)](https://towardsdatascience.com/learning-computer-vision-41398ad9941f)
- [Image embeddings. Image similarity and building (2020)](https://medium.com/@rom1504/image-embeddings-ed1b194d113e) ([Code](https://github.com/rom1504/image_embeddings))
- [All You Need to Know About Object Detection Systems (2020)](https://lionbridge.ai/articles/everything-you-need-to-know-about-object-detection-systems/)
- [Lightly](https://github.com/lightly-ai/lightly) - Computer vision framework for self-supervised learning.
- [DISK: Learning local features with policy gradient (2020)](https://arxiv.org/abs/2006.13566) ([Code](https://github.com/cvlab-epfl/disk))
- [Caer](https://github.com/jasmcaus/caer) - Lightweight Computer Vision library for high-performance AI research. ([Intro](https://towardsdatascience.com/introducing-caer-modern-computer-vision-on-the-fly-1619d7155c15))
- [Awesome Image to Image Translation Papers](https://github.com/weihaox/awesome-image-translation)
- [EfficientDet: Scalable and Efficient Object Detection, in PyTorch](https://github.com/toandaominh1997/EfficientDet.Pytorch)
- [UNet: semantic segmentation with PyTorch](https://github.com/milesial/Pytorch-UNet)
- [Exploring Simple Siamese Representation Learning (2020)](https://arxiv.org/abs/2011.10566) ([Code](https://github.com/PatrickHua/SimSiam)) ([Code](https://github.com/facebookresearch/simsiam))
- [Show, Control and Tell: A Framework for Generating Controllable and Grounded Captions](https://github.com/aimagelab/show-control-and-tell)
- [Nerfies: Deformable Neural Radiance Fields](https://nerfies.github.io/) ([Code](https://github.com/google/nerfies))
- [Timeception for Complex Action Recognition (2019)](https://arxiv.org/abs/1812.01289) ([Code](https://github.com/noureldien/timeception))
- [Programming Computer Vision with Python (2014)](http://programmingcomputervision.com/) ([Code](https://github.com/jesolem/PCV)) ([Notes](https://github.com/nico/cvbook))
- [Fast and Accurate One-Stage Space-Time Video Super-Resolution (2020)](https://github.com/Mukosame/Zooming-Slow-Mo-CVPR-2020)
- [pixelNeRF: Neural Radiance Fields from One or Few Images (2020)](https://alexyu.net/pixelnerf/) ([Code](https://github.com/sxyu/pixel-nerf))
- [vedadet](https://github.com/Media-Smart/vedadet) - Single stage object detector toolbox based on PyTorch.
- [OneNet: End-to-End One-Stage Object Detection by Classification Cost](https://github.com/PeizeSun/OneNet)
- [Consistent Video Depth Estimation](https://github.com/facebookresearch/consistent_depth) - Estimate dense, flicker-free, geometrically consistent depth from monocular video, for example hand-held cell phone video.
- [Implicit Neural Representations with Periodic Activation Functions](https://github.com/vsitzmann/siren)
- [Computational Imaging Stanford Lab](http://www.computationalimaging.org/)
- [Trimap-Free Solution for Portrait Matting in Real Time](https://github.com/ZHKKKe/MODNet)
- [Local Light Field Fusion](https://github.com/Fyusion/LLFF)
- [Awesome Crowd Counting](https://github.com/gjy3035/Awesome-Crowd-Counting)
- [Neural Sparse Voxel Fields (NSVF)](https://github.com/facebookresearch/NSVF)
- [One-Shot Free-View Neural Talking-Head Synthesis for Video Conferencing (2020)](https://arxiv.org/abs/2011.15126) ([Tweet](https://twitter.com/goodfellow_ian/status/1333845997697388544))
- [SharpAI DeepCamera](https://github.com/SharpAI/DeepCamera) - Source stack for machine learning engineering with private deployment and AutoML for edge computing. ([HN](https://news.ycombinator.com/item?id=25368272))
- [Contrastive learning of global and local features for medical image segmentation with limited annotations](https://github.com/krishnabits001/domain_specific_cl)
- [Real-Time High-Resolution Background Matting (2020)](https://arxiv.org/abs/2012.07810) ([Code](https://github.com/PeterL1n/BackgroundMattingV2))
- [Torchreid](https://github.com/KaiyangZhou/deep-person-reid) - Deep learning person re-identification in PyTorch.
- [Unsupervised Embedding Learning via Invariant and Spreading Instance Feature](https://github.com/mangye16/Unsupervised_Embedding_Learning)
- [img2pose: Face Alignment and Detection via 6DoF, Face Pose Estimation](https://github.com/vitoralbiero/img2pose)
- [SSD: Single Shot MultiBox Detector | a PyTorch Tutorial to Object Detection](https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection)
- [PCT: Point Cloud Transformer (2020)](https://arxiv.org/pdf/2012.09688.pdf) ([Code](https://github.com/MenghaoGuo/PCT))
- [Learning Continuous Image Representation with Local Implicit Image Function (2020)](https://arxiv.org/abs/2012.09161) ([Code](https://github.com/yinboc/liif))
- [Computer Vision Annotation Tool (CVAT)](https://github.com/openvinotoolkit/cvat)
- [DeiT: Data-efficient Image Transformers](https://github.com/facebookresearch/deit)
- [Awesome Implicit Neural Representations](https://github.com/vsitzmann/awesome-implicit-representations)
- [ImageAI](https://github.com/OlafenwaMoses/ImageAI) - Python library built to empower developers to build applications and systems with self-contained Computer Vision capabilities. ([Web](http://imageai.org/))
- [RAIVN Lab](https://raivn.cs.washington.edu/) - Reasoning, AI and VisioN (RAIVN) Lab. ([GitHub](https://github.com/RAIVNLab))
- [Norfair](https://github.com/tryolabs/norfair) - Customizable lightweight Python library for real-time 2D object tracking.
- [Universal Style Transfer in PyTorch](https://github.com/sunshineatnoon/PytorchWCT)
- [NVIDIA Deep learning Dataset Synthesizer (NDDS)](https://github.com/NVIDIA/Dataset_Synthesizer)
- [Object Detection at 2530 FPS with TensorRT and 8-Bit Quantization (2020)](https://paulbridger.com/posts/tensorrt-object-detection-quantized/)
- [HTML4Vision](https://github.com/mtli/HTML4Vision) - Simple HTML visualization tool for computer vision research.
- [Soft-IntroVAE: Analyzing and Improving Introspective Variational Autoencoders](https://github.com/taldatech/soft-intro-vae-pytorch)
- [Taming Transformers for High-Resolution Image Synthesis](https://github.com/CompVis/taming-transformers)
- [X-Temporal](https://github.com/Sense-X/X-Temporal) - Easily implement SOTA video understanding methods with PyTorch on multiple machines and GPUs.
- [NanoDet](https://github.com/RangiLyu/nanodet) - Super fast and lightweight anchor-free object detection model. Real-time on mobile devices.
- [PyTorch Image Models](https://github.com/rwightman/pytorch-image-models)
- [Awesome Vision and Language](https://github.com/sangminwoo/awesome-vision-and-language) - Curated list of awesome vision and language resources.
- [DropBlock: A regularization method for convolutional networks (2018)](https://arxiv.org/abs/1810.12890v1) ([Code](https://github.com/miguelvr/dropblock))
- [Glasses](https://github.com/FrancescoSaverioZuppichini/glasses) - Compact, concise and customizable deep learning computer vision library. ([Web](https://francescosaveriozuppichini.github.io/glasses-webapp/))
- [Explorable Super Resolution (2019)](https://github.com/YuvalBahat/Explorable-Super-Resolution)
- [PySceneDetect](https://github.com/Breakthrough/PySceneDetect) - Python and OpenCV-based scene cut/transition detection program & library.
- [Best Practices for Building Computer Vision Models (2021)](https://phaseai.com/resources/computer-vision-best-practices)
- [TIDE](https://github.com/dbolya/tide) - General Toolbox for Identifying Object Detection Errors.
- [Sparse R-CNN: End-to-End Object Detection with Learnable Proposals (2020)](https://arxiv.org/abs/2011.12450) ([Code](https://github.com/PeizeSun/SparseR-CNN))
- [Unsplash Image Search](https://github.com/haltakov/natural-language-image-search) - Search photos on Unsplash using natural language.
- [Kimera Semantics](https://github.com/MIT-SPARK/Kimera-Semantics) - Real-Time 3D Semantic Reconstruction from 2D data.
- [Voxblox++](https://github.com/ethz-asl/voxblox-plusplus) - Volumetric object-level semantic mapping framework.
- [Neural Geometric Level of Detail: Real-time Rendering with Implicit 3D Surfaces](https://nv-tlabs.github.io/nglod/) ([Code](https://github.com/nv-tlabs/nglod))
- [Non-Rigid Neural Radiance Fields: Reconstruction and Novel View Synthesis of a Deforming Scene from Monocular Video (2020)](https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/) ([Code](https://github.com/facebookresearch/nonrigid_nerf))
- [DeepSDF: Learning Continuous Signed Distance Functions for Shape Representation (2019)](https://openaccess.thecvf.com/content_CVPR_2019/html/Park_DeepSDF_Learning_Continuous_Signed_Distance_Functions_for_Shape_Representation_CVPR_2019_paper.html) ([Code](https://github.com/facebookresearch/DeepSDF))
- [Awesome Neural Radiance Fields](https://github.com/yenchenlin/awesome-NeRF)
- [D2Det: Towards High Quality Object Detection and Instance Segmentation (2020)](https://github.com/JialeCao001/D2Det)
- [DetCo: Unsupervised Contrastive Learning for Object Detection (2021)](https://arxiv.org/abs/2102.04803) ([Code](https://github.com/xieenze/DetCo))
- [Computer Vision Video Lectures](https://github.com/kuzand/Computer-Vision-Video-Lectures) - Curated list of free, high-quality, university-level courses with video lectures related to the field of Computer Vision.
- [Cord](https://cord.tech/) - Training data toolbox for computer vision. ([HN](https://news.ycombinator.com/item?id=26104104))
- [Text-Guided Editing of Images (Using CLIP and StyleGAN)](https://github.com/orpatashnik/StyleCLIP)
- [torchvision](https://github.com/pytorch/vision) - Datasets, Transforms and Models specific to Computer Vision. ([Web](https://paperswithcode.com/lib/torchvision))
- [MeInGame: Create a Game Character Face from a Single Portrait (2021)](https://arxiv.org/abs/2102.02371) ([Code](https://github.com/FuxiCV/MeInGame))
- [Awesome Deep Vision](https://github.com/kjw0612/awesome-deep-vision)
- [dataset-tools](https://github.com/dvschultz/dataset-tools) - Tools for quickly normalizing image datasets.
- [Using Streamlit to visualize object detection output (2021)](https://blog.streamlit.io/how-to-use-roboflow-and-streamlit-to-visualize-object-detection-output/)
- [Mobile Computer Vision @ Facebook](https://github.com/facebookresearch/mobile-vision)
- [Opening the black box of vision AI algorithms (2021)](https://medium.com/hasty-ai/opening-the-black-box-of-vision-ai-algorithms-466fc3d4bf78)
- [CompreFace](https://github.com/exadel-inc/CompreFace) - Free face recognition solution that can be easily integrated into any IT system without prior machine learning skills.
- [IBRNet: Learning Multi-View Image-Based Rendering (2021)](https://ibrnet.github.io/) ([Code](https://github.com/googleinterns/IBRNet))
- [From Coarse to Fine: Robust Hierarchical Localization at Large Scale (2019)](https://arxiv.org/abs/1812.03506) ([Code](https://github.com/ethz-asl/hfnet))
- [Camera Response Function (2021)](https://roboalgorithms.com/posts/camera-response-function/)
- [I2L-MeshNet: Image-to-Lixel Prediction Network for Accurate 3D Human Pose and Mesh Estimation from a Single RGB Image (2020)](https://arxiv.org/abs/2008.03713) ([Code](https://github.com/mks0601/I2L-MeshNet_RELEASE))
- [SkipNet: Learning Dynamic Routing in Convolutional Networks (2018)](https://arxiv.org/abs/1711.09485) ([Code](https://github.com/ucbdrive/skipnet))
- [Mrcal](http://mrcal.secretsauce.net/) - Camera Calibrations and More. ([HN](https://news.ycombinator.com/item?id=26300118))
- [Digging Into Self-Supervised Monocular Depth Estimation (2019)](https://arxiv.org/abs/1806.01260) ([Code](https://github.com/nianticlabs/monodepth2)) ([Code](https://github.com/pxl-th/Monodepth2.jl))
- [VISSL](https://github.com/facebookresearch/vissl) - FAIR's library of extensible, modular and scalable components for SOTA Self-Supervised Learning with images. ([Web](https://vissl.ai/))
- [Zumo Labs](https://www.zumolabs.ai/) - Generate custom synthetic data sets that result in more robust and reliable computer vision models. ([GitHub](https://github.com/ZumoLabs))
- [Oriented Object Detection in Aerial Images with Box Boundary-Aware Vectors (2020)](https://arxiv.org/abs/2008.07043) ([Code](https://github.com/yijingru/BBAVectors-Oriented-Object-Detection))
- [Perceiver: General Perception with Iterative Attention (2021)](https://arxiv.org/abs/2103.03206) ([Code](https://github.com/lucidrains/perceiver-pytorch))
- [SEER: The start of a more powerful, flexible, and accessible era for computer vision (2021)](https://ai.facebook.com/blog/seer-the-start-of-a-more-powerful-flexible-and-accessible-era-for-computer-vision)
- [NerFACE: Dynamic Neural Radiance Fields for Monocular 4D Facial Avatar Reconstruction (2021)](https://gafniguy.github.io/4D-Facial-Avatars/)
- [Neural 3D Video Synthesis](https://neural-3d-video.github.io/)
- [Involution: Inverting the Inherence of Convolution for Visual Recognition (2021)](https://arxiv.org/abs/2103.06255) ([Code](https://github.com/d-li14/involution))
- [Awesome Causality in Computer Vision](https://github.com/Wangt-CN/Awesome-Causality-in-CV)
- [Vision Transformers for Dense Prediction (2021)](https://arxiv.org/abs/2103.13413) ([Code](https://github.com/intel-isl/DPT))
- [LoFTR: Detector-Free Local Feature Matching with Transformers (2021)](https://arxiv.org/abs/2104.00680) ([Code](https://github.com/zju3dv/LoFTR))
- [ccv](https://github.com/liuliu/ccv) - C-based/Cached/Core Computer Vision Library, A Modern Computer Vision Library.
- [Neural Scene Flow Fields for Space-Time View Synthesis of Dynamic Scenes (2020)](https://arxiv.org/abs/2011.13084) ([Code](https://github.com/zhengqili/Neural-Scene-Flow-Fields))
- [AMP: Adversarial Motion Priors for Stylized Physics-Based Character Control (2021)](https://xbpeng.github.io/projects/AMP/) ([Tweet](https://twitter.com/xbpeng4/status/1379465757688352769))
- [Computer Vision and Embroidery (2021)](https://healeycodes.com/computer-vision-and-embroidery/) ([Code](https://github.com/healeycodes/embroidery-vision))
- [mip-NeRF: A Multiscale Representation for Anti-Aliasing Neural Radiance Fields (2021)](https://jonbarron.info/mipnerf/)
- [Python libraries I use every day for computer vision work (2021)](https://twitter.com/svpino/status/1379666495811117062)
- [Awesome Temporal Sentence Grounding in Videos](https://github.com/Soldelli/Awesome-Temporal-Language-Grounding-in-Videos)
- [The Affective Growth of Computer Vision](https://authentic.sice.indiana.edu/publications/Su_Crandall-AffectiveGrowthCV-CVPR21.pdf)
- [Lift, Splat, Shoot: Encoding Images From Arbitrary Camera Rigs by Implicitly Unprojecting to 3D (2020)](https://arxiv.org/abs/2008.05711) ([Code](https://github.com/nv-tlabs/lift-splat-shoot))
- [End-to-End Video Instance Segmentation with Transformers (2021)](https://arxiv.org/abs/2011.14503) ([Code](https://github.com/Epiphqny/VisTR))
- [SAHI: Slicing Aided Hyper Inference](https://github.com/obss/sahi)
- [FOVO: A new 3D rendering technique based on human vision (2020)](https://www.gamasutra.com/blogs/RobertPepperell/20200527/363615/FOVO_A_new_3D_rendering_technique_based_on_human_vision.php) ([HN](https://news.ycombinator.com/item?id=26795290))
- [Is Space-Time Attention All You Need for Video Understanding? (2021)](https://arxiv.org/abs/2102.05095) ([Code](https://github.com/facebookresearch/TimeSformer))
- [Awesome Visual-Transformer](https://github.com/dk-liang/Awesome-Visual-Transformer) - Transformer with Computer-Vision (CV) papers.
- [PyTorchVideo](https://github.com/facebookresearch/pytorchvideo) - Deep learning library for video understanding research. ([Web](https://pytorchvideo.org/))
- [Self-supervised Video Object Segmentation by Motion Grouping (2021)](https://charigyang.github.io/motiongroup/) ([HN](https://news.ycombinator.com/item?id=26842018)) ([Code](https://github.com/charigyang/motiongrouping))
- [torchvideo](https://github.com/torchvideo/torchvideo) - Datasets, transforms and samplers for video in PyTorch.
- [A General and Adaptive Robust Loss Function (2019)](https://arxiv.org/abs/1701.03077) ([Code](https://github.com/jonbarron/robust_loss_pytorch))
- [Self-supervising Fine-grained Region Similarities for Large-scale Image Localization (2020)](https://geyixiao.com/projects/sfrs) ([Code](https://github.com/yxgeee/OpenIBL))
- [MaX-DeepLab: Dual-Path Transformers for End-to-End Panoptic Segmentation (2021)](https://ai.googleblog.com/2021/04/max-deeplab-dual-path-transformers-for.html)
- [Vizy](https://vizycam.com/) - AI Camera.
- [MMPX Style-Preserving Pixel Art Magnification (2021)](https://casual-effects.com/research/McGuire2021PixelArt/McGuire2021PixelArt.pdf) ([HN](https://news.ycombinator.com/item?id=26934973))
- [Modular Interactive Video Object Segmentation: Interaction-to-Mask, Propagation and Difference-Aware Fusion](https://hkchengrex.github.io/MiVOS/) ([Code](https://github.com/hkchengrex/Scribble-to-Mask))
- [SuperPoint: Self-Supervised Interest Point Detection and Description (2018)](https://arxiv.org/abs/1712.07629) ([Code](https://github.com/eric-yyjau/pytorch-superpoint))
- [Multi-Stage Progressive Image Restoration (2021)](https://arxiv.org/abs/2102.02808) ([Code](https://github.com/swz30/MPRNet))
- [COLMAP](https://github.com/colmap/colmap) - General-purpose Structure-from-Motion (SfM) and Multi-View Stereo (MVS) pipeline with a graphical and command-line interface. ([Docs](https://colmap.github.io/))
- [Awesome Vision-based SLAM / Visual Odometry](https://github.com/tzutalin/awesome-visual-slam)
- [Barlow Twins: Self-Supervised Learning via Redundancy Reduction (2021)](https://arxiv.org/abs/2103.03230) ([Code](https://github.com/facebookresearch/barlowtwins))
- [HIPCL](https://github.com/cpc/hipcl) - OpenCL/SPIR-V implementation of HIP.
- [MMCV](https://github.com/open-mmlab/mmcv) - Foundational library for computer vision research and supports many research projects. ([Docs](https://mmcv.readthedocs.io/en/latest/))
- [MDETR -- Modulated Detection for End-to-End Multi-Modal Understanding (2021)](https://arxiv.org/abs/2104.12763) ([Code](https://github.com/ashkamath/mdetr))
- [Semi-Supervised Learning of Visual Features by Non-Parametrically Predicting View Assignments with Support Samples (2021)](https://arxiv.org/abs/2104.13963) ([Code](https://github.com/facebookresearch/suncet)) ([Code](https://github.com/facebookresearch/msn))
- [Emerging Properties in Self-Supervised Vision Transformers (2021)](https://arxiv.org/abs/2104.14294) ([Code](https://github.com/facebookresearch/dino)) ([Tweet](https://twitter.com/i/lists/1351120526220152839)) ([Tweet](https://twitter.com/schrep/status/1388189398496202752))
- [Geometry-Free View Synthesis: Transformers and no 3D Priors (2021)](https://arxiv.org/abs/2104.07652) ([Code](https://github.com/CompVis/geometry-free-view-synthesis))
- [Easily Transform Portraits of People into AI Aberrations Using StyleCLIP (2021)](https://minimaxir.com/2021/04/styleclip/)
- [DeepMetaHandles: Learning Deformation Meta-Handles of 3D Meshes with Biharmonic Coordinates (2021)](https://arxiv.org/abs/2102.09105) ([Code](https://github.com/Colin97/DeepMetaHandles))
- [Onepanel](https://github.com/onepanelio/onepanel) - Open and extensible integrated development environment (IDE) for computer vision. ([Web](https://docs.onepanel.ai/))
- [Vector Neurons: A General Framework for SO(3)-Equivariant Networks (2021)](https://arxiv.org/abs/2104.12229) ([Code](https://github.com/FlyingGiraffe/vnn))
- [ISTR: End-to-End Instance Segmentation with Transformers (2021)](https://arxiv.org/abs/2105.00637) ([Code](https://github.com/hujiecpp/ISTR))
- [MLP-Mixer: An all-MLP Architecture for Vision (2021)](https://arxiv.org/abs/2105.01601) ([Code](https://github.com/lucidrains/mlp-mixer-pytorch)) ([Code](https://github.com/rishikksh20/MLP-Mixer-pytorch))
- [Self-attention building blocks for computer vision applications in PyTorch](https://github.com/The-AI-Summer/self-attention-cv)
- [LeViT: a Vision Transformer in ConvNet's Clothing for Faster Inference](https://github.com/facebookresearch/LeViT)
- [Text2Video: Text-driven Talking-head Video Synthesis with Phonetic Dictionary (2021)](https://arxiv.org/abs/2104.14631) ([Web](https://sites.google.com/view/sibozhang/text2video)) ([Code](https://github.com/sibozhang/Text2Video))
- [Neural Rendering: How Low Can You Go in Terms of Input? (2021)](https://www.unite.ai/neural-rendering-low-resolution-input-intel/)
- [Enhancing Photorealism Enhancement (2021)](https://intel-isl.github.io/PhotorealismEnhancement/) ([Paper](https://arxiv.org/abs/2105.04619)) ([Code](https://github.com/intel-isl/PhotorealismEnhancement))
- [DeepFaceEditing: Deep Face Generation and Editing with Disentangled Geometry and Appearance Control (2021)](http://www.geometrylearning.com/DeepFaceEditing/) ([Code](https://github.com/IGLICT/DeepFaceEditing-Jittor))
- [Omnimatte: Associating Objects and Their Effects in Video (2021)](https://omnimatte.github.io/)
- [Rethinking "Batch" in BatchNorm (2021)](https://arxiv.org/abs/2105.07576)
- [Most popular metrics used to evaluate object detection algorithms](https://github.com/rafaelpadilla/Object-Detection-Metrics)
- [UniVL: A Unified Video and Language Pre-Training Model for Multimodal Understanding and Generation (2020)](https://arxiv.org/abs/2002.06353) ([Code](https://github.com/microsoft/UniVL))
- [Synthetic for Computer Vision](https://github.com/unrealcv/synthetic-computer-vision) - List of synthetic dataset and tools for computer vision.
- [vision_blender](https://github.com/Cartucho/vision_blender) - Blender addon for generating synthetic ground truth data for Computer Vision applications.
- [Easy Few-Shot Learning](https://github.com/sicara/easy-few-shot-learning) - Ready-to-use code and tutorial notebooks to boost your way into few-shot image classification.
- [BasicSR (Basic Super Restoration)](https://github.com/xinntao/BasicSR) - Open source image and video restoration toolbox based on PyTorch, such as super-resolution, denoise, deblurring, JPEG artifacts removal, etc.
- [Intriguing Properties of Vision Transformers (2021)](https://arxiv.org/abs/2105.10497) ([Reddit](https://www.reddit.com/r/MachineLearning/comments/njm2ru/r_intriguing_properties_of_vision_transformers/))
- [DIY Amazon Go – computer vision tutorial for cashierless checkout](https://www.sbxrobotics.com/tutorial)
- [Image Retrieval in the Wild (2020)](https://matsui528.github.io/cvpr2020_tutorial_retrieval/)
- [Awesome Transformer in CV papers](https://github.com/Yutong-Zhou-cv/Awesome-Transformer-in-CV)
- [Sensor Calibration from Scratch with Rust (2021)](https://www.tangramvision.com/blog/calibration-from-scratch-using-rust-part-1-of-3)
- [Tangram Vision](https://www.tangramvision.com/) - Integrate, Calibrate Perception Sensors For Robots, Drones & Automation. ([Blog](https://www.tangramvision.com/blog))
- [Rust CV](https://github.com/rust-cv/cv) - Project to implement computer vision algorithms, abstractions, and systems in Rust.
- [Neural Actor: Neural Free-view Synthesis of Human Actors with Pose Control (2021)](http://gvv.mpi-inf.mpg.de/projects/NeuralActor/) ([HN](https://news.ycombinator.com/item?id=27393047))
- [Robust Instance Segmentation through Reasoning about Multi-Object Occlusion (2021)](https://arxiv.org/abs/2012.02107) ([Code](https://github.com/XD7479/Multi-Object-Occlusion))
- [MERLOT: Multimodal Neural Script Knowledge Models (2021)](https://arxiv.org/abs/2106.02636) ([Tweet](https://twitter.com/jmhessel/status/1401983972272345088))
- [Scaling Vision Transformers (2021)](https://arxiv.org/abs/2106.04560)
- [Self-Supervised Scene De-occlusion (2020)](https://arxiv.org/abs/2004.02788) ([Code](https://github.com/XiaohangZhan/deocclusion))
- [Pivotal Tuning for Latent-based Editing of Real Images (2021)](https://arxiv.org/abs/2106.05744) ([Code](https://github.com/danielroich/PTI))
- [FLAME: Articulated Expressive 3D Head Model](https://flame.is.tue.mpg.de/) ([Code](https://github.com/Rubikplayer/flame-fitting))
- [XCiT: Cross-Covariance Image Transformers (2021)](https://arxiv.org/abs/2106.09681) ([Code](https://github.com/facebookresearch/xcit))
- [Robust Consistent Video Depth Estimation (2021)](https://robust-cvd.github.io/) ([Code](https://github.com/facebookresearch/robust_cvd))
- [cvpods](https://github.com/Megvii-BaseDetection/cvpods) - All-in-one Toolbox for Computer Vision Research.
- [CDFI: Compression-Driven Network Design for Frame Interpolation (2021)](https://arxiv.org/abs/2103.10559) ([Code](https://github.com/tding1/CDFI))
- [NeRF--: Neural Radiance Fields Without Known Camera Parameters (2021)](https://nerfmm.active.vision/) ([Code](https://github.com/ActiveVisionLab/nerfmm)) ([Code](https://github.com/ventusff/improved-nerfmm))
- [Oxford Active Vision Laboratory](https://www.robots.ox.ac.uk/ActiveVision/) ([GitHub](https://github.com/ActiveVisionLab))
- [Computer Vision: Algorithms and Applications, 2nd ed.](http://szeliski.org/Book/)
- [motionEyeOS](https://github.com/ccrisan/motioneyeos) - Linux distribution that turns your single board computer into a video surveillance system.
- [Long-Short Transformer: Efficient Transformers for Language and Vision (2021)](https://arxiv.org/abs/2107.02192) ([Code](https://github.com/lucidrains/long-short-transformer))
- [Feature Visualization – How NNs understand images (2017)](https://distill.pub/2017/feature-visualization/)
- [What Is Wrong With Scene Text Recognition Model Comparisons? Dataset and Model Analysis (2019)](https://arxiv.org/abs/1904.01906) ([Code](https://github.com/clovaai/deep-text-recognition-benchmark))
- [Convolutional Hough Matching Networks (2021)](https://arxiv.org/abs/2103.16831) ([Code](https://github.com/juhongm999/chm))
- [Efficient Self-Supervised Vision Transformers (EsViT)](https://github.com/microsoft/esvit)
- [ConViT: Improving Vision Transformers with Soft Convolutional Inductive Biases (2021)](https://arxiv.org/abs/2103.10697) ([Code](https://github.com/facebookresearch/convit)) ([Paper Read](https://www.youtube.com/watch?v=QdbieYXn_XM)) ([Article](https://www.marktechpost.com/2021/07/20/facebook-ai-introduces-convit-a-computer-vision-model-that-improves-vision-transformers-vit-with-soft-convolutional-inductive-biases/))
- [CO3D: Common Objects In 3D](https://github.com/facebookresearch/co3d) - Tools for working with the Common Objects in 3D (CO3D) dataset.
- [ORBIT: A Real-World Few-Shot Dataset for Teachable Object Recognition (2021)](https://arxiv.org/abs/2104.03841) ([Code](https://github.com/microsoft/ORBIT-Dataset))
- [Vision Transformer Architecture Search (2021)](https://arxiv.org/abs/2106.13700) ([Code](https://github.com/xiusu/ViTAS))
- [TSIT: A Simple and Versatile Framework for Image-to-Image Translation (2020)](https://arxiv.org/abs/2007.12072) ([Code](https://github.com/EndlessSora/TSIT))
- [Recognizing People in Photos Through Private On-Device Machine Learning (2021)](https://machinelearning.apple.com/research/recognizing-people-photos)
- [CoCosNet v2: Full-Resolution Correspondence Learning for Image Translation (2021)](https://arxiv.org/abs/2012.02047) ([Code](https://github.com/microsoft/CoCosNet-v2))
- [HPNet: Deep Primitive Segmentation Using Hybrid Representations (2021)](https://arxiv.org/abs/2105.10620) ([Code](https://github.com/SimingYan/HPNet))
- [Portal](https://github.com/datature/portal) - Fastest way to load and visualize your deep neural networks on images and videos.
- [Awesome Human Pose Estimation](https://github.com/cbsudux/awesome-human-pose-estimation)
- [Learning A Single Network for Scale-Arbitrary Super-Resolution (2021)](https://arxiv.org/abs/2004.03791) ([Code](https://github.com/LongguangWang/ArbSR))
- [PyTorch implementation for Vision Transformer](https://github.com/omihub777/ViT-CIFAR)
- [Repulsive Curves](https://www.cs.cmu.edu/~kmcrane/Projects/RepulsiveCurves/index.html) - Model 2D & 3D curves while avoiding self-intersection. ([Tweet](https://twitter.com/keenanisalive/status/1422318272800829440)) ([Code](https://github.com/icethrush/repulsive-curves)) ([HN](https://news.ycombinator.com/item?id=31120139))
- [SDEdit: Image Synthesis and Editing with Stochastic Differential Equations](https://chenlin9.github.io/SDEdit/) ([Code](https://github.com/ermongroup/SDEdit))
- [Region Similarity Representation Learning (2021)](https://arxiv.org/abs/2103.12902) ([Code](https://github.com/Tete-Xiao/ReSim))
- [NeX: Real-time View Synthesis with Neural Basis Expansion (2021)](https://nex-mpi.github.io/) ([Code](https://github.com/nex-mpi/nex-code))
- [Convolutional Occupancy Networks (2020)](https://pengsongyou.github.io/conv_onet) ([Code](https://github.com/autonomousvision/convolutional_occupancy_networks))
- [Learning Optical Flow from a Few Matches (2021)](https://arxiv.org/abs/2104.02166) ([Code](https://github.com/zacjiang/SCV))
- [Visual Parser: Representing Part-whole Hierarchies with Transformers (2021)](https://arxiv.org/abs/2107.05790) ([Code](https://github.com/kevin-ssy/ViP))
- [Super SloMo: High Quality Estimation of Multiple Intermediate Frames for Video Interpolation](http://jianghz.me/projects/superslomo/) ([Code](https://github.com/avinashpaliwal/Super-SloMo))
- [On Generating Transferable Targeted Perturbations (2021)](https://arxiv.org/abs/2103.14641) ([Code](https://github.com/Muzammal-Naseer/TTP))
- [Awesome Scene Understanding](https://github.com/bertjiazheng/awesome-scene-understanding) - List of papers for scene understanding.
- [Align before Fuse: Vision and Language Representation Learning with Momentum Distillation (2021)](https://arxiv.org/abs/2107.07651) ([Code](https://github.com/salesforce/ALBEF))
- [DONeRF: Towards Real-Time Rendering of Compact Neural Radiance Fields using Depth Oracle Networks (2021)](https://depthoraclenerf.github.io/) ([Code](https://github.com/facebookresearch/DONERF))
- [Object Detection in an Hour (2021)](https://www.strayrobots.io/blog/object-detection-in-an-hour) ([HN](https://news.ycombinator.com/item?id=28100346))
- [Fixing the train-test resolution discrepancy (2020)](https://arxiv.org/abs/1906.06423) ([Code](https://github.com/facebookresearch/FixRes))
- [Align Deep Features for Oriented Object Detection (2020)](https://arxiv.org/abs/2008.09397) ([Code](https://github.com/csuhan/s2anet))
- [Vision-Language Transformer and Query Generation for Referring Segmentation (2021)](https://arxiv.org/abs/2108.05565) ([Code](https://github.com/henghuiding/Vision-Language-Transformer))
- [Depth-supervised NeRF: Fewer Views and Faster Training for Free (2021)](https://www.cs.cmu.edu/~dsnerf/) ([Code](https://github.com/dunbar12138/DSNeRF))
- [SwinIR: Image Restoration Using Swin Transformer (2021)](https://arxiv.org/abs/2108.10257) ([Code](https://github.com/JingyunLiang/SwinIR))
- [You Only Learn One Representation: Unified Network for Multiple Tasks (2021)](https://arxiv.org/abs/2105.04206) ([Code](https://github.com/WongKinYiu/yolor))
- [Probabilistic Modeling for Human Mesh Recovery (2021)](https://arxiv.org/abs/2108.11944) ([Code](https://github.com/nkolot/ProHMR))
- [BARF: Bundle-Adjusting Neural Radiance Fields (2021)](https://chenhsuanlin.bitbucket.io/bundle-adjusting-NeRF/) ([Code](https://github.com/chenhsuanlin/bundle-adjusting-NeRF))
- [Self-Calibrating Neural Radiance Fields (2021)](https://postech-cvlab.github.io/SCNeRF/) ([Code](https://github.com/POSTECH-CVLab/SCNeRF))
- [Transformers-Tutorials](https://github.com/NielsRogge/Transformers-Tutorials) - Demos I made with the Transformers library by HuggingFace.
- [3D Human Texture Estimation from a Single Image with Transformers (2021)](https://arxiv.org/abs/2109.02563) ([Code](https://github.com/xuxy09/Texformer))
- [CLIP4Clip: An Empirical Study of CLIP for End to End Video Clip Retrieval (2021)](https://arxiv.org/abs/2104.08860) ([Code](https://github.com/ArrowLuo/CLIP4Clip))
- [RAFT: Recurrent All Pairs Field Transforms for Optical Flow (2020)](https://arxiv.org/abs/2003.12039) ([Code](https://github.com/princeton-vl/RAFT))
- [Volume rendering + 3D implicit surface = Neural 3D Reconstruction](https://github.com/ventusff/neurecon)
- [Hierarchical Deep Stereo Matching on High-resolution Images (2019)](http://www.contrib.andrew.cmu.edu/~gengshay/cvpr19stereo) ([Code](https://github.com/gengshan-y/high-res-stereo))
- [Learning Object-Compositional Neural Radiance Field for Editable Scene Rendering (2021)](https://zju3dv.github.io/object_nerf/) ([Code](https://github.com/zju3dv/object_nerf))
- [Image Synthesis via Semantic Composition (2021)](https://shepnerd.github.io/scg/) ([Code](https://github.com/dvlab-research/SCGAN))
- [Awesome-Edge-Detection-Papers](https://github.com/MarkMoHR/Awesome-Edge-Detection-Papers)
- [Awesome-Image-Colorization](https://github.com/MarkMoHR/Awesome-Image-Colorization)
- [Learning A Single Network for Scale-Arbitrary Super-Resolution (2021)](https://longguangwang.github.io/Project/ArbSR/) ([Code](https://github.com/LongguangWang/ArbSR))
- [Face Recognition](https://github.com/1adrianb/face-alignment) - 2D and 3D Face alignment library build using PyTorch.
- [Awesome image retrieval papers](https://github.com/willard-yuan/awesome-cbir-papers)
- [PeekingDuck](https://github.com/aimakerspace/PeekingDuck) - Modular framework built to simplify Computer Vision inference workloads.
- [Pri3D: Can 3D Priors Help 2D Representation Learning? (2021)](https://arxiv.org/abs/2104.11225) ([Code](https://github.com/Sekunde/Pri3D))
- [FaceXLib](https://github.com/xinntao/facexlib) - Aims at providing ready-to-use face-related functions based on current STOA open-source methods.
- [MMAction2](https://github.com/open-mmlab/mmaction2) - Open-source toolbox for video understanding based on PyTorch.
- [Awesome Collision Detection](https://github.com/jslee02/awesome-collision-detection)
- [Video Super-Resolution Transformer (2021)](https://arxiv.org/abs/2106.06847) ([Code](https://github.com/caojiezhang/VSR-Transformer))
- [NeRF Atlas](https://github.com/JulianKnodt/nerf_atlas) - Collection of NeRF extensions for fun and experimentation.
- [Training and testing codes for USRNet, DnCNN, FFDNet, SRMD, DPSR, MSRResNet, ESRGAN, BSRGAN, SwinIR](https://github.com/cszn/KAIR)
- [Uformer: A General U-Shaped Transformer for Image Restoration (2021)](https://arxiv.org/abs/2106.03106) ([Code](https://github.com/ZhendongWang6/Uformer)) ([Code](https://github.com/lucidrains/uformer-pytorch))
- [Self-Supervised Pretraining Improves Self-Supervised Pretraining (2021)](https://arxiv.org/abs/2103.12718) ([Code](https://github.com/cjrd/self-supervised-pretraining))
- [SNARF: Differentiable Forward Skinning for Animating Non-Rigid Neural Implicit Shapes (2021)](https://xuchen-ethz.github.io/snarf/) ([Code](https://github.com/xuchen-ethz/snarf))
- [HRFormer: High-Resolution Transformer for Dense Prediction, NeurIPS 2021](https://github.com/HRNet/HRFormer)
- [IceVision](https://github.com/airctic/icevision) - Agnostic Computer Vision Framework - Pluggable to any Training Library: Fastai, Pytorch-Lightning with more to come. ([Docs](https://airctic.com/))
- [e-ViL: A Dataset and Benchmark for Natural Language Explanations in Vision-Language Tasks (2021)](https://arxiv.org/abs/2105.03761) ([Tweet](https://twitter.com/maximek3/status/1438554571756933127))
- [Attention Gated Networks (Image Classification & Segmentation) in PyTorch](https://github.com/ozan-oktay/Attention-Gated-Networks)
- [Full-Duplex Strategy for Video Object Segmentation (2021)](https://arxiv.org/abs/2108.03151v2) ([Code](https://github.com/GewelsJI/FSNet))
- [YoHa](https://handtracking.io/) - Practical hand tracking engine. ([HN](https://news.ycombinator.com/item?id=28825820)) ([Code](https://github.com/handtracking-io/yoha))
- [Deep Learning for Face Anti-Spoofing: A Survey (2021)](https://arxiv.org/abs/2106.14948) ([Code](https://github.com/ZitongYu/DeepFAS))
- [A-SDF: Learning Disentangled Signed Distance Functions for Articulated Shape Representation (2021)](https://arxiv.org/abs/2104.07645) ([Code](https://github.com/JitengMu/A-SDF))
- [Resolution-robust Large Mask Inpainting with Fourier Convolutions (2021)](https://saic-mdal.github.io/lama-project/) ([Code](https://github.com/saic-mdal/lama))
- [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows (2021)](https://arxiv.org/abs/2103.14030) ([Code](https://github.com/microsoft/Swin-Transformer)) ([Code](https://github.com/berniwal/swin-transformer-pytorch))
- [ADOP: Approximate Differentiable One-Pixel Point Rendering (2021)](https://arxiv.org/abs/2110.06635) ([Tweet](https://twitter.com/rodolfor/status/1448655222876741634)) ([Tweet](https://twitter.com/keenanisalive/status/1448708734511951879)) ([Code](https://github.com/darglein/ADOP))
- [Patches Are All You Need? (2021)](https://openreview.net/forum?id=TVHS5Y4dNvM) ([Code](https://github.com/tmp-iclr/convmixer))
- [ViP-DeepLab: Learning Visual Perception with Depth-aware Video Panoptic Segmentation (2020)](https://arxiv.org/abs/2012.05258) ([Code](https://github.com/joe-siyuan-qiao/ViP-DeepLab))
- [Video Panoptic Segmentation (2020)](https://arxiv.org/abs/2006.11339) ([Code](https://github.com/mcahny/vps))
- [Awesome-ICCV2021-Low-Level-Vision](https://github.com/Kobaayyy/Awesome-ICCV2021-Low-Level-Vision) - Collection of Papers and Codes for ICCV2021 Low Level Vision and Image Generation.
- [Multiple Heads are Better than One: Few-shot Font Generation with Multiple Localized Experts (2021)](https://arxiv.org/abs/2104.00887) ([Code](https://github.com/clovaai/mxfont))
- [Non-deep Networks (2021)](https://arxiv.org/abs/2110.07641) ([Code](https://github.com/imankgoyal/NonDeepNetworks))
- [receptivefield](https://github.com/fornaxai/receptivefield) - Gradient based receptive field estimation for Convolutional Neural Networks.
- [Iso-Points: Optimizing Neural Implicit Surfaces with Hybrid Representations (2021)](https://igl.ethz.ch/projects/iso-points/) ([Code](https://github.com/yifita/iso-points))
- [Neural Articulated Radiance Field (2021)](https://arxiv.org/abs/2104.03110) ([Code](https://github.com/nogu-atsu/NARF))
- [Efficient Visual Pretraining with Contrastive Detection (2021)](https://arxiv.org/abs/2103.10957) ([Code](https://github.com/deepmind/detcon))
- [VoTT (Visual Object Tagging Tool)](https://github.com/microsoft/VoTT) - Source annotation and labeling tool for image and video assets.
- [FlexConv: Continuous Kernel Convolutions with Differentiable Kernel Sizes (2021)](https://arxiv.org/abs/2110.08059) ([Code](https://github.com/rjbruin/flexconv))
- [ByteTrack: Multi-Object Tracking by Associating Every Detection Box (2021)](https://arxiv.org/abs/2110.06864) ([Code](https://github.com/ifzhang/ByteTrack))
- [Dense Video Captioning with Bi-modal Transformer (2020)](https://iashin.ai/bmt) ([Code](https://github.com/v-iashin/BMT))
- [PyTorch-Encoding](https://github.com/zhanghang1989/PyTorch-Encoding) - CV toolkit for my papers. ([Docs](https://hangzhang.org/PyTorch-Encoding/))
- [Space Time Recurrent Memory Network (2021)](https://arxiv.org/abs/2109.06474) ([Code](https://github.com/lucidrains/spacetime-recurrent-memory-network))
- [CVNets](https://github.com/apple/ml-cvnets) - Library for training computer vision networks.
- [Scenic](https://github.com/google-research/scenic) - Jax Library for Computer Vision Research and Beyond. ([Paper](https://arxiv.org/abs/2110.11403))
- [CV Arxiv Daily](http://vincentqin.tech/cv-arxiv-daily/) ([Code](https://github.com/Vincentqyw/cv-arxiv-daily))
- [OpenVisionCapsules](https://github.com/opencv/open_vision_capsules) - Set of libraries for encapsulating smart vision algorithms.
- [MedMNIST: Large-Scale Lightweight Benchmark for 2D and 3D Biomedical Image Classification](https://medmnist.com/) ([Code](https://github.com/MedMNIST/MedMNIST))
- [Dynamic Visual Reasoning by Learning Differentiable Physics Models from Video and Language (2021)](https://arxiv.org/abs/2110.15358) ([Code](https://github.com/dingmyu/VRDP))
- [Neural-Pull: Learning Signed Distance Functions from Point Clouds by Learning to Pull Space onto Surfaces (2021)](https://arxiv.org/abs/2011.13495) ([Code](https://github.com/mabaorui/NeuralPull))
- [The 2021 Image Similarity Dataset and Challenge (2021)](https://arxiv.org/abs/2106.09672) ([Code](https://github.com/facebookresearch/isc2021))
- [K-Net: Towards Unified Image Segmentation (2021)](https://arxiv.org/abs/2106.14855) ([Code](https://github.com/ZwwWayne/K-Net))
- [Yolov5 + Deep Sort with PyTorch](https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch)
- [Shape As Points: A Differentiable Poisson Solver (2021)](https://arxiv.org/abs/2106.03452) ([Code](https://github.com/autonomousvision/shape_as_points))
- [Supervision Exists Everywhere: A Data Efficient Contrastive Language-Image Pre-training Paradigm (2021)](https://arxiv.org/abs/2110.05208) ([Code](https://github.com/Sense-GVT/DeCLIP))
- [Awesome Vision-Language Navigation](https://github.com/daqingliu/awesome-vln)
- [An Exploration of Embodied Visual Exploration (2021)](http://vision.cs.utexas.edu/projects/exploring-exploration/) ([Code](https://github.com/facebookresearch/exploring_exploration))
- [DVC: An End-to-end Deep Video Compression Framework (2019)](https://arxiv.org/abs/1812.00101) ([Code](https://github.com/GuoLusjtu/DVC))
- [Pixray](https://github.com/dribnet/pixray) - Neural image generation.
- [Unsupervised Learning of Compositional Energy Concepts (2021)](https://arxiv.org/abs/2111.03042) ([Tweet](https://twitter.com/du_yilun/status/1456630363040751616))
- [Learning with Noisy Labels for Robust Point Cloud Segmentation (2021)](https://shuquanye.com/PNAL_website/) ([Code](https://github.com/pleaseconnectwifi/PNAL))
- [Kalidoface](https://github.com/yeemachine/kalidoface) - Become a virtual character with just your webcam. ([Web](https://kalidoface.com/))
- [KalidoKit](https://github.com/yeemachine/kalidokit) - Face, Pose, and Hand Tracking Kinematics.
- [The Ancient Secrets of Computer Vision](https://pjreddie.com/courses/computer-vision/)
- [Unsupervised Real-world Image Super Resolution via Domain-distance Aware Training (2020)](https://arxiv.org/abs/2004.01178) ([Code](https://github.com/ShuhangGu/DASR))
- [PyGaze](https://www.pygaze.org/) - Open source eye-tracking software and more. ([HN](https://news.ycombinator.com/item?id=29171416))
- [Exploring Relational Context for Multi-Task Dense Prediction (2021)](https://arxiv.org/abs/2104.13874) ([Code](https://github.com/brdav/atrc))
- [Neural Scene Graphs for Dynamic Scenes (2021)](https://light.princeton.edu/publication/neural-scene-graphs/) ([Code](https://github.com/princeton-computational-imaging/neural-scene-graphs))
- [Image Super-Resolution via Iterative Refinement](https://iterative-refinement.github.io/) ([HN](https://news.ycombinator.com/item?id=29202899)) ([Code](https://github.com/Janspiry/Image-Super-Resolution-via-Iterative-Refinement))
- [UniFormer: Unified Transformer for Efficient Spatial-Temporal Representation Learning (2021)](https://openreview.net/forum?id=nBU_u6DLvoK) ([Code](https://github.com/lucidrains/uniformer-pytorch))
- [Keeping Your Eye on the Ball: Trajectory Attention in Video Transformers (2021)](https://arxiv.org/abs/2106.05392) ([Code](https://github.com/facebookresearch/Motionformer))
- [Multimodal Virtual Point 3D Detection (2021)](https://tianweiy.github.io/mvp/) ([Code](https://github.com/tianweiy/MVP))
- [SiT: Self-supervised vIsion Transformer](https://github.com/Sara-Ahmed/SiT)
- [Attention Mechanisms in Computer Vision: A Survey (2021)](https://arxiv.org/abs/2111.07624)
- [Awesome Vision Attention Papers](https://github.com/MenghaoGuo/Awesome-Vision-Attentions)
- [FastFlowNet: A Lightweight Network for Fast Optical Flow Estimation (2021)](https://arxiv.org/abs/2103.04524) ([Code](https://github.com/ltkong218/FastFlowNet))
- [RenderNet: A deep convolutional network for differentiable rendering from 3D shapes (2018)](https://www.monkeyoverflow.com/#/rendernet-a-cnn-for-differentiable-rendering-from-3d-shapes/) ([Code](https://github.com/thunguyenphuoc/RenderNet))
- [Masked Autoencoders Are Scalable Vision Learners (2021)](https://arxiv.org/abs/2111.06377) ([Code](https://github.com/pengzhiliang/MAE-pytorch)) ([Code](https://github.com/facebookresearch/mae)) ([Code](https://github.com/catalys1/mae-pytorch))
- [BoostingMonocularDepth](https://github.com/compphoto/BoostingMonocularDepth)
- [It's About Time: Analog Clock Reading in the Wild (2021)](https://arxiv.org/abs/2111.09162) ([Tweet](https://twitter.com/giffmana/status/1461249563466022913)) ([Code](https://github.com/charigyang/itsabouttime))
- [Learning to Compose Visual Relations (2021)](https://composevisualrelations.github.io/) ([Code](https://github.com/nanlliu/compose-visual-relations))
- [LF-Net: Learning Local Features from Images (2018)](https://arxiv.org/abs/1805.09662) ([Code](https://github.com/vcg-uvic/lf-net-release))
- [Aligning Pretraining for Detection via Object-Level Contrastive Learning (2021)](https://arxiv.org/abs/2106.02637) ([Code](https://github.com/hologerry/SoCo))
- [Look at the Variance! Efficient Black-box Explanations with Sobol-based Sensitivity Analysis (2021)](https://arxiv.org/abs/2111.04138) ([Code](https://github.com/fel-thomas/Sobol-Attribution-Method))
- [Deep unfolding network for image super-resolution (2020)](https://github.com/cszn/USRNet)
- [VOLO: Vision Outlooker for Visual Recognition (2021)](https://arxiv.org/abs/2106.13112) ([Code](https://github.com/sail-sg/volo))
- [Direct Multi-view Multi-person 3D Pose Estimation (2021)](https://arxiv.org/abs/2111.04076) ([Code](https://github.com/sail-sg/mvp))
- [Image2Mesh: A learning framework for single image 3D reconstruction (2019)](https://jhonykaesemodel.com/publication/image2mesh/) ([Code](https://github.com/jhonykaesemodel/image2mesh))
- [GammaCV](https://github.com/PeculiarVentures/GammaCV) - WebGL accelerated Computer Vision library for modern web applications. ([Web](https://gammacv.com/))
- [Localizing Objects with Self-Supervised Transformers and no Labels (2021)](https://arxiv.org/abs/2109.14279) ([Code](https://github.com/valeoai/LOST))
- [Harvester](https://github.com/genicam/harvesters) - GenICam-based Image Acquisition Python Library.
- [NÜWA: Visual Synthesis Pre-training for Neural visUal World creAtion (2021)](https://arxiv.org/abs/2111.12417) ([Code](https://github.com/microsoft/NUWA)) ([PyTorch Code](https://github.com/lucidrains/nuwa-pytorch))
- [ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision (2021)](https://arxiv.org/abs/2102.03334) ([Code](https://github.com/dandelin/ViLT))
- [MetaFormer is Actually What You Need for Vision (2021)](https://arxiv.org/abs/2111.11418) ([Code](https://github.com/sail-sg/poolformer))
- [ARAPReg: An As-Rigid-As Possible Regularization Loss for Learning Deformable Shape Generators (2021)](https://arxiv.org/abs/2108.09432) ([Code](https://github.com/GitBoSun/ARAPReg))
- [Mesa: A Memory-saving Training Framework for Transformers (2021)](https://arxiv.org/abs/2111.11124) ([Code](https://github.com/zhuang-group/Mesa))
- [MMPose](https://github.com/open-mmlab/mmpose) - Open-source toolbox for pose estimation based on PyTorch. ([Docs](https://mmpose.readthedocs.io/en/latest/))
- [An Empirical Study of Training End-to-End Vision-and-Language Transformers (2021)](https://arxiv.org/abs/2111.02387) ([Code](https://github.com/zdou0830/METER))
- [Useful computer vision PhD resources](https://github.com/hassony2/useful-computer-vision-phd-resources)
- [Tenyks](https://www.tenyks.ai/) - Data-centric Computer Vision.
- [Mask2Former: Masked-attention Mask Transformer for Universal Image Segmentation (2021)](https://bowenc0221.github.io/mask2former/) ([Code](https://github.com/facebookresearch/Mask2Former))
- [GIRAFFE: Representing Scenes as Compositional Generative Neural Feature Fields (2021)](https://m-niemeyer.github.io/project-pages/giraffe/index.html) ([Code](https://github.com/autonomousvision/giraffe))
- [Learning to See by Looking at Noise (2021)](https://mbaradad.github.io/learning_with_noise/) ([Code](https://github.com/mbaradad/learning_with_noise))
- [iBOT: Image BERT Pre-Training with Online Tokenizer (2021)](https://arxiv.org/abs/2111.07832) ([Code](https://github.com/bytedance/ibot))
- [Grounded Language-Image Pre-training (2021)](https://arxiv.org/abs/2112.03857) ([Code](https://github.com/microsoft/GLIP))
- [3D-R2N2: A Unified Approach for Single and Multi-view 3D Object Reconstruction (2016)](https://arxiv.org/abs/1604.00449) ([Code](https://github.com/chrischoy/3D-R2N2))
- [Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks](http://proceedings.mlr.press/v97/lee19d.html) ([Code](https://github.com/juho-lee/set_transformer))
- [Awesome Visual Grounding](https://github.com/TheShadow29/awesome-grounding)
- [Are Transformers More Robust Than CNNs? (2021)](https://arxiv.org/abs/2111.05464) ([Code](https://github.com/ytongbai/ViTs-vs-CNNs))
- [Plenoxels: Radiance Fields without Neural Networks (2021)](https://alexyu.net/plenoxels/) ([Code](https://github.com/sxyu/svox2)) ([Code](https://github.com/sarafridov/plenoxels))
- [GFPGAN](https://github.com/TencentARC/GFPGAN) - Developing Practical Algorithms for Real-world Face Restoration.
- [Awesome Video Stabilization](https://github.com/yaochih/awesome-video-stabilization)
- [MVSNeRF: Fast Generalizable Radiance Field Reconstruction from Multi-View Stereo (2021)](https://apchenstu.github.io/mvsnerf/) ([Code](https://github.com/apchenstu/mvsnerf))
- [Tracking People with 3D Representations (2021)](http://people.eecs.berkeley.edu/~jathushan/T3DP/) ([Code](https://github.com/brjathu/T3DP))
- [Class-balanced Grouping and Sampling for Point Cloud 3D Object Detection (2019:)](https://arxiv.org/abs/1908.09492) ([Code](https://github.com/poodarchu/Det3D))
- [Learning to Stylize Novel Views (2021)](https://hhsinping.github.io/3d_scene_stylization/) ([Code](https://github.com/hhsinping/stylescene))
- [YOLOX](https://github.com/Megvii-BaseDetection/YOLOX) - High-performance anchor-free YOLO. ([Docs](https://yolox.readthedocs.io/en/latest/))
- [PyMAF: 3D Human Pose and Shape Regression with Pyramidal Mesh Alignment Feedback Loop (2021)](https://hongwenzhang.github.io/pymaf/) ([Code](https://github.com/HongwenZhang/PyMAF))
- [SeqFormer: a Frustratingly Simple Model for Video Instance Segmentation (2021)](https://arxiv.org/abs/2112.08275) ([Code](https://github.com/wjf5203/SeqFormer))
- [NeRD: Neural Reflectance Decomposition from Image Collections (2021)](https://markboss.me/publication/2021-nerd/) ([Code](https://github.com/cgtuebingen/NeRD-Neural-Reflectance-Decomposition))
- [Vector Quantized Diffusion Model for Text-to-Image Synthesis (2021)](https://arxiv.org/abs/2111.14822) ([Code](https://github.com/microsoft/VQ-Diffusion)) ([Code](https://github.com/cientgu/VQ-Diffusion)) ([Code](https://github.com/microsoft/VQ-Diffusion))
- [GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models (2021)](https://arxiv.org/abs/2112.10741) ([Code](https://github.com/openai/glide-text2im))
- [SynthDet](https://github.com/Unity-Technologies/SynthDet) - End-to-end object detection pipeline using synthetic data.
- [MPViT: Multi-Path Vision Transformer for Dense Prediction (2021)](https://arxiv.org/abs/2112.11010) ([Code](https://github.com/youngwanLEE/MPViT))
- [StyleSwin: Transformer-based GAN for High-resolution Image Generation (2021)](https://arxiv.org/abs/2112.10762) ([Code](https://github.com/microsoft/StyleSwin))
- [Revisiting Point Cloud Shape Classification with a Simple and Effective Baseline (2021)](https://arxiv.org/abs/2106.05304) ([Code](https://github.com/princeton-vl/SimpleView))
- [SLIP: Self-supervision meets Language-Image Pre-training (2021)](https://arxiv.org/abs/2112.12750) ([Code](https://github.com/facebookresearch/SLIP))
- [General Facial Representation Learning in a Visual-Linguistic Manner (2021)](https://arxiv.org/abs/2112.03109) ([Code](https://github.com/microsoft/FaRL)) ([Code](https://github.com/FacePerceiver/FaRL))
- [HyperNeRF: A Higher-Dimensional Representation for Topologically Varying Neural Radiance Fields](https://hypernerf.github.io/) ([Code](https://github.com/google/hypernerf)) ([HN](https://news.ycombinator.com/item?id=29698276))
- [Learning to Regress Bodies from Images using Differentiable Semantic Rendering (2021)](https://arxiv.org/abs/2110.03480) ([Code](https://github.com/saidwivedi/DSR))
- [High-Resolution Image Synthesis with Latent Diffusion Models (2021)](https://arxiv.org/abs/2112.10752) ([Code](https://github.com/CompVis/latent-diffusion))
- [Photorealistic Audio-driven Video Portraits (2020)](https://richardt.name/publications/audio-dvp/) ([Code](https://github.com/xinwen-cs/AudioDVP))
- [Awesome Hand Pose Estimation](https://github.com/xinghaochen/awesome-hand-pose-estimation)
- [Generic Attention-model Explainability for Interpreting Bi-Modal and Encoder-Decoder Transformers (2021)](https://arxiv.org/abs/2103.15679) ([Code](https://github.com/hila-chefer/Transformer-MM-Explainability))
- [Transformer Interpretability Beyond Attention Visualization (2021)](https://arxiv.org/abs/2012.09838) ([Code](https://github.com/hila-chefer/Transformer-Explainability))
- [StyleCLIPDraw: Coupling Content and Style in Text-to-Drawing Synthesis (2021)](https://arxiv.org/abs/2111.03133) ([Code](https://github.com/pschaldenbrand/StyleCLIPDraw))
- [Light Field Image Super-Resolution with Transformers (2021)](https://arxiv.org/abs/2108.07597) ([Code](https://github.com/ZhengyuLiang24/LFT))
- [Unleashing Transformers: Parallel Token Prediction with Discrete Absorbing Diffusion for Fast High-Resolution Image Generation from Vector-Quantized Codes (2021)](https://arxiv.org/abs/2111.12701) ([Code](https://github.com/samb-t/unleashing-transformers))
- [DeepSIM: Image Shape Manipulation from a Single Augmented Training Sample (2021)](https://www.vision.huji.ac.il/deepsim/) ([Code](https://github.com/eliahuhorwitz/DeepSIM))
- [RAFT-3D: Scene Flow using Rigid-Motion Embeddings (2021)](https://arxiv.org/abs/2012.00726) ([Code](https://github.com/princeton-vl/RAFT-3D))
- [Unsupervised Indoor Depth Estimation (2020)](https://jwbian.net/unsupervised-indoor-depth) ([Code](https://github.com/JiawangBian/Unsupervised-Indoor-Depth))
- [A-NeRF: Articulated Neural Radiance Fields for Learning Human Shape, Appearance, and Pose (2021)](https://arxiv.org/abs/2102.06199) ([Code](https://github.com/LemonATsu/A-NeRF))
- [Rethinking Self-supervised Correspondence Learning: A Video Frame-level Similarity Perspective (2021)](https://arxiv.org/abs/2103.17263) ([Code](https://github.com/xvjiarui/VFS#readme))
- [Sara](https://gitlab.com/DO-CV/sara) - Easy-to-Use C++ Computer Vision Library.
- [RAFT-Stereo: Multilevel Recurrent Field Transforms for Stereo Matching (2021)](https://arxiv.org/abs/2109.07547) ([Code](https://github.com/princeton-vl/RAFT-Stereo))
- [U-2-Net: Going Deeper with Nested U-Structure for Salient Object Detection (2020)](https://arxiv.org/abs/2005.09007) ([Code](https://github.com/Norod/U-2-Net-StyleTransfer))
- [Language as Queries for Referring Video Object Segmentation (2022)](https://arxiv.org/abs/2201.00487) ([Code](https://github.com/wjn922/ReferFormer))
- [Localization with Sampling-Argmax (2021)](https://arxiv.org/abs/2110.08825) ([Code](https://github.com/Jeff-sjtu/sampling-argmax))
- [VOCA: Voice Operated Character Animation](https://voca.is.tue.mpg.de/) ([Code](https://github.com/TimoBolkart/voca))
- [CVZone](https://github.com/cvzone/cvzone) - Computer vision package that makes its easy to run Image processing and AI functions.
- [Deepface](https://github.com/serengil/deepface) - Lightweight Face Recognition and Facial Attribute Analysis (Age, Gender, Emotion and Race) Library for Python.
- [Location-aware Single Image Reflection Removal (2021)](https://arxiv.org/abs/2012.07131) ([Code](https://github.com/zdlarr/Location-aware-SIRR))
- [MeshTalk: 3D Face Animation from Speech using Cross-Modality Disentanglement (2021)](https://arxiv.org/abs/2104.08223) ([Code](https://github.com/facebookresearch/meshtalk))
- [Detecting Twenty-thousand Classes using Image-level Supervision (2022)](https://arxiv.org/abs/2201.02605) ([Code](https://github.com/facebookresearch/Detic))
- [Language-driven Semantic Segmentation (2022)](https://arxiv.org/abs/2201.03546) ([Code](https://github.com/isl-org/lang-seg))
- [Rethinking Nearest Neighbors for Visual Classification (2021)](https://arxiv.org/abs/2112.08459) ([Code](https://github.com/KMnP/nn-revisit))
- [Vision Transformer with Deformable Attention (2022)](https://arxiv.org/abs/2201.00520) ([Code](https://github.com/LeapLabTHU/DAT)) ([Code](https://github.com/lucidrains/deformable-attention))
- [KerasCV](https://github.com/keras-team/keras-cv) - Industry-strength Computer Vision workflows with Keras.
- [Instant Neural Graphics Primitives](https://github.com/NVlabs/instant-ngp) - Lightning fast NeRF and more.
- [Dynamic Head: Unifying Object Detection Heads with Attentions (2021)](https://arxiv.org/abs/2106.08322) ([Code](https://github.com/microsoft/DynamicHead))
- [ELSA: Enhanced Local Self-Attention for Vision Transformer (2021)](https://arxiv.org/abs/2112.12786) ([Code](https://github.com/damo-cv/ELSA))
- [FFCV](https://github.com/libffcv/ffcv) - Fast Forward Computer Vision (and other ML workloads!) ([Web](https://ffcv.io/))
- [Awesome Vit](https://github.com/open-mmlab/awesome-vit) - Curated list and survey of awesome Vision Transformers.
- [Instant Neural Graphics Primitives with a Multiresolution Hash Encoding (2022)](https://nvlabs.github.io/instant-ngp/) ([Code](https://github.com/ashawkey/torch-ngp)) ([Code](https://github.com/yashbhalgat/HashNeRF-pytorch)) ([Video Summary](https://www.youtube.com/watch?v=j8tMk-GE8hY)) ([HN](https://news.ycombinator.com/item?id=30408898))
- [Road Extraction by Deep Residual U-Net (2017)](https://arxiv.org/abs/1711.10684) ([Code](https://github.com/nikhilroxtomar/Deep-Residual-Unet))
- [Single-Stage 6D Object Pose Estimation (2019)](https://arxiv.org/abs/1911.08324) ([Code](https://github.com/cvlab-epfl/single-stage-pose))
- [Visual Task Adaptation Benchmark (VTAB)](https://github.com/google-research/task_adaptation)
- [TAda! Temporally-Adaptive Convolutions for Video Understanding (2022)](https://tadaconv-iclr2022.github.io/) ([Code](https://github.com/alibaba-mmai-research/TAdaConv))
- [UNISURF: Unifying Neural Implicit Surfaces and Radiance Fields for Multi-View Reconstruction (2021)](https://moechsle.github.io/unisurf/) ([Code](https://github.com/autonomousvision/unisurf))
- [Co-Fusion: Real-time Segmentation, Tracking and Fusion of Multiple Objects (2020)](http://visual.cs.ucl.ac.uk/pubs/cofusion/index.html) ([Code](https://github.com/martinruenz/co-fusion))
- [VRT: A Video Restoration Transformer (2021)](https://arxiv.org/abs/2201.12288) ([Code](https://github.com/JingyunLiang/VRT))
- [Unknown Object Segmentation from Stereo Images (2021)](https://arxiv.org/abs/2103.06796) ([Code](https://github.com/DLR-RM/instr))
- [Stacked Cross Attention for Image-Text Matching (2018)](https://arxiv.org/abs/1803.08024) ([Code](https://github.com/kuanghuei/SCAN))
- [BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation (2022)](https://arxiv.org/abs/2201.12086) ([Code](https://github.com/salesforce/BLIP))
- [DeFlow: Learning Complex Image Degradations from Unpaired Data with Conditional Flows (2021)](https://arxiv.org/abs/2101.05796) ([Code](https://github.com/volflow/DeFlow))
- [DocFormer: End-to-End Transformer for Document Understanding (2022)](https://arxiv.org/abs/2106.11539) ([Code](https://github.com/shabie/docformer))
- [SeMask: Semantically Masked Transformers for Semantic Segmentation (2021)](https://arxiv.org/abs/2112.12782) ([Code](https://github.com/Picsart-AI-Research/SeMask-Segmentation))
- [Image Quality Assessment: Unifying Structure and Texture Similarity (2020)](https://arxiv.org/abs/2004.07728) ([Code](https://github.com/dingkeyan93/DISTS))
- [Learning Super-Features for Image Retrieval (2022)](https://github.com/naver/fire)
- [YOLOv7](https://github.com/jinfagang/yolov7) - Framework Beyond Detection.
- [A Simple Baseline for Zero-shot Semantic Segmentation with Pre-trained Vision-language Model (2021)](https://arxiv.org/abs/2112.14757) ([Code](https://github.com/MendelXu/zsseg.baseline))
- [Single/Multiple Object Tracking and Segmentation](https://github.com/JudasDie/SOTS)
- [Learnable Multi-level Frequency Decomposition and Hierarchical Attention Mechanism for Generalized Face Presentation Attack Detection (2021)](https://arxiv.org/abs/2109.07950) ([Code](https://github.com/meilfang/LMFD-PAD))
- [HifiFace: 3D Shape and Semantic Prior Guided High Fidelity Face Swapping (2021)](https://arxiv.org/abs/2106.09965) ([Code](https://github.com/mindslab-ai/hififace))
- [Scalable Large Scene Neural View Synthesis (2022)](https://waymo.com/research/block-nerf/) ([HN](https://news.ycombinator.com/item?id=30299498))
- [Transformer Recipe](https://github.com/dair-ai/Transformers-Recipe) - Quick recipe to learn all about Transformers.
- [NeROIC: Neural Rendering of Objects from Online Image Collections (2022)](https://arxiv.org/abs/2201.02533) ([Code](https://github.com/snap-research/NeROIC))
- [DiffusionNet: Discretization Agnostic Learning on Surfaces (2022)](https://arxiv.org/abs/2012.00888) ([Code](https://github.com/nmwsharp/diffusion-net))
- [FILM: Frame Interpolation for Large Motion (2022)](https://film-net.github.io/) ([Code](https://github.com/google-research/frame-interpolation))
- [Learning Signed Distance Field for Multi-view Surface Reconstruction (2021)](https://arxiv.org/abs/2108.09964) ([Code](https://github.com/jzhangbs/MVSDF))
- [Deep Metric Learning in PyTorch](https://github.com/bnu-wangxun/Deep_Metric)
- [ICON: Implicit Clothed humans Obtained from Normals (2021)](https://icon.is.tue.mpg.de/) ([Code](https://github.com/YuliangXiu/ICON))
- [CLIPasso: Semantically-Aware Object Sketching (2022)](https://clipasso.github.io/clipasso/) ([Code](https://github.com/yael-vinker/CLIPasso))
- [BANMo: Building Animatable 3D Neural Models from Many Casual Videos (2022)](https://banmo-www.github.io/) ([Code](https://github.com/facebookresearch/banmo))
- [How Do Vision Transformers Work?](https://github.com/xxxnell/how-do-vits-work)
- [Top 10 Computer Vision Papers of 2021](https://github.com/louisfb01/top-10-cv-papers-2021)
- [Exploring Sparsity in Image Super-Resolution for Efficient Inference (2021)](https://arxiv.org/abs/2006.09603) ([Code](https://github.com/The-Learning-And-Vision-Atelier-LAVA/SMSR))
- [AutoInt: Automatic Integration for Fast Neural Volume Rendering (2021)](https://github.com/computational-imaging/automatic-integration)
- [Learning to Prompt for Vision-Language Models (2021)](https://arxiv.org/abs/2109.01134) ([Code](https://github.com/KaiyangZhou/CoOp))
- [Summarizing Videos with Attention (2019)](https://arxiv.org/abs/1812.01969) ([Code](https://github.com/ok1zjf/VASNet))
- [vkit](https://github.com/vkit-dev/vkit) - Toolkit designed for CV (Computer Vision) developers. ([Docs](https://vkit-dev.github.io/))
- [Generative Adversarial Graph Convolutional Networks for Human Action Synthesis (2021)](https://arxiv.org/abs/2110.11191) ([Code](https://github.com/DegardinBruno/Kinetic-GAN))
- [Awesome Image Matting](https://github.com/wchstrife/Awesome-Image-Matting)
- [Image-to-Markup Generation with Coarse-to-Fine Attention](http://lstm.seas.harvard.edu/latex/) ([Code](https://github.com/harvardnlp/im2markup))
- [Push-ups with Python, mediapipe and OpenCV](https://aryanvij02.medium.com/push-ups-with-python-mediapipe-open-a544bd9b4351) ([HN](https://news.ycombinator.com/item?id=30402651))
- [Lama-cleaner: Image inpainting tool powered by LaMa](https://github.com/Sanster/lama-cleaner)
- [Vision-Language Pre-Training with Triple Contrastive Learning (2022)](https://arxiv.org/abs/2202.10401) ([Code](https://github.com/uta-smile/TCL))
- [3D Machine Learning resources/papers](https://github.com/timzhang642/3D-Machine-Learning)
- [FiftyOne](https://github.com/voxel51/fiftyone) - Open-source tool for building high-quality datasets and computer vision models.
- [Self-Supervised Transformers for Unsupervised Object Discovery using Normalized Cut (2022)](https://arxiv.org/abs/2202.11539) ([Code](https://github.com/YangtaoWANG95/TokenCut))
- [Awesome Multiple object Tracking](https://github.com/luanshiyinyang/awesome-multiple-object-tracking)
- [Rethinking Coarse-to-Fine Approach in Single Image Deblurring (2021)](https://arxiv.org/abs/2108.05054) ([Code](https://github.com/chosj95/MIMO-UNet))
- [Less is More: ClipBERT for Video-and-Language Learning via Sparse Sampling (2021)](https://arxiv.org/abs/2102.06183) ([Code](https://github.com/jayleicn/ClipBERT))
- [As-ViT: Auto-scaling Vision Transformers without Training (2022)](https://arxiv.org/abs/2202.11921) ([Code](https://github.com/VITA-Group/AsViT))
- [Awesome 3D Body Papers](https://github.com/3DFaceBody/awesome-3dbody-papers)
- [RINDNet: Edge Detection for Discontinuity in Reflectance, Illumination, Normal and Depth (2021)](https://arxiv.org/abs/2108.00616) ([Code](https://github.com/MengyangPu/RINDNet))
- [Image Similarity Challenge](https://github.com/drivendataorg/image-similarity-challenge)
- [Blended Diffusion for Text-driven Editing of Natural Images (2021)](https://arxiv.org/abs/2111.14818) ([Code](https://github.com/omriav/blended-diffusion))
- [The Many Faces of Robustness: A Critical Analysis of Out-of-Distribution Generalization (2021)](https://arxiv.org/abs/2006.16241) ([Code](https://github.com/hendrycks/imagenet-r))
- [Awesome Object Pose](https://github.com/nkalavak/awesome-object-pose)
- [Video Enhancement papers/resources](https://github.com/yulunzhang/video-enhancement)
- [PowerQE: An Open Framework for Quality Enhancement of Compressed Visual Data](https://github.com/ryanxingql/powerqe)
- [Semi-Supervised Semantic Segmentation Using Unreliable Pseudo-Labels (2022)](https://arxiv.org/abs/2203.03884) ([Code](https://github.com/Haochen-Wang409/U2PL))
- [Accurate Image Alignment and Registration Using OpenCV (2022)](https://magamig.github.io/posts/accurate-image-alignment-and-registration-using-opencv/) ([HN](https://news.ycombinator.com/item?id=30613745))
- [Video Grounding and Captioning](https://github.com/facebookresearch/grounded-video-description)
- [Awesome Detection Transformer](https://github.com/IDEACVR/awesome-detection-transformer)
- [StyleNeRF: A Style-based 3D-Aware Generator for High-resolution Image Synthesis (2021)](https://arxiv.org/abs/2110.08985) ([Code](https://github.com/facebookresearch/StyleNeRF)) ([Web](http://jiataogu.me/style_nerf/)) ([HN](https://news.ycombinator.com/item?id=30637403))
- [Pyramidal Convolution: Rethinking Convolutional Neural Networks for Visual Recognition (2020)](https://arxiv.org/abs/2006.11538) ([Code](https://github.com/iduta/pyconv))
- [MHFormer: Multi-Hypothesis Transformer for 3D Human Pose Estimation (2021)](https://arxiv.org/abs/2111.12707) ([Code](https://github.com/Vegetebird/MHFormer))
- [DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection (2022)](https://arxiv.org/abs/2203.03605) ([Code](https://github.com/IDEACVR/DINO))
- [Single-Shot Multi-Object 3D Shape Reconstruction and Categorical 6D Pose and Size Estimation (2022)](https://github.com/zubair-irshad/CenterSnap)
- [CycleMLP: A MLP-like Architecture for Dense Prediction (2022)](https://arxiv.org/abs/2107.10224) ([Code](https://github.com/ShoufaChen/CycleMLP))
- [Image Quality Assessment Benchmark](https://github.com/weizhou-geek/Image-Quality-Assessment-Benchmark)
- [StyleSDF: High-Resolution 3D-Consistent Image and Geometry Generation (2021)](https://arxiv.org/abs/2112.11427) ([Code](https://github.com/royorel/StyleSDF))
- [Transformers, originally designed to handle language, are taking on vision (2022)](https://www.quantamagazine.org/will-transformers-take-over-artificial-intelligence-20220310/) ([HN](https://news.ycombinator.com/item?id=30629214))
- [Fast Image Processing with Fully-Convolutional Networks (2017)](https://arxiv.org/abs/1709.00643) ([Code](https://github.com/nrupatunga/Fast-Image-Filters))
- [Efficient Attention: Attention with Linear Complexities (2020)](https://arxiv.org/abs/1812.01243) ([Code](https://github.com/cmsflash/efficient-attention))
- [Label-Efficient Semantic Segmentation with Diffusion Models (2022)](https://yandex-research.github.io/ddpm-segmentation/) ([Code](https://github.com/yandex-research/ddpm-segmentation))
- [hloc](https://github.com/cvg/Hierarchical-Localization) - Modular toolbox for state-of-the-art 6-DoF visual localization.
- [All Tokens Matter: Token Labeling for Training Better Vision Transformers (2021)](https://arxiv.org/abs/2104.10858) ([Code](https://github.com/zihangJiang/TokenLabeling))
- [Deformable ConvNets v2: More Deformable, Better Results (2018)](https://arxiv.org/abs/1811.11168) ([Code](https://github.com/chengdazhi/Deformable-Convolution-V2-PyTorch))
- [Restormer: Efficient Transformer for High-Resolution Image Restoration (2021)](https://arxiv.org/abs/2111.09881) ([Code](https://github.com/swz30/Restormer))
- [Anti-Oversmoothing in Deep Vision Transformers via the Fourier Domain Analysis: From Theory to Practice (2022)](https://openreview.net/forum?id=O476oWmiNNp) ([Code](https://github.com/VITA-Group/ViT-Anti-Oversmoothing))
- [NeuralRecon: Real-Time Coherent 3D Reconstruction from Monocular Video (2021)](https://zju3dv.github.io/neuralrecon/) ([Code](https://github.com/zju3dv/NeuralRecon))
- [Awesome 3D Human Reconstruction](https://github.com/rlczddl/awesome-3d-human-reconstruction)
- [Awesome 3D Human Resources List](https://github.com/lijiaman/awesome-3d-human)
- [A ConvNet for the 2020s (2022)](https://arxiv.org/abs/2201.03545) ([Code](https://github.com/facebookresearch/ConvNeXt)) ([Code](https://github.com/FrancescoSaverioZuppichini/ConvNext))
- [Remote-sensing-image-semantic-segmentation](https://github.com/TachibanaYoshino/Remote-sensing-image-semantic-segmentation) - Uses Unet-based improved networks to study Remote sensing image semantic segmentation, which is based on keras.
- [Animatable Neural Radiance Fields for Modeling Dynamic Human Bodies (2021)](https://arxiv.org/abs/2105.02872) ([Code](https://github.com/zju3dv/animatable_nerf))
- [TensoRF: Tensorial Radiance Fields (2022)](https://arxiv.org/abs/2203.09517) ([Code](https://github.com/apchenstu/TensoRF))
- [Autoregressive Image Generation using Residual Quantization (2022)](https://arxiv.org/abs/2203.01941) ([Code](https://github.com/lucidrains/RQ-Transformer)) ([Code](https://github.com/kakaobrain/rq-vae-transformer))
- [Pix2Pix Timbre Transfer](https://github.com/hmartelb/Pix2Pix-Timbre-Transfer)
- [One-Shot Adaptation of GAN in Just One CLIP (2022)](https://arxiv.org/abs/2203.09301) ([Code](https://github.com/submission6378/OneshotCLIP))
- [PAConv: Position Adaptive Convolution with Dynamic Kernel Assembling on Point Clouds (2021)](https://arxiv.org/abs/2103.14635) ([Code](https://github.com/CVMI-Lab/PAConv))
- [VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training (2022)](https://arxiv.org/abs/2203.12602) ([Code](https://github.com/MCG-NJU/VideoMAE))
- [Awesome Masked Image Modeling](https://github.com/ucasligang/awesome-MIM)
- [BigDetection: A Large-scale Benchmark for Improved Object Detector Pre-training (2022)](https://arxiv.org/abs/2203.13249) ([Code](https://github.com/amazon-research/bigdetection))
- [A Transformer-Based Siamese Network for Change Detection (2022)](https://arxiv.org/abs/2201.01293) ([Code](https://github.com/wgcban/ChangeFormer))
- [Patch-NetVLAD: Multi-Scale Fusion of Locally-Global Descriptors for Place Recognition (2021)](https://arxiv.org/abs/2103.01486) ([Code](https://github.com/QVPR/Patch-NetVLAD))
- [Robust fine-tuning of zero-shot models (2022)](https://arxiv.org/abs/2109.01903) ([Code](https://github.com/mlfoundations/wise-ft))
- [DiscoBox: Weakly Supervised Instance Segmentation and Semantic Correspondence from Box Supervision (2021)](https://arxiv.org/abs/2105.06464) ([Code](https://github.com/NVlabs/DiscoBox))
- [GroupViT: Semantic Segmentation Emerges from Text Supervision (2022)](https://arxiv.org/abs/2202.11094) ([Code](https://github.com/NVlabs/GroupViT))
- [HyperTransformer: A Textural and Spectral Feature Fusion Transformer for Pansharpening (2022)](https://arxiv.org/abs/2203.02503) ([Code](https://github.com/wgcban/HyperTransformer))
- [TVConv: Efficient Translation Variant Convolution for Layout-aware Visual Processing (2022)](https://arxiv.org/abs/2203.10489) ([Code](https://github.com/JierunChen/TVConv))
- [DeepStream-Yolo](https://github.com/marcoslucianops/DeepStream-Yolo) - NVIDIA DeepStream SDK 6.0.1 configuration for YOLO models.
- [An Empirical Investigation of 3D Anomaly Detection and Segmentation (2022)](https://arxiv.org/abs/2203.05550) ([Code](https://github.com/eliahuhorwitz/3D-ADS))
- [Out-of-Domain Human Mesh Reconstruction via Dynamic Bilevel Online Adaptation (2021)](https://arxiv.org/abs/2111.04017) ([Code](https://github.com/syguan96/DynaBOA))
- [Layered Neural Atlases for Consistent Video Editing (2021)](https://arxiv.org/abs/2109.11418) ([Code](https://github.com/ykasten/layered-neural-atlases))
- [TDAN: Temporally-Deformable Alignment Network for Video Super-Resolution (2020)](https://github.com/YapengTian/TDAN-VSR-CVPR-2020)
- [Shape from Polarization for Complex Scenes in the Wild (2022)](https://chenyanglei.github.io/sfpwild/index.html) ([Code](https://github.com/ChenyangLEI/sfp-wild))
- [Pix2Seq](https://github.com/google-research/pix2seq) - General framework for turning RGB pixels into semantically meaningful sequences.
- [Gait Recognition in the Wild with Dense 3D Representations and A Benchmark (2022)](https://gait3d.github.io/) ([Code](https://github.com/Gait3D/Gait3D-Benchmark))
- [Ensembling Hugging Face Transformers made easy](https://github.com/jaketae/ensemble-transformers)
- [Relational Knowledge Distillation (2019)](https://arxiv.org/abs/1904.05068) ([Code](https://github.com/lenscloth/RKD))
- [NICE-SLAM: Neural Implicit Scalable Encoding for SLAM (2021)](https://arxiv.org/abs/2112.12130) ([Code](https://github.com/cvg/nice-slam))
- [Neural 3D Mesh Renderer (2017)](https://arxiv.org/abs/1711.07566) ([Code](https://github.com/daniilidis-group/neural_renderer))
- [Large-scale Bilingual Language-Image Contrastive Learning (2022)](https://arxiv.org/abs/2203.14463) ([Code](https://github.com/navervision/KELIP))
- [OpenMVG](https://github.com/openMVG/openMVG) - Open Multiple View Geometry library. Basis for 3D computer vision and Structure from Motion.
- [Neural Points: Point Cloud Representation with Neural Fields (2021)](https://arxiv.org/abs/2112.04148) ([Code](https://github.com/WanquanF/NeuralPoints))
- [OpenCV JS Web Worker](https://github.com/vinissimus/opencv-js-webworker) - Getting started with OpenCV compiled to Webassembly and loaded in a worker.
- [Learning Graph Regularisation for Guided Super-Resolution (2022)](https://arxiv.org/abs/2203.14297) ([Code](https://github.com/prs-eth/graph-super-resolution))
- [Video Polyp Segmentation: A Deep Learning Perspective (2022)](https://arxiv.org/abs/2203.14291) ([Code](https://github.com/GewelsJI/VPS))
- [Adjacent Context Coordination Network for Salient Object Detection in Optical Remote Sensing Images (2022)](https://arxiv.org/abs/2203.13664) ([Code](https://github.com/MathLee/ACCoNet))
- [HybridNets: End-to-End Perception Network (2022)](https://arxiv.org/abs/2203.09035) ([Code](https://github.com/datvuthanh/HybridNets))
- [HDR-NeRF: High Dynamic Range Neural Radiance Fields (2022)](https://shsf0817.github.io/hdr-nerf/) ([Code](https://github.com/shsf0817/hdr-nerf))
- [AdaMixer: A Fast-Converging Query-Based Object Detector (2022)](https://arxiv.org/abs/2203.16507) ([Code](https://github.com/MCG-NJU/AdaMixer))
- [MixFormer: End-to-End Tracking with Iterative Mixed Attention (2022)](https://arxiv.org/abs/2203.11082) ([Code](https://github.com/MCG-NJU/MixFormer))
- [Bringing Old Films Back to Life (2022)](http://raywzy.com/Old_Film/) ([Code](https://github.com/raywzy/Bringing-Old-Films-Back-to-Life))
- [Extracting Triangular 3D Models, Materials, and Lighting From Images (2022)](https://nvlabs.github.io/nvdiffrec/) ([Code](https://github.com/NVlabs/nvdiffrec))
- [LiT: Zero-Shot Transfer with Locked-image text Tuning (2021)](https://arxiv.org/abs/2111.07991) ([Tweet](https://twitter.com/giffmana/status/1508400604082806785))
- [LAFITE: Towards Language-Free Training for Text-to-Image Generation (2021)](https://arxiv.org/abs/2111.13792) ([Code](https://github.com/drboog/Lafite))
- [Neural 3D Video Synthesis from Multi-view Video (2022)](https://neural-3d-video.github.io/) ([Code](https://github.com/facebookresearch/Neural_3D_Video))
- [ToFu: Topologically Consistent Multi-View Face Inference Using Volumetric Sampling (2021)](https://github.com/tianyeli/tofu)
- [Soft Rasterizer: A Differentiable Renderer for Image-based 3D Reasoning (2019)](https://arxiv.org/abs/1904.01786) ([Code](https://github.com/ShichenLiu/SoftRas))
- [FrankMocap: A Strong and Easy-to-use Single View 3D Hand+Body Pose Estimator (2021)](https://github.com/facebookresearch/frankmocap)
- [Reddit Place Script 2022](https://github.com/rdeepak2002/reddit-place-script-2022) - Script to draw an image onto r/place.
- [A Unified Objective for Novel Class Discovery (2021)](https://arxiv.org/abs/2108.08536) ([Code](https://github.com/DonkeyShot21/UNO))
- [Papers and Datasets about Point Cloud](https://github.com/zhulf0804/3D-PointCloud)
- [On the Importance of Asymmetry for Siamese Representation Learning (2022)](https://arxiv.org/abs/2204.00613) ([Code](https://github.com/facebookresearch/asym-siam))
- [REGTR: End-to-end Point Cloud Correspondences with Transformers](https://github.com/yewzijian/RegTR)
- [A Closer Look at Local Aggregation Operators in Point Cloud Analysis (2020)](https://arxiv.org/abs/2007.01294) ([Code](https://github.com/zeliu98/CloserLook3D))
- [Online Continual Learning on a Contaminated Data Stream with Blurry Task Boundaries (2022)](https://arxiv.org/abs/2203.15355) ([Code](https://github.com/clovaai/puridiver))
- [Perception Prioritized Training of Diffusion Models (2022)](https://arxiv.org/abs/2204.00227) ([Code](https://github.com/jychoi118/P2-weighting))
- [VisualBERT: A Simple and Performant Baseline for Vision and Language (2019)](https://arxiv.org/abs/1908.03557) ([Code](https://github.com/uclanlp/visualbert))
- [MultiMAE: Multi-modal Multi-task Masked Autoencoders (2022)](https://arxiv.org/abs/2204.01678) ([Code](https://github.com/EPFL-VILAB/MultiMAE))
- [NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction (2021)](https://arxiv.org/abs/2106.10689) ([Code](https://github.com/Totoro97/NeuS))
- [Towards Open World Object Detection (2021)](https://arxiv.org/abs/2103.02603) ([Code](https://github.com/JosephKJ/OWOD))
- [Transformer in Vision](https://github.com/DirtyHarryLYL/Transformer-in-Vision) - Recent Transformer-based CV and related works.
- [Shunted Self-Attention via Multi-Scale Token Aggregation (2021)](https://arxiv.org/abs/2111.15193) ([Code](https://github.com/OliverRensu/Shunted-Transformer))
- [Space-Time Correspondence as a Contrastive Random Walk (2020)](https://ajabri.github.io/videowalk/) ([Code](https://github.com/ajabri/videowalk))
- [MaskGIT: Masked Generative Image Transformer (2022)](https://arxiv.org/abs/2202.04200) ([Code](https://github.com/google-research/maskgit))
- [EasyCV](https://github.com/alibaba/EasyCV) - All-in-one computer vision toolbox based on PyTorch.
- [Unleashing Vanilla Vision Transformer with Masked Image Modeling for Object Detection (2022)](https://arxiv.org/abs/2204.02964) ([Code](https://github.com/hustvl/MIMDet))
- [EMOCA: Emotion Driven Monocular Face Capture and Animation (2022)](https://github.com/radekd91/emoca)
- [Learning Hierarchical Cross-Modal Association for Co-Speech Gesture Generation (2022)](https://arxiv.org/abs/2203.13161) ([Code](https://github.com/alvinliu0/HA2G))
- [FaceVerse: a Fine-grained and Detail-controllable 3D Face Morphable Model from a Hybrid Dataset](http://www.liuyebin.com/faceverse/faceverse.html) ([Code](https://github.com/LizhenWangT/FaceVerse))
- [PointCLIP: Point Cloud Understanding by CLIP (2022)](https://arxiv.org/abs/2112.02413) ([Code](https://github.com/ZrrSkywalker/PointCLIP))
- [DaViT: Dual Attention Vision Transformers (2022)](https://arxiv.org/abs/2204.03645) ([Code](https://github.com/dingmyu/davit))
- [DALL-Eval: Probing the Reasoning Skills and Social Biases of Text-to-Image Generative Transformers (2022)](https://arxiv.org/abs/2202.04053) ([Code](https://github.com/j-min/DallEval))
- [Recovering 3D Human Mesh from Monocular Images: A Survey (2022)](https://arxiv.org/abs/2203.01923) ([Code](https://github.com/tinatiansjz/hmr-survey))
- [Video Diffusion Models (2022)](https://arxiv.org/abs/2204.03458v1) ([Web](https://video-diffusion.github.io/)) ([Code](https://github.com/lucidrains/video-diffusion-pytorch))
- [MaxViT: Multi-Axis Vision Transformer (2022)](https://arxiv.org/abs/2204.01697) ([Code](https://github.com/ChristophReich1996/MaxViT))
- [Unified Contrastive Learning in Image-Text-Label Space (2022)](https://arxiv.org/abs/2204.03610) ([Code](https://github.com/microsoft/UniCL))
- [RePOSE: Fast 6D Object Pose Refinement via Deep Texture Rendering (2021)](https://arxiv.org/abs/2104.00633) ([Code](https://github.com/sh8/RePOSE))
- [MetaSAug: Meta Semantic Augmentation for Long-Tailed Visual Recognition (2021)](https://arxiv.org/abs/2103.12579) ([Code](https://github.com/BIT-DA/MetaSAug))
- [Learning What Not to Segment: A New Perspective on Few-Shot Segmentation (2022)](https://arxiv.org/abs/2203.07615) ([Code](https://github.com/chunbolang/BAM))
- [MAXIM: Multi-Axis MLP for Image Processing (2022)](https://arxiv.org/abs/2201.02973) ([Code](https://github.com/google-research/maxim))
- [Tensil tutorial for YOLO v4 Tiny on Ultra96 V2 (2022)](https://k155la3.blog/2022/04/04/tensil-tutorial-for-yolo-v4-tiny-on-ultra96-v2/)
- [UNITER: UNiversal Image-TExt Representation Learning (2020)](https://arxiv.org/abs/1909.11740) ([Code](https://github.com/ChenRocks/UNITER))
- [Consistent Depth of Moving Objects in Video (2021)](https://dynamic-video-depth.github.io/) ([Code](https://github.com/google/dynamic-video-depth))
- [Bridging Video-text Retrieval with Multiple Choice Questions (2022)](https://arxiv.org/abs/2201.04850) ([Code](https://github.com/TencentARC/MCQ))
- [Cross-Domain Few-Shot Classification via Learned Feature-Wise Transformation (2020)](https://arxiv.org/abs/2001.08735) ([Code](https://github.com/hytseng0509/CrossDomainFewShot))
- [BACON: Band-limited Coordinate Networks for Multiscale Scene Representation (2022)](https://arxiv.org/abs/2112.04645) ([Code](https://github.com/computational-imaging/bacon))
- [Solving ImageNet: a Unified Scheme for Training any Backbone to Top Results (2022)](https://arxiv.org/abs/2204.03475) ([Code](https://github.com/Alibaba-MIIL/Solving_ImageNet))
- [Light Field Networks: Neural Scene Representations with Single-Evaluation Rendering (2021)](https://www.vincentsitzmann.com/lfns/) ([Code](https://github.com/vsitzmann/light-field-networks))
- [SinNeRF: Training Neural Radiance Fields on Complex Scenes from a Single Image (2022)](https://arxiv.org/abs/2204.00928) ([Code](https://github.com/VITA-Group/SinNeRF))
- [StyleMesh: Style Transfer for Indoor 3D Scene Reconstructions (2021)](https://arxiv.org/abs/2112.01530) ([Code](https://github.com/lukasHoel/stylemesh))
- [Neighborhood Attention Transformer (2022)](https://arxiv.org/abs/2204.07143) ([Code](https://github.com/SHI-Labs/Neighborhood-Attention-Transformer))
- [3D Surface Reconstruction From Multi-Date Satellite Images (2021)](https://arxiv.org/abs/2102.02502) ([Code](https://github.com/SBCV/SatelliteSurfaceReconstruction))
- [Decoupling Makes Weakly Supervised Local Feature Better (2022)](https://arxiv.org/abs/2201.02861) ([Code](https://github.com/The-Learning-And-Vision-Atelier-LAVA/PoSFeat))
- [ZeroCap: Zero-Shot Image-to-Text Generation for Visual-Semantic Arithmetic (2022)](https://arxiv.org/abs/2111.14447) ([Code](https://github.com/YoadTew/zero-shot-image-to-text))
- [EasyMocap](https://github.com/zju3dv/EasyMocap) - Open-source toolbox for markerless human motion capture from RGB videos.
- [QS-Attn: Query-Selected Attention for Contrastive Learning in I2I Translation (2022)](https://arxiv.org/abs/2203.08483) ([Code](https://github.com/sapphire497/query-selected-attention))
- [PolarMask: Single Shot Instance Segmentation with Polar Representation (2019)](https://arxiv.org/abs/1909.13226) ([Code](https://github.com/xieenze/PolarMask))
- [Latent Video Transformer (2020)](https://arxiv.org/abs/2006.10704) ([Code](https://github.com/rakhimovv/lvt))
- [NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis (2020)](https://arxiv.org/abs/2003.08934) ([JAX Code](https://github.com/unixpickle/learn-nerf))
- [A Latent Transformer for Disentangled Face Editing in Images and Videos (2021)](https://arxiv.org/abs/2106.11895) ([Code](https://github.com/InterDigitalInc/latent-transformer))
- [Photorealistic Style Transfer via Wavelet Transforms (2019)](https://arxiv.org/abs/1903.09760) ([Code](https://github.com/clovaai/WCT2))
- [Probing ViTs](https://github.com/sayakpaul/probing-vits)
- [Dense Depth Priors for Neural Radiance Fields from Sparse Input Views (2021)](https://arxiv.org/abs/2112.03288) ([Code](https://github.com/barbararoessle/dense_depth_priors_nerf))
- [Self-Supervised Models are Continual Learners (2021)](https://arxiv.org/abs/2112.04215) ([Code](https://github.com/DonkeyShot21/cassle))
- [Mask Transfiner for High-Quality Instance Segmentation (2022)](https://www.vis.xyz/pub/transfiner/) ([Code](https://github.com/SysCV/transfiner))
- [An Extendable, Efficient and Effective Transformer-based Object Detector (2022)](https://github.com/naver-ai/vidt)
- [Learned Queries for Efficient Local Attention (2021)](https://arxiv.org/abs/2112.11435) ([Code](https://github.com/moabarar/qna))
- [3D Human Pose Estimation with Spatial and Temporal Transformers (2021)](https://arxiv.org/abs/2103.10455) ([Code](https://github.com/zczcwh/PoseFormer))
- [3D human pose estimation in video with temporal convolutions and semi-supervised training (2019)](https://arxiv.org/abs/1811.11742) ([Code](https://github.com/facebookresearch/VideoPose3D))
- [MC-Calib: A generic and robust calibration toolbox for multi-camera systems (2022)](https://www.sciencedirect.com/science/article/abs/pii/S1077314221001818) ([Code](https://github.com/rameau-fr/MC-Calib))
- [Understanding The Robustness in Vision Transformers (2022)](https://arxiv.org/abs/2204.12451) ([Code](https://github.com/NVlabs/FAN))
- [Nonuniform-to-Uniform Quantization: Towards Accurate Quantization via Generalized Straight-Through Estimation (2021)](https://arxiv.org/abs/2111.14826) ([Code](https://github.com/liuzechun/Nonuniform-to-Uniform-Quantization))
- [Tackling multiple tasks with a single visual language model (2022)](https://www.deepmind.com/blog/tackling-multiple-tasks-with-a-single-visual-language-model) ([Code](https://github.com/lucidrains/flamingo-pytorch)) ([Tweet](https://twitter.com/DeepMind/status/1519686445258231811))
- [Associating Objects with Transformers for Video Object Segmentation (2021)](https://arxiv.org/abs/2106.02638) ([Code](https://github.com/z-x-yang/AOT))
- [Simple multi-dataset detection](https://github.com/xingyizhou/UniDet) - Object detection on multiple datasets with an automatically learned unified label space.
- [Learning Texture Transformer Network for Image Super-Resolution (2020)](https://arxiv.org/abs/2006.04139) ([Code](https://github.com/researchmm/TTSR))
- [Balanced MSE for Imbalanced Visual Regression (2022)](https://arxiv.org/abs/2203.16427) ([Code](https://github.com/jiawei-ren/BalancedMSE))
- [Templates for 3D Object Pose Estimation Revisited: Generalization to New Objects and Robustness to Occlusions (2022)](https://arxiv.org/abs/2203.17234) ([Code](https://github.com/nv-nguyen/template-pose))
- [Action-Conditioned 3D Human Motion Synthesis with Transformer VAE (2021)](https://arxiv.org/abs/2104.05670) ([Code](https://github.com/Mathux/ACTOR))
- [CoMoGAN: continuous model-guided image-to-image translation (2021)](https://arxiv.org/abs/2103.06879) ([Code](https://github.com/cv-rits/CoMoGAN))
- [OpenMVS](https://github.com/cdcseacave/openMVS) - Open Multi-View Stereo reconstruction library.
- [Sliced Recursive Transformer (2021)](https://arxiv.org/abs/2111.05297) ([Code](https://github.com/szq0214/SReT))
- [Neural Dual Contouring (2022)](https://arxiv.org/abs/2202.01999) ([Code](https://github.com/czq142857/NDC))
- [Awesome Deblurring](https://github.com/subeeshvasu/Awesome-Deblurring) - Curated list of resources for Image and Video Deblurring.
- [CoCa: Contrastive Captioners are Image-Text Foundation Models (2022)](https://arxiv.org/abs/2205.01917) ([Code](https://github.com/lucidrains/CoCa-pytorch))
- [Sequencer: Deep LSTM for Image Classification (2022)](https://arxiv.org/abs/2205.01972)
- [Language Models Can See: Plugging Visual Controls in Text Generation (2022)](https://arxiv.org/abs/2205.02655) ([Code](https://github.com/yxuansu/MAGIC))
- [flyswot](https://github.com/davanstrien/flyswot) - CLI for Hugging Face Transformers image classification models.
- [Neural 3D Scene Reconstruction with the Manhattan-world Assumption (2022)](https://zju3dv.github.io/manhattan_sdf/) ([Code](https://github.com/zju3dv/manhattan_sdf))
- [PoseTriplet: Co-evolving 3D Human Pose Estimation, Imitation, and Hallucination under Self-supervision (2022)](https://arxiv.org/abs/2203.15625) ([Code](https://github.com/Garfield-kh/PoseTriplet))
- [What do the Vision Transformers learn? How do they encode anything useful for image recognition? (2022)](https://twitter.com/RisingSayak/status/1515918406171914240)
- [Integrative Few-Shot Learning for Classification and Segmentation (2022)](https://arxiv.org/abs/2203.15712) ([Code](https://github.com/dahyun-kang/ifsl))
- [DeltaConv: Anisotropic Geometric Deep Learning with Exterior Calculus (2022)](https://arxiv.org/abs/2111.08799) ([Code](https://github.com/rubenwiersma/deltaconv))
- [pi-GAN: Periodic Implicit Generative Adversarial Networks for 3D-Aware Image Synthesis (2021)](https://arxiv.org/abs/2012.00926) ([Code](https://github.com/lucidrains/pi-GAN-pytorch))
- [Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework (2022)](https://arxiv.org/abs/2202.03052) ([Code](https://github.com/OFA-Sys/OFA))
- [ConvMAE: Masked Convolution Meets Masked Autoencoders (2022)](https://arxiv.org/abs/2205.03892) ([Code](https://github.com/Alpha-VL/ConvMAE))
- [Deep Kernelized Dense Geometric Matching (2022)](https://arxiv.org/abs/2202.00667) ([Code](https://github.com/Parskatt/DKM))
- [Unsupervised Semantic Segmentation by Distilling Feature Correspondences (2022)](https://arxiv.org/abs/2203.08414) ([Code](https://github.com/mhamilton723/STEGO))
- [RecursiveMix: Mixed Learning with History (2022)](https://arxiv.org/abs/2203.06844) ([Code](https://github.com/implus/RecursiveMix-pytorch))
- [MMDetection3d](https://github.com/open-mmlab/mmdetection3d) - OpenMMLab's next-generation platform for general 3D object detection.
- [Imagen: Text-to-Image Diffusion Models](https://imagen.research.google/) ([Tweet](https://twitter.com/JeffDean/status/1528951937948741632)) ([Code](https://github.com/lucidrains/imagen-pytorch)) ([HN](https://news.ycombinator.com/item?id=31484562)) ([HN](https://news.ycombinator.com/item?id=31513919))
- [An End-to-End Transformer Model for 3D Object Detection (2021)](https://arxiv.org/abs/2109.08141) ([Code](https://github.com/facebookresearch/3detr))
- [Neural 3D Reconstruction in the Wild (2022)](https://arxiv.org/abs/2205.12955) ([Code](https://github.com/zju3dv/NeuralRecon-W))
- [Body shape and pose estimation on 3D scans of people in clothing using Ceres Solver](https://github.com/maria-korosteleva/Body-Shape-Estimation)
- [A Survey of Visual Transformers (2021)](https://arxiv.org/abs/2111.06091) ([Code](https://github.com/liuyang-ict/awesome-visual-transformers))
- [Nerfies: Deformable Neural Radiance Fields (2021)](https://nerfies.github.io/) ([Code](https://github.com/nerfies/nerfies.github.io))
- [Working notes on the role of vision papers in basic science (2022)](https://scienceplusplus.org/visions/index.html) ([Tweet](https://twitter.com/michael_nielsen/status/1530659395453202433))
- [CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers (2022)](https://github.com/THUDM/CogVideo) ([HN](https://news.ycombinator.com/item?id=31561845))
- [Prompt-aligned Gradient for Prompt Tuning (2022)](https://arxiv.org/abs/2205.14865) ([Code](https://github.com/BeierZhu/Prompt-align))
- [Text2Human: Text-Driven Controllable Human Image Generation (2022)](https://arxiv.org/abs/2205.15996) ([Code](https://github.com/yumingj/Text2Human))
- [OnePose: One-Shot Object Pose Estimation without CAD Models (2022)](https://arxiv.org/abs/2205.12257) ([Code](https://github.com/zju3dv/OnePose))
- [PREF: Phasorial Embedding Fields for Compact Neural Representations (2022)](https://arxiv.org/abs/2205.13524) ([Code](https://github.com/hbb1/PREF))
- [Optimizing Relevance Maps of Vision Transformers Improves Robustness (2022)](https://arxiv.org/abs/2206.01161) ([Code](https://github.com/hila-chefer/RobustViT))
- [Exploring Visual Prompts for Adapting Large-Scale Models (2022)](https://arxiv.org/abs/2203.17274) ([Code](https://github.com/hjbahng/visual_prompting))
- [Deepfake Offensive Toolkit](https://github.com/sensity-ai/dot) - Makes real-time, controllable deepfakes ready for virtual cameras injection. ([HN](https://news.ycombinator.com/item?id=31650797))
- [Real-time Object Detection for Streaming Perception (2022)](https://arxiv.org/abs/2203.12338) ([Code](https://github.com/yancie-yjr/StreamYOLO))
- [Volumentations 3D](https://github.com/ZFTurbo/volumentations) - Library for 3D augmentations.
- [Awesome Learning with Label Noise](https://github.com/subeeshvasu/Awesome-Learning-with-Label-Noise)
- [LIVE: Towards Layer-wise Image Vectorization (2022)](https://ma-xu.github.io/LIVE/) ([Code](https://github.com/ma-xu/LIVE))
- [BEVT: BERT Pretraining of Video Transformers (2021)](https://arxiv.org/abs/2112.01529) ([Code](https://github.com/xyzforever/BEVT))
- [Variable Bitrate Neural Fields (2022)](https://nv-tlabs.github.io/vqad/) ([Code](https://github.com/nv-tlabs/vqad))
- [Gated-SCNN: Gated Shape CNNs for Semantic Segmentation (2019)](https://arxiv.org/abs/1907.05740) ([Code](https://github.com/nv-tlabs/GSCNN))
- [Masked Unsupervised Self-training for Zero-shot Image Classification (2022)](https://arxiv.org/abs/2206.02967) ([Code](https://github.com/salesforce/MUST))
- [HumanNeRF: Free-viewpoint Rendering of Moving People from Monocular Video (2022)](https://arxiv.org/abs/2201.04127) ([Code](https://github.com/chungyiweng/humannerf))
- [Awesome Implicit NeRF Robotics](https://github.com/zubair-irshad/Awesome-Implicit-NeRF-Robotics)
- [EfficientFormer: Vision Transformers at MobileNet Speed (2022)](https://arxiv.org/abs/2206.01191) ([Code](https://github.com/snap-research/EfficientFormer))
- [ARF: Artistic Radiance Fields (2022)](https://www.cs.cornell.edu/projects/arf/) ([Code](https://github.com/Kai-46/ARF-svox2)) ([HN](https://news.ycombinator.com/item?id=31825177))
- [Patch2Pix: Epipolar-Guided Pixel-Level Correspondences (2020)](https://arxiv.org/abs/2012.01909) ([Code](https://github.com/GrumpyZhou/patch2pix))
- [Translating Images into Maps (2022)](https://arxiv.org/abs/2110.00966) ([Code](https://github.com/avishkarsaha/translating-images-into-maps))
- [Instances as Queries (2021)](https://arxiv.org/abs/2105.01928) ([Code](https://github.com/hustvl/QueryInst))
- [OcclusionFusion: Occlusion-aware Motion Estimation for Real-time Dynamic 3D Reconstruction (2022)](https://arxiv.org/abs/2203.07977) ([Code](https://github.com/wenbin-lin/OcclusionFusion))
- [CogView: Mastering Text-to-Image Generation via Transformers (2021)](https://arxiv.org/abs/2105.13290) ([Code](https://github.com/THUDM/CogView2))
- [All in One: Exploring Unified Video-Language Pre-training (2022)](https://arxiv.org/abs/2203.07303) ([Code](https://github.com/showlab/all-in-one))
- [Towards Exemplar-Free Continual Learning in Vision Transformers: an Account of Attention, Functional and Weight Regularization (2022)](https://arxiv.org/abs/2203.13167) ([Code](https://github.com/srvCodes/continual_learning_with_vit))
- [Solving Inefficiency of Self-supervised Representation Learning (2021)](https://arxiv.org/abs/2104.08760) ([Code](https://github.com/wanggrun/triplet))
- [NeRFactor: Neural Factorization of Shape and Reflectance Under an Unknown Illumination (2021)](https://arxiv.org/abs/2106.01970) ([Code](https://github.com/google/nerfactor))
- [Trending in 3D Vision](https://github.com/dragonlong/Trending-in-3D-Vision)
- [ShapeFormer: Transformer-based Shape Completion via Sparse Representation (2022)](https://shapeformer.github.io/) ([Code](https://github.com/QhelDIV/ShapeFormer))
- [Awesome Prompting Papers in Computer Vision](https://github.com/ttengwang/Awesome_Prompting_Papers_in_Computer_Vision)
- [EPro-PnP: Generalized End-to-End Probabilistic Perspective-n-Points for Monocular Object Pose Estimation (2022)](https://arxiv.org/abs/2203.13254) ([Code](https://github.com/tjiiv-cprg/EPro-PnP))
- [GenDR: A Generalized Differentiable Renderer (2022)](https://arxiv.org/abs/2204.13845) ([Code](https://github.com/Felix-Petersen/gendr))
- [Elucidating the Design Space of Diffusion-Based Generative Models (2022)](https://arxiv.org/abs/2206.00364) ([Code](https://github.com/crowsonkb/k-diffusion))
- [IRON: Inverse Rendering by Optimizing Neural SDFs and Materials from Photometric Images (2022)](https://kai-46.github.io/IRON-website/) ([Code](https://github.com/Kai-46/IRON))
- [Omnivore: A Single Model for Many Visual Modalities (2022)](https://arxiv.org/abs/2201.08377) ([Code](https://github.com/facebookresearch/omnivore))
- [Benchmarking and Analyzing Point Cloud Classification under Corruptions (2022)](https://arxiv.org/abs/2202.03377) ([Code](https://github.com/ldkong1205/PointCloud-C))
- [DVGO: Direct Voxel Grid Optimization (Super-fast Convergence for Radiance Fields Reconstruction) (2022)](https://sunset1995.github.io/dvgo/) ([Code](https://github.com/sunset1995/DirectVoxGO))
- [RegionCLIP: Region-based Language-Image Pretraining (2021)](https://arxiv.org/abs/2112.09106) ([Code](https://github.com/microsoft/RegionCLIP))
- [Fast Light-Weight Near-Field Photometric Stereo (2022)](https://dlichy.github.io/fastNFPS.github.io/) ([Code](https://github.com/dlichy/FastNFPSCode))
- [ILVR: Conditioning Method for Denoising Diffusion Probabilistic Models (2021)](https://arxiv.org/abs/2108.02938) ([Code](https://github.com/jychoi118/ilvr_adm))
- [RePaint: Inpainting using Denoising Diffusion Probabilistic Models](https://github.com/andreas128/RePaint)
- [The Probabilistic Normal Epipolar Constraint for Frame-To-Frame Rotation Optimization under Uncertain Feature Positions (2022)](https://arxiv.org/abs/2204.02256) ([Code](https://github.com/tum-vision/pnec))
- [3D Moments from Near-Duplicate Photos (2022)](https://arxiv.org/abs/2205.06255) ([Code](https://github.com/google-research/3d-moments))
- [Prototypical Contrastive Language Image Pretraining (2022)](https://arxiv.org/abs/2206.10996) ([Code](https://github.com/megvii-research/protoclip))
- [NeRV: Neural Representations for Videos (2021)](https://haochen-rye.github.io/NeRV/) ([Code](https://github.com/haochen-rye/NeRV))
- [MT-YOLOv6](https://github.com/meituan/YOLOv6) - Single-stage object detection framework dedicated to industrial applications.
- [Fast Point Transformer (2022)](https://arxiv.org/abs/2112.04702) ([Code](https://github.com/POSTECH-CVLab/FastPointTransformer))
- [FIFO: Learning Fog-invariant Features for Foggy Scene Segmentation (2022)](https://arxiv.org/abs/2204.01587) ([Code](https://github.com/sohyun-l/fifo))
- [Nettle Magic Project](https://github.com/nettlep/magic) - Scanner for decks of cards with bar codes printed on card edges. ([HN](https://news.ycombinator.com/item?id=31922682))
- [Image Quality Assessment using Contrastive Learning (2021)](https://arxiv.org/abs/2110.13266) ([Code](https://github.com/pavancm/CONVIQT))
- [Denoised MDPs: Learning World Models Better Than The World Itself (2022)](https://ssnl.github.io/denoised_mdp/) ([Code](https://github.com/facebookresearch/denoised_mdp))
- [Sparse Instance Activation for Real-Time Instance Segmentation (2022)](https://arxiv.org/abs/2203.12827) ([Code](https://github.com/hustvl/SparseInst))
- [Referring Image Matting (2022)](https://arxiv.org/abs/2206.05149) ([Code](https://github.com/JizhiziLi/RIM))
- [Voxel-MAE: Masked Autoencoders for Pre-training Large-scale Point Clouds (2022)](https://arxiv.org/abs/2206.09900) ([Code](https://github.com/chaytonmin/Voxel-MAE))
- [Contrastive Boundary Learning for Point Cloud Segmentation (2022)](https://arxiv.org/abs/2203.05272) ([Code](https://github.com/LiyaoTang/contrastBoundary))
- [Scaling up Kernels in 3D CNNs (2022)](https://arxiv.org/abs/2206.10555) ([Code](https://github.com/dvlab-research/LargeKernel3D))
- [Oriented RepPoints for Aerial Object Detection (2022)](https://arxiv.org/abs/2105.11111v4) ([Code](https://github.com/LiWentomng/OrientedRepPoints))
- [Reliable Visual Question Answering: Abstain Rather Than Answer Incorrectly (2022)](https://arxiv.org/abs/2204.13631) ([Code](https://github.com/facebookresearch/reliable_vqa))
- [EdgeNeXt: Efficiently Amalgamated CNN-Transformer Architecture for Mobile Vision Applications (2022)](https://arxiv.org/abs/2206.10589) ([Code](https://github.com/mmaaz60/EdgeNeXt))
- [Awesome Visual Diffusion Models](https://github.com/Xiefan-Guo/Awesome-Visual-Diffusion-Models)
- [Vision Transformer Adapter for Dense Predictions (2022)](https://arxiv.org/abs/2205.08534) ([Code](https://github.com/czczup/ViT-Adapter))
- [Activating More Pixels in Image Super-Resolution Transformer (2022)](https://arxiv.org/abs/2205.04437) ([Code](https://github.com/XPixelGroup/HAT))
- [PointNeXt: Revisiting PointNet++ with Improved Training and Scaling Strategies (2022)](https://arxiv.org/abs/2206.04670) ([Code](https://github.com/guochengqian/PointNeXt))
- [GMFlow: Learning Optical Flow via Global Matching (2022)](https://arxiv.org/abs/2111.13680) ([Code](https://github.com/haofeixu/gmflow))
- [Vector-quantized Image Modeling with Improved VQGAN (2021)](https://arxiv.org/abs/2110.04627) ([JAX Code](https://github.com/patil-suraj/vit-vqgan))
- [Learned Vertex Descent: A New Direction for 3D Human Model Fitting (2022)](https://arxiv.org/abs/2205.06254) ([Code](https://github.com/enriccorona/LVD))
- [YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors (2022)](https://arxiv.org/abs/2207.02696) ([Code](https://github.com/WongKinYiu/yolov7))
- [AITViewer](https://github.com/eth-ait/aitviewer) - Set of tools to visualize and interact with sequences of 3D data.
- [Object-Compositional Neural Implicit Surfaces](https://wuqianyi.top/objectsdf/) ([Code](https://github.com/QianyiWu/objsdf))
- [Awesome Egocentric Vision](https://github.com/Sid2697/awesome-egocentric-vision)
- [MonoScene: Monocular 3D Semantic Scene Completion (2022)](https://cv-rits.github.io/MonoScene/) ([Code](https://github.com/cv-rits/MonoScene))
- [Visual Prompt Tuning (2022)](https://arxiv.org/abs/2203.12119) ([Code](https://github.com/KMnP/vpt))
- [Unified Implicit Neural Stylization (2022)](https://arxiv.org/abs/2204.01943) ([Code](https://github.com/VITA-Group/INS))
- [3D-Aware Semantic-Guided Generative Model for Human Synthesis (2021)](https://arxiv.org/abs/2112.01422) ([Code](https://github.com/zhangqianhui/3DSGAN))
- [Text2LIVE: Text-Driven Layered Image and Video Editing (2022)](https://text2live.github.io/) ([HN](https://news.ycombinator.com/item?id=32043235))
- [HiVT: Hierarchical Vector Transformer for Multi-Agent Motion Prediction (2022)](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_HiVT_Hierarchical_Vector_Transformer_for_Multi-Agent_Motion_Prediction_CVPR_2022_paper.pdf) ([Code](https://github.com/ZikangZhou/HiVT))
- [Generalization of Otsu's Method and Minimum Error Thresholding (2020)](https://arxiv.org/abs/2007.07350)
- [XMem: Long-Term Video Object Segmentation with an Atkinson-Shiffrin Memory Model (2022)](https://arxiv.org/abs/2207.07115) ([Code](https://github.com/hkchengrex/XMem))
- [Rethinking Space-Time Networks with Improved Memory Coverage for Efficient Video Object Segmentation (2021)](https://arxiv.org/abs/2106.05210) ([Code](https://github.com/hkchengrex/STCN))
- [Deformable Sprites for Unsupervised Video Decomposition (2022)](https://arxiv.org/abs/2204.07151) ([Code](https://github.com/vye16/deformable-sprites))
- [Topologically-Aware Deformation Fields for Single-View 3D Reconstruction (2022)](https://arxiv.org/abs/2205.06267) ([Code](https://github.com/ShivamDuggal4/TARS3D))
- [Multimodal Transformer with Variable-length Memory for Vision-and-Language Navigation (2021)](https://arxiv.org/abs/2111.05759) ([Code](https://github.com/clin1223/MTVM))
- [Refign: Align and Refine for Adaptation of Semantic Segmentation to Adverse Conditions (2022)](https://arxiv.org/abs/2207.06825) ([Code](https://github.com/brdav/refign))
- [Multi-View Depth Estimation by Fusing Single-View Depth Probability with Multi-View Geometry (2021)](https://arxiv.org/abs/2112.08177) ([Code](https://github.com/baegwangbin/MaGNet))
- [Box-supervised Instance Segmentation with Level Set Evolution (2022)](https://github.com/LiWentomng/boxlevelset)
- [Tent: Fully Test-Time Adaptation by Entropy Minimization (2021)](https://openreview.net/forum?id=uXl3bZLkr3c) ([Code](https://github.com/DequanWang/tent))
- [UniFormer: Unifying Convolution and Self-attention for Visual Recognition (2022)](https://arxiv.org/abs/2201.09450) ([Code](https://github.com/Sense-X/UniFormer))
- [MOTR: End-to-End Multiple-Object Tracking with Transformer (2022)](https://arxiv.org/abs/2105.03247) ([Code](https://github.com/megvii-research/MOTR))
- [Towards Grand Unification of Object Tracking (2022)](https://arxiv.org/abs/2207.07078) ([Code](https://github.com/MasterBin-IIAU/Unicorn))
- [Benchmarking Omni-Vision Representation through the Lens of Visual Realms (2022)](https://arxiv.org/abs/2207.07106) ([Code](https://github.com/ZhangYuanhan-AI/OmniBenchmark))
- [Color Histograms in Image Retrieval](https://www.pinecone.io/learn/color-histograms/)
- [SeqTR: A Simple yet Universal Network for Visual Grounding (2022)](https://arxiv.org/abs/2203.16265) ([Code](https://github.com/sean-zhuh/SeqTR))
- [Image Inpainting with External-internal Learning and Monochromic Bottleneck (2021)](https://arxiv.org/abs/2104.09068) ([Code](https://github.com/Tengfei-Wang/external-internal-inpainting))
- [Deep Image Homography Estimation (2016)](https://arxiv.org/abs/1606.03798) ([Code](https://github.com/mazenmel/Deep-homography-estimation-Pytorch))
- [Illumination Adaptive Transformer (2022)](https://arxiv.org/abs/2205.14871) ([Code](https://github.com/cuiziteng/Illumination-Adaptive-Transformer))
- [MotionCLIP: Exposing Human Motion Generation to CLIP Space (2022)](https://arxiv.org/abs/2203.08063) ([Code](https://github.com/GuyTevet/MotionCLIP))
- [Awesome Image Composition](https://github.com/bcmi/Awesome-Image-Composition)
- [Scene Text Recognition with Permuted Autoregressive Sequence Models (2022)](https://arxiv.org/abs/2207.06966) ([Code](https://github.com/baudm/parseq))
- [Multimodal Masked Autoencoders Learn Transferable Representations](https://arxiv.org/abs/2205.14204) ([Code](https://github.com/young-geng/m3ae_public))
- [BEVDepth: Acquisition of Reliable Depth for Multi-view 3D Object Detection (2022)](https://arxiv.org/abs/2206.10092) ([Code](https://github.com/Megvii-BaseDetection/BEVDepth))
- [BEVerse: Unified Perception and Prediction in Birds-Eye-View for Vision-Centric Autonomous Driving (2022)](https://arxiv.org/abs/2205.09743) ([Code](https://github.com/zhangyp15/BEVerse))
- [AdaNeRF: Adaptive Sampling for Real-time Rendering of Neural Radiance Fields (2022)](https://arxiv.org/abs/2207.10312) ([Code](https://github.com/thomasneff/AdaNeRF))
- [Harmonizer: Learning to Perform White-Box Image and Video Harmonization (2022)](https://arxiv.org/abs/2207.01322) ([Code](https://github.com/ZHKKKe/Harmonizer))
- [CVAT](https://www.cvat.ai/) - Computer Vision Annotation Tool. ([Code](https://github.com/cvat-ai/cvat))
- [NeuMesh: Learning Disentangled Neural Mesh-based Implicit Field for Geometry and Texture Editing (2022)](https://github.com/zju3dv/NeuMesh)
- [Monocular 3D Object Detection with Depth from Motion (2022)](https://arxiv.org/abs/2207.12988) ([Code](https://github.com/Tai-Wang/Depth-from-Motion))
- [Masked Discrimination for Self-Supervised Learning on Point Clouds (2022)](https://arxiv.org/abs/2203.11183) ([Code](https://github.com/haotian-liu/MaskPoint))
- [SORT](https://github.com/abewley/sort) - Simple, online, and real time tracking of multiple objects in a video sequence.
- [Local Color Distributions Prior for Image Enhancement (2022)](https://hywang99.github.io/2022/07/09/lcdpnet/) ([Code](https://github.com/hywang99/LCDPNet))
- [S2Contact: Graph-based Network for 3D Hand-Object Contact Estimation with Semi-Supervised Learning (2022)](https://eldentse.github.io/s2contact/) ([Code](https://github.com/eldentse/s2contact))
- [Is Attention All NeRF Needs? (2022)](https://arxiv.org/abs/2207.13298) ([Code](https://github.com/VITA-Group/GNT))
- [Camouflaged/Concealed Object Detection](https://github.com/visionxiang/awesome-camouflaged-object-detection)
- [Accelerate Vision Transformer (ViT) with Quantization using Optimum (2022)](https://www.philschmid.de/optimizing-vision-transformer)
- [Optimizing Transformers for GPUs with Optimum (2022)](https://www.philschmid.de/optimizing-transformers-with-optimum-gpu)
- [Photogrammetry Guide](https://github.com/mikeroyal/Photogrammetry-Guide) ([HN](https://news.ycombinator.com/item?id=32284276))
- [Multi-View Mesh Reconstruction with Neural Deferred Shading (2022)](https://fraunhoferhhi.github.io/neural-deferred-shading/) ([Code](https://github.com/fraunhoferhhi/neural-deferred-shading))
- [Initialization and Alignment for Adversarial Texture Optimization (2022)](https://arxiv.org/abs/2207.14289) ([Code](https://github.com/Xiaoming-Zhao/advtex_init_align))
- [DCT-Net: Domain-Calibrated Translation for Portrait Stylization (2022)](https://arxiv.org/abs/2207.02426) ([Code](https://github.com/menyifang/DCT-Net))
- [Pretraining is All You Need for Image-to-Image Translation (2022)](https://arxiv.org/abs/2205.12952) ([Code](https://github.com/PITI-Synthesis/PITI))
- [Vision-Centric BEV Perception: A Survey](https://github.com/4DVLab/Vision-Centric-BEV-Perception)
- [Share With Thy Neighbors: Single-View Reconstruction by Cross-Instance Consistency (2022)](https://arxiv.org/abs/2204.10310) ([Code](https://github.com/monniert/unicorn))
- [Awesome Weakly Supervised Semantic Segmentation Papers](https://github.com/PengtaoJiang/Awesome-Weakly-Supervised-Semantic-Segmentation-Papers)
- [GAUDI: A Neural Architect for Immersive 3D Scene Generation (2022)](https://arxiv.org/abs/2207.13751) ([Code](https://github.com/apple/ml-gaudi)) ([HN](https://news.ycombinator.com/item?id=32344014))
- [Multimodal Image Synthesis and Editing: A Survey (2021)](https://arxiv.org/abs/2112.13592) ([Code](https://github.com/fnzhan/MISE))
- [High-Resolution Image Synthesis with Latent Diffusion Models (2022)](https://arxiv.org/abs/2112.10752) ([Code](https://github.com/pesser/stable-diffusion))
- [ASE: Large-Scale Reusable Adversarial Skill Embeddings for Physically Simulated Characters (2022)](https://xbpeng.github.io/projects/ASE/index.html) ([Code](https://github.com/nv-tlabs/ASE))
- [3D Vision with Transformers: A Survey (2022)](https://github.com/lahoud/3d-vision-transformers)
- [Optical Flow Processing Stack](https://github.com/h33p/ofps)
- [VideoX - Multi-modal Video Content Understanding](https://github.com/microsoft/VideoX)
- [Simple Baselines for Image Restoration (2022)](https://arxiv.org/abs/2204.04676) ([Code](https://github.com/megvii-research/NAFNet))
- [Analog Bits: Generating Discrete Data using Diffusion Models with Self-Conditioning (2022)](https://arxiv.org/abs/2208.04202)
- [Revisiting the Critical Factors of Augmentation-Invariant Representation Learning (2022)](https://arxiv.org/abs/2208.00275) ([Code](https://github.com/megvii-research/revisitAIRL))
- [Image Quality Related Papers](https://github.com/weizhou-geek/Recent-Image-Quality-Related-Papers)
- [Learning Spatiotemporal Frequency-Transformer for Compressed Video Super-Resolution (2022)](https://arxiv.org/abs/2208.03012) ([Code](https://github.com/researchmm/FTVSR))
- [MCVD: Masked Conditional Video Diffusion for Prediction, Generation, and Interpolation (2022)](https://arxiv.org/abs/2205.09853) ([Code](https://github.com/voletiv/mcvd-pytorch))
